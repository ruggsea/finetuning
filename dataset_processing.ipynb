{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_HOME=/work/ba214121/.cache/huggingface\n",
      "env: TRANFORMERS_CACHE=/work/ba214121/.cache/huggingface\n",
      "env: HF_DATASETS_CACHE=/work/ba214121/.cache/huggingface\n",
      "/work/ba214121/.cache/huggingface\n"
     ]
    }
   ],
   "source": [
    "## making sure env variables are set\n",
    "%env HF_HOME=/hpcwork/ba214121/.cache/huggingface\n",
    "%env TRANFORMERS_CACHE=/hpcwork/ba214121/.cache/huggingface\n",
    "%env HF_DATASETS_CACHE=/hpcwork/ba214121/.cache/huggingface\n",
    "\n",
    "\n",
    "!echo $HF_DATASETS_CACHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting dataset from HF\n",
    "\n",
    "import os\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "phil_enc_dataset=load_dataset(\"hugfaceguy0001/stanford_plato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(phil_enc_dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "John Wyclif’s Political Philosophy    1\n",
       "Abduction                             1\n",
       "Peter Abelard                         1\n",
       "Abhidharma                            1\n",
       "Abilities                             1\n",
       "                                     ..\n",
       "The Concept of the Aesthetic          1\n",
       "Aesthetic Experience                  1\n",
       "Aesthetics of the Everyday            1\n",
       "Affirmative Action                    1\n",
       "Africana Philosophy                   1\n",
       "Name: count, Length: 1776, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nIn the philosophical literature, the term “abduction” is\\nused in two related but different senses. In both senses, the term\\nrefers to some form of explanatory reasoning. However, in the\\nhistorically first sense, it refers to the place of explanatory\\nreasoning in generating hypotheses, while in the sense in\\nwhich it is used most frequently in the modern literature it refers to\\nthe place of explanatory reasoning in justifying hypotheses.\\nIn the latter sense, abduction is also often called “Inference\\nto the Best Explanation.”',\n",
       " '\\nThis entry is exclusively concerned with abduction in the modern\\nsense, although there is a supplement on abduction in the historical\\nsense, which had its origin in the work of Charles Sanders\\nPeirce—see the',\n",
       " '\\nSee also the entry on\\n scientific discovery,\\n in particular the section on discovery as abduction.',\n",
       " '\\nMost philosophers agree that abduction (in the sense of Inference to\\nthe Best Explanation) is a type of inference that is frequently\\nemployed, in some form or other, both in everyday and in scientific\\nreasoning. However, the exact form as well as the normative status of\\nabduction are still matters of controversy. This entry contrasts\\nabduction with other types of inference; points at prominent uses of\\nit, both in and outside philosophy; considers various more or less\\nprecise statements of it; discusses its normative status; and\\nhighlights possible connections between abduction and Bayesian\\nconfirmation theory.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.preamble[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "## load the llama tokenizer\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_main = df.main_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'main_content': ['\\nYou happen to know that Tim and Harry have recently had a terrible row\\nthat ended their friendship. Now someone tells you that she just saw\\nTim and Harry jogging together. The best explanation for this that you\\ncan think of is that they made up. You conclude that they are friends\\nagain.',\n",
       "   '\\nOne morning you enter the kitchen to find a plate and cup on the\\ntable, with breadcrumbs and a pat of butter on it, and surrounded by a\\njar of jam, a pack of sugar, and an empty carton of milk. You conclude\\nthat one of your house-mates got up at night to make him- or herself a\\nmidnight snack and was too tired to clear the table. This, you think,\\nbest explains the scene you are facing. To be sure, it might be that\\nsomeone burgled the house and took the time to have a bite while on\\nthe job, or a house-mate might have arranged the things on the table\\nwithout having a midnight snack but just to make you believe that\\nsomeone had a midnight snack. But these hypotheses strike you as\\nproviding much more contrived explanations of the data than the one\\nyou infer to.',\n",
       "   '\\nWalking along the beach, you see what looks like a picture of Winston\\nChurchill in the sand. It could be that, as in the opening pages of\\nHilary Putnam’s book Reason, Truth, and History,\\n(1981), what you see is actually the trace of an ant crawling on the\\nbeach. The much simpler, and therefore (you think) much better,\\nexplanation is that someone intentionally drew a picture of Churchill\\nin the sand. That, in any case, is what you come away believing.',\n",
       "   '\\nIn these examples, the conclusions do not follow logically from the\\npremises. For instance, it does not follow logically that Tim and\\nHarry are friends again from the premises that they had a terrible row\\nwhich ended their friendship and that they have just been seen jogging\\ntogether; it does not even follow, we may suppose, from all the\\ninformation you have about Tim and Harry. Nor do you have any useful\\nstatistical data about friendships, terrible rows, and joggers that\\nmight warrant an inference from the information that you have about\\nTim and Harry to the conclusion that they are friends again, or even\\nto the conclusion that, probably (or with a certain probability), they\\nare friends again. What leads you to the conclusion, and what\\naccording to a considerable number of philosophers may also warrant\\nthis conclusion, is precisely the fact that Tim and Harry’s\\nbeing friends again would, if true, best explain the\\nfact that they have just been seen jogging together. (The proviso that\\na hypothesis be true if it is to explain anything is taken as read\\nfrom here on.) Similar remarks apply to the other two examples. The\\ntype of inference exhibited here is called abduction or,\\nsomewhat more commonly nowadays, Inference to the Best\\nExplanation.'],\n",
       "  'section_title': '1. Abduction: The General Idea',\n",
       "  'subsections': [{'content': ['\\nAbduction is normally thought of as being one of three major types of\\ninference, the other two being deduction and induction. The\\ndistinction between deduction, on the one hand, and induction and\\nabduction, on the other hand, corresponds to the distinction between\\nnecessary and non-necessary inferences. In deductive inferences, what\\nis inferred is necessarily true if the premises from which it\\nis inferred are true; that is, the truth of the premises\\nguarantees the truth of the conclusion. A familiar type of\\nexample is inferences instantiating the schema',\n",
       "     '\\nAll As are Bs.\\n\\na is an A.\\n\\nHence, a is a B.\\n',\n",
       "     '\\nBut not all inferences are of this variety. Consider, for instance,\\nthe inference of “John is rich” from “John lives in\\nChelsea” and “Most people living in Chelsea are\\nrich.” Here, the truth of the first sentence is not guaranteed\\n(but only made likely) by the joint truth of the second and third\\nsentences. Differently put, it is not necessarily the case that if the\\npremises are true, then so is the conclusion: it is logically\\ncompatible with the truth of the premises that John is a member of the\\nminority of non-rich inhabitants of Chelsea. The case is similar\\nregarding your inference to the conclusion that Tim and Harry are\\nfriends again on the basis of the information that they have been seen\\njogging together. Perhaps Tim and Harry are former business partners\\nwho still had some financial matters to discuss, however much they\\nwould have liked to avoid this, and decided to combine this with their\\ndaily exercise; this is compatible with their being firmly decided\\nnever to make up.',\n",
       "     '\\nIt is standard practice to group non-necessary inferences into\\ninductive and abductive ones. Inductive inferences\\nform a somewhat heterogeneous class, but for present purposes they may\\nbe characterized as those inferences that are based purely on\\nstatistical data, such as observed frequencies of occurrences of a\\nparticular feature in a given population. An example of such an\\ninference would be this:',\n",
       "     '\\n96 per cent of the Flemish college students speak both Dutch and\\nFrench.\\n\\nLouise is a Flemish college student.\\n\\nHence, Louise speaks both Dutch and French.\\n',\n",
       "     '\\nHowever, the relevant statistical information may also be more vaguely\\ngiven, as in the premise, “Most people living in Chelsea are\\nrich.” (There is much discussion about whether the conclusion of\\nan inductive argument can be stated in purely qualitative terms or\\nwhether it should be a quantitative one—for instance, that it\\nholds with a probability of .96 that Louise speaks both Dutch and\\nFrench—or whether it can sometimes be stated in\\nqualitative terms—for instance, if the probability that it is\\ntrue is high enough—and sometimes not. On these and other issues\\nrelated to induction, see Kyburg 1990 (Ch. 4). It should also be\\nmentioned that Harman (1965) conceives induction as a special type of\\nabduction. See also Weintraub 2013 for discussion.)',\n",
       "     '\\nThe mere fact that an inference is based on statistical data is not\\nenough to classify it as an inductive one. You may have observed many\\ngray elephants and no non-gray ones, and infer from this that all\\nelephants are gray, because that would provide the best\\nexplanation for why you have observed so many gray elephants\\nand no non-gray ones. This would be an instance of an\\nabductive inference. It suggests that the best way to distinguish\\nbetween induction and abduction is this: both are ampliative,\\nmeaning that the conclusion goes beyond what is (logically) contained\\nin the premises (which is why they are non-necessary inferences), but\\nin abduction there is an implicit or explicit appeal to explanatory\\nconsiderations, whereas in induction there is not; in induction, there\\nis only an appeal to observed frequencies or statistics. (I\\nemphasize “only,” because in abduction there may also be\\nan appeal to frequencies or statistics, as the example about the\\nelephants exhibits.)',\n",
       "     '\\nA noteworthy feature of abduction, which it shares with induction but\\nnot with deduction, is that it violates monotonicity, meaning\\nthat it may be possible to infer abductively certain conclusions from\\na subset of a set S of premises which cannot be\\ninferred abductively from S as a whole. For instance, adding\\nthe premise that Tim and Harry are former business partners who still\\nhave some financial matters to discuss, to the premises that they had\\na terrible row some time ago and that they were just seen jogging\\ntogether may no longer warrant you to infer that they are friends\\nagain, even if—let us suppose—the last two premises alone\\ndo warrant that inference. The reason is that what counts as the best\\nexplanation of Tim and Harry’s jogging together in light of the\\noriginal premises may no longer do so once the information has been\\nadded that they are former business partners with financial matters to\\ndiscuss.'],\n",
       "    'subsection_title': '1.1 Deduction, induction, abduction'},\n",
       "   {'content': ['\\nThe type of inference exemplified in the cases described at the\\nbeginning of this entry will strike most as entirely familiar.\\nPhilosophers as well as psychologists tend to agree that abduction is\\nfrequently employed in everyday reasoning. Sometimes our reliance on\\nabductive reasoning is quite obvious and explicit. But in some daily\\npractices, it may be so routine and automatic that it easily goes\\nunnoticed. A case in point may be our trust in other people’s\\ntestimony, which has been said to rest on abductive reasoning; see\\nHarman 1965, Adler 1994, Fricker 1994, and Lipton 1998 for defenses of\\nthis claim. For instance, according to Jonathan Adler (1994, 274f),\\n“[t]he best explanation for why the informant asserts that\\nP is normally that … he believes it for duly responsible\\nreasons and … he intends that I shall believe it too,”\\nwhich is why we are normally justified in trusting the\\ninformant’s testimony. This may well be correct, even though in\\ncoming to trust a person’s testimony one does not normally seem\\nto be aware of any abductive reasoning going on in one’s mind.\\nSimilar remarks may apply to what some hold to be a further, possibly\\neven more fundamental, role of abduction in linguistic practice, to\\nwit, its role in determining what a speaker means by an utterance.\\nSpecifically, it has been argued that decoding utterances is a matter\\nof inferring the best explanation of why someone said what he or she\\nsaid in the context in which the utterance was made. Even more\\nspecifically, authors working in the field of pragmatics have\\nsuggested that hearers invoke the Gricean maxims of conversation to\\nhelp them work out the best explanation of a speaker’s utterance\\nwhenever the semantic content of the utterance is insufficiently\\ninformative for the purposes of the conversation, or is too\\ninformative, or off-topic, or implausible, or otherwise odd or\\ninappropriate; see, for instance, Bach and Harnish 1979 (92f), Dascal\\n1979 (167), and Hobbs 2004. As in cases of reliance on speaker\\ntestimony, the requisite abductive reasoning would normally seem to\\ntake place at a subconscious level.',\n",
       "     '\\nAbductive reasoning is not limited to everyday contexts. Quite the\\ncontrary: philosophers of science have argued that abduction is a\\ncornerstone of scientific methodology; see, for instance, Boyd 1981,\\n1984, Harré 1986, 1988, Lipton 1991, 2004, and Psillos 1999.\\nAccording to Timothy Williamson (2007), “[t]he abductive\\nmethodology is the best science provides” and Ernan McMullin\\n(1992) even goes so far to call abduction “the inference that\\nmakes science.” To illustrate the use of abduction in science,\\nwe consider two examples.',\n",
       "     '\\nAt the beginning of the nineteenth century, it was discovered that the\\norbit of Uranus, one of the seven planets known at the time, departed\\nfrom the orbit as predicted on the basis of Isaac Newton’s\\ntheory of universal gravitation and the auxiliary assumption that\\nthere were no further planets in the solar system. One possible\\nexplanation was, of course, that Newton’s theory is false. Given\\nits great empirical successes for (then) more than two centuries, that\\ndid not appear to be a very good explanation. Two astronomers, John\\nCouch Adams and Urbain Leverrier, instead suggested (independently of\\neach other but almost simultaneously) that there was an eighth, as yet\\nundiscovered planet in the solar system; that, they thought, provided\\nthe best explanation of Uranus’ deviating orbit. Not much later,\\nthis planet, which is now known as “Neptune,” was\\ndiscovered.',\n",
       "     '\\nThe second example concerns what is now commonly regarded to have been\\nthe discovery of the electron by the English physicist Joseph John\\nThomson. Thomson had conducted experiments on cathode rays in order to\\ndetermine whether they are streams of charged particles. He concluded\\nthat they are indeed, reasoning as follows:',\n",
       "     '\\n\\n\\nAs the cathode rays carry a charge of negative electricity, are\\ndeflected by an electrostatic force as if they were negatively\\nelectrified, and are acted on by a magnetic force in just the way in\\nwhich this force would act on a negatively electrified body moving\\nalong the path of these rays, I can see no escape from the conclusion\\nthat they are charges of negative electricity carried by particles of\\nmatter. (Thomson, cited in Achinstein 2001, 17)\\n',\n",
       "     '\\nThe conclusion that cathode rays consist of negatively charged\\nparticles does not follow logically from the reported experimental\\nresults, nor could Thomson draw on any relevant statistical data. That\\nnevertheless he could “see no escape from the conclusion”\\nis, we may safely assume, because the conclusion is the best—in\\nthis case presumably even the only plausible—explanation of his\\nresults that he could think of.',\n",
       "     '\\nMany other examples of scientific uses of abduction have been\\ndiscussed in the literature; see, for instance, Harré 1986,\\n1988 and Lipton 1991, 2004. Abduction is also said to be the\\npredominant mode of reasoning in medical diagnosis: physicians tend to\\ngo for the hypothesis that best explains the patient’s symptoms\\n(see Josephson and Josephson (eds.) 1994, 9–12; see also\\nDragulinescu 2016 on abductive reasoning in the context of\\nmedicine).',\n",
       "     '\\nLast but not least, abduction plays a central role in some important\\nphilosophical debates. See Shalkowski 2010 on the place of abduction\\nin metaphysics (also Bigelow 2010), Krzyżanowska, Wenmackers, and\\nDouven 2014 and Douven 2016a for a possible role of\\nabduction in the semantics of conditionals, and Williamson\\n2017 for an application of abduction in the philosophy of logic.\\nArguably, however, abduction plays its most notable philosophical role\\nin epistemology and in the philosophy of science, where it is\\nfrequently invoked in objections to so-called underdetermination\\narguments. Underdetermination arguments generally start from the\\npremise that a number of given hypotheses are empirically equivalent,\\nwhich their authors take to mean that the evidence—indeed, any\\nevidence we might ever come to possess—is unable to favor one of\\nthem over the others. From this, we are supposed to conclude that one\\ncan never be warranted in believing any particular one of the\\nhypotheses. (This is rough, but it will do for present purposes; see\\nDouven 2008 and Stanford 2009, for more detailed accounts of\\nunderdetermination arguments.) A famous instance of this type of\\nargument is the Cartesian argument for global skepticism, according to\\nwhich the hypothesis that reality is more or less the way we\\ncustomarily deem it to be is empirically equivalent to a variety of\\nso-called skeptical hypotheses (such as that we are beguiled by an\\nevil demon, or that we are brains in a vat, connected to a\\nsupercomputer; see, e.g., Folina 2016). Similar arguments have been\\ngiven in support of scientific antirealism, according to which it will\\nnever be warranted for us to choose between empirically equivalent\\nrivals concerning what underlies the observable part of reality (van\\nFraassen 1980).',\n",
       "     '\\nResponses to these arguments typically point to the fact that the\\nnotion of empirical equivalence at play unduly neglects explanatory\\nconsiderations, for instance, by defining the notion strictly in terms\\nof hypotheses’ making the same predictions. Those responding\\nthen argue that even if some hypotheses make exactly the same\\npredictions, one of them may still be a better explanation of the\\nphenomena predicted. Thus, if explanatory considerations have a role\\nin determining which inferences we are licensed to make—as\\naccording to defenders of abduction they have—then we might\\nstill be warranted in believing in the truth (or probable truth, or\\nsome such, depending—as will be seen below—on the version\\nof abduction one assumes) of one of a number of hypotheses that all\\nmake the same predictions. Following Bertrand Russell (1912, Ch. 2),\\nmany epistemologists have invoked abduction in arguing against\\nCartesian skepticism, their key claim being that even though, by\\nconstruction, the skeptical hypotheses make the same predictions as\\nthe hypothesis that reality is more or less the way we ordinarily take\\nit to be, they are not equally good explanations of what they predict;\\nin particular, the skeptical hypotheses have been said to be\\nconsiderably less simple than the “ordinary world”\\nhypothesis. See, among many others, Harman 1973 (Chs. 8 and 11),\\nGoldman 1988 (205), Moser 1989 (161), and Vogel 1990, 2005; see\\nPargetter 1984 for an abductive response specifically to skepticism\\nregarding other minds. Similarly, philosophers of science have argued\\nthat we are warranted to believe in Special Relativity Theory as\\nopposed to Lorentz’s version of the æther theory. For even\\nthough these theories make the same predictions, the former is\\nexplanatorily superior to the latter. (Most arguments that have been\\ngiven for this claim come down to the contention that Special\\nRelativity Theory is ontologically more parsimonious than its\\ncompetitor, which postulates the existence of an æther. See\\nJanssen 2002 for an excellent discussion of the various reasons\\nphilosophers of science have adduced for preferring Einstein’s\\ntheory to Lorentz’s.)'],\n",
       "    'subsection_title': '1.2 The ubiquity of abduction'}]},\n",
       " {'main_content': ['\\nPrecise statements of what abduction amounts to are rare in the\\nliterature on abduction. (Peirce did propose an at least fairly\\nprecise statement; but, as explained in the supplement to this entry,\\nit does not capture what most nowadays understand by abduction.) Its\\ncore idea is often said to be that explanatory considerations have\\nconfirmation-theoretic import, or that explanatory success is a (not\\nnecessarily unfailing) mark of truth. Clearly, however, these\\nformulations are slogans at best, and it takes little effort to see\\nthat they can be cashed out in a great variety of prima facie\\nplausible ways. Here we will consider a number of such possible\\nexplications, starting with what one might term the “textbook\\nversion of abduction,” which, as will be seen, is manifestly\\ndefective, and then going on to consider various possible refinements\\nof it. What those versions have in\\ncommon—unsurprisingly—is that they are all inference\\nrules, requiring premises encompassing explanatory considerations and\\nyielding a conclusion that makes some statement about the truth of a\\nhypothesis. The differences concern the premises that are required, or\\nwhat exactly we are allowed to infer from them (or both).',\n",
       "   '\\nIn textbooks on epistemology or the philosophy of science, one often\\nencounters something like the following as a formulation of\\nabduction:',\n",
       "   '\\nAn observation that is frequently made about this rule, and that\\npoints to a potential problem for it, is that it presupposes the\\nnotions of candidate explanation and best explanation, neither of\\nwhich has a straightforward interpretation. While some still hope that\\nthe former can be spelled out in purely logical, or at least purely\\nformal, terms, it is often said that the latter must appeal to the\\nso-called theoretical virtues, like simplicity, generality, and\\ncoherence with well-established theories; the best explanation would\\nthen be the hypothesis which, on balance, does best with respect to\\nthese virtues. (See, for instance, Thagard 1978 and McMullin 1996.)\\nThe problem is that none of the said virtues is presently particularly\\nwell understood. (Giere, in Callebaut (ed.) 1993 (232), even makes the\\nradical claim that the theoretical virtues lack real content and play\\nno more than a rhetorical role in science. In view of recent formal\\nwork both on simplicity and on coherence—for instance, Forster\\nand Sober 1994, Li and Vitanyi 1997, and Sober 2015, on simplicity and\\nBovens and Hartmann 2003 and Olsson 2005, on coherence—the first\\npart of this claim has become hard to maintain; also, Schupbach and\\nSprenger (2011) present an account of explanatory goodness directly in\\nprobabilistic terms. Psychological evidence casts doubt on the second\\npart of the claim; see, for instance, Lombrozo 2007, on the role of\\nsimplicity in people’s assessments of explanatory goodness and\\nKoslowski et al. 2008, on the role of coherence with\\nbackground knowledge in those assessments.)',\n",
       "   '\\nFurthermore, many of those who think ABD1 is headed along the right\\nlines believe that it is too strong. Some think that abduction\\nwarrants an inference only to the probable truth of the best\\nexplanation, others that it warrants an inference only to the\\napproximate truth of the best explanation, and still others\\nthat it warrants an inference only to the probable\\napproximate truth.',\n",
       "   '\\nThe real problem with ABD1 runs deeper than this, however. Because\\nabduction is ampliative—as explained earlier—it will not\\nbe a sound rule of inference in the strict logical sense, however\\nabduction is explicated exactly. It can still be reliable in\\nthat it mostly leads to a true conclusion whenever the premises are\\ntrue. An obvious necessary condition for ABD1 to be reliable in this\\nsense is that, mostly, when it is true that H best\\nexplains E, and E is true, then H is true as well\\n(or H is approximately true, or probably true, or probably\\napproximately true). But this would not be enough for ABD1 to\\nbe reliable. For ABD1 takes as its premise only that some hypothesis\\nis the best explanation of the evidence as compared to other\\nhypotheses in a given set. Thus, if the rule is to be\\nreliable, it must hold that, at least typically, the best explanation\\nrelative to the set of hypotheses that we consider would also come out\\nas being best in comparison with any other hypotheses that we might\\nhave conceived (but for lack of time or ingenuity, or for some other\\nreason, did not conceive). In other words, it must hold that at least\\ntypically the absolutely best explanation of the evidence is\\nto be found among the candidate explanations we have come up with, for\\nelse ABD1 may well lead us to believe “the best of a bad\\nlot” (van Fraassen 1989, 143).',\n",
       "   '\\nHow reasonable is it to suppose that this extra requirement is usually\\nfulfilled? Not at all, presumably. To believe otherwise, we must\\nassume some sort of privilege on our part to the effect that when we\\nconsider possible explanations of the data, we are somehow predisposed\\nto hit, inter alia, upon the absolutely best explanation of those\\ndata. After all, hardly ever will we have considered, or will it even\\nbe possible to consider, all potential explanations. As van\\nFraassen (1989, 144) points out, it is a priori rather\\nimplausible to hold that we are thus privileged.',\n",
       "   '\\nIn response to this, one might argue that the challenge to show that\\nthe best explanation is always or mostly among the hypotheses\\nconsidered can be met without having to assume some form of privilege\\n(see Schupbach 2014 for a different response, and see Dellsén\\n2017 for discussion). For given the hypotheses we have managed to come\\nup with, we can always generate a set of hypotheses which jointly\\nexhaust logical space. Suppose\\nH1,…,Hn are the\\ncandidate explanations we have so far been able to conceive. Then\\nsimply define Hn+1 := ¬H1\\n∧ … ∧ ¬Hn and add this new\\nhypothesis as a further candidate explanation to the ones we already\\nhave. Obviously, the set\\n{H1,…,Hn+1} is exhaustive,\\nin that one of its elements must be true. Following this in itself\\nsimple procedure would seem enough to make sure that we never miss out\\non the absolutely best explanation. (See Lipton 1993, for a proposal\\nalong these lines.)',\n",
       "   '\\nAlas, there is a catch. For even though there may be many hypotheses\\nHj that imply Hn+1 and, had\\nthey been formulated, would have been evaluated as being a better\\nexplanation for the data than the best explanation among the candidate\\nexplanations we started out with, Hn+1 itself will\\nin general be hardly informative; in fact, in general it will not even\\nbe clear what its empirical consequences are. Suppose, for instance,\\nwe have as competing explanations Special Relativity Theory and\\nLorentz’s version of the æther theory. Then, following the\\nabove proposal, we may add to our candidate explanations that neither\\nof these two theories is true. But surely this further hypothesis will\\nbe ranked quite low qua explanation—if it will be\\nranked at all, which seems doubtful, given that it is wholly unclear\\nwhat its empirical consequences are. This is not to say that the\\nsuggested procedure may never work. The point is that in general it\\nwill give little assurance that the best explanation is among the\\ncandidate explanations we consider.',\n",
       "   '\\nA more promising response to the above “argument of the bad\\nlot” begins with the observation that the argument capitalizes\\non a peculiar asymmetry or incongruence in ABD1. The rule gives\\nlicense to an absolute conclusion—that a given hypothesis is\\ntrue—on the basis of a comparative premise, namely, that that\\nparticular hypothesis is the best explanation of the evidence relative\\nto the other hypotheses available (see Kuipers 2000, 171). This\\nincongruence is not avoided by replacing “truth” with\\n“probable truth” or “approximate truth.” In\\norder to avoid it, one has two general options.',\n",
       "   '\\nThe first option is to modify the rule so as to have it require an\\nabsolute premise. For instance, following Alan Musgrave (1988) or\\nPeter Lipton (1993), one may require the hypothesis whose truth is\\ninferred to be not only the best of the available potential\\nexplanations, but also to be satisfactory (Musgrave) or\\ngood enough (Lipton), yielding the following variant of\\nABD1:',\n",
       "   '\\nNeedless to say, ABD2 needs supplementing by a criterion for the\\nsatisfactoriness of explanations, or their being good enough, which,\\nhowever, we are still lacking.',\n",
       "   '\\nSecondly, one can formulate a symmetric or congruous version of\\nabduction by having it sanction, given a comparative premise, only a\\ncomparative conclusion; this option, too, can in turn be realized in\\nmore than one way. Here is one way to do it, which has been proposed\\nand defended in the work of Theo Kuipers (e.g., Kuipers 1984, 1992,\\n2000).',\n",
       "   '\\nClearly, ABD3 requires an account of closeness to the truth, but many\\nsuch accounts are on offer today (see, e.g., Niiniluoto 1998).',\n",
       "   '\\nOne noteworthy feature of the congruous versions of abduction\\nconsidered here is that they do not rely on the assumption of an\\nimplausible privilege on the reasoner’s part that, we saw, ABD1\\nimplicitly relies on. Another is that if one can be certain that,\\nhowever many candidate explanations for the data one may have missed,\\nnone equals the best of those one has thought of, then the\\ncongruous versions license exactly the same inference as ABD1 does\\n(supposing that one would not be certain that no potential explanation\\nis as good as the best explanation one has thought of if the latter is\\nnot even satisfactory or sufficiently good).',\n",
       "   '\\nAs mentioned, there is widespread agreement that people frequently\\nrely on abductive reasoning. Which of the above rules exactly\\nis it that people rely on? Or might it be still some further rule that\\nthey rely on? Or might they in some contexts rely on one version, and\\nin others on another (Douven 2017, forthcoming)? Philosophical\\nargumentation is unable to answer these questions. In recent years,\\nexperimental psychologists have started paying attention to the role\\nhumans give to explanatory considerations in reasoning. For instance,\\nTania Lombrozo and Nicholas Gwynne (2014) report experiments showing\\nthat how a property of a given class of things is explained\\nto us—whether mechanistically, by reference to parts and\\nprocesses, or functionally, by reference to functions and\\npurposes—matters to how likely we are to generalise that\\nproperty to other classes of things (see also Sloman 1994 and Williams\\nand Lombrozo 2010). And Igor Douven and Jonah Schupbach (2015a),\\n(2015b) present experimental evidence to the effect that\\npeople’s probability updates tend to be influenced by\\nexplanatory considerations in ways that makes them deviate from\\nstrictly Bayesian updates (see below). Douven (2016b) shows that, in\\nthe aforementioned experiments, participants who gave more weight to\\nexplanatory considerations tended to be more accurate, as determined\\nin terms of a standard scoring rule. (See Lombrozo 2012 and 2016 for\\nuseful overviews of recent experimental work relevant to explanation\\nand inference.) Douven and Patricia Mirabile (2018) found some\\nevidence indicating that people rely on something like ABD2, at least\\nin some contexts, but for the most part, empirical work on the\\nabove-mentioned questions is lacking.',\n",
       "   '\\nWith respect to the normative question of which of the previously\\nstated rules we ought to rely on (if we ought to rely on any\\nform of abduction), where philosophical argumentation should be able\\nto help, the situation is hardly any better. In view of the argument\\nof the bad lot, ABD1 does not look very good. Other arguments against\\nabduction are claimed to be independent of the exact explication of\\nthe rule; below, these arguments will be found wanting. On the other\\nhand, arguments that have been given in favor of abduction—some\\nof which will also be discussed below—do not discern between\\nspecific versions. So, supposing people do indeed commonly rely on\\nabduction, it must be considered an open question as to which\\nversion(s) of abduction they rely on. Equally, supposing it is\\nrational for people to rely on abduction, it must be considered an\\nopen question as to which version, or perhaps versions, of abduction\\nthey ought to, or are at least permitted to, rely on.'],\n",
       "  'section_title': '2. Explicating Abduction',\n",
       "  'subsections': []},\n",
       " {'main_content': ['\\nEven if it is true that we routinely rely on abductive reasoning, it\\nmay still be asked whether this practice is rational. For instance,\\nexperimental studies have shown that when people are able to think of\\nan explanation for some possible event, they tend to overestimate the\\nlikelihood that this event will actually occur. (See Koehler 1991, for\\na survey of some of these studies; see also Brem and Rips 2000.) More\\ntelling still, Lombrozo (2007) shows that, in some situations, people\\ntend to grossly overrate the probability of simpler explanations\\ncompared to more complicated ones. Although these studies are not\\ndirectly concerned with abduction in any of the forms discussed so\\nfar, they nevertheless suggest that taking into account explanatory\\nconsiderations in one’s reasoning may not always be for the\\nbetter. (It is to be noted that Lombrozo’s experiments\\nare directly concerned with some proposals that have been\\nmade for explicating abduction in a Bayesian framework; see Section\\n4.) However, the most pertinent remarks about the normative status of\\nabduction are so far to be found in the philosophical literature. This\\nsection discusses the main criticisms that have been levelled against\\nabduction, as well as the strongest arguments that have been given in\\nits defense.'],\n",
       "  'section_title': '3. The Status of Abduction',\n",
       "  'subsections': [{'content': ['\\nWe have already encountered the so-called argument of the bad lot,\\nwhich, we saw, is valid as a criticism of ABD1 but powerless against\\nvarious (what we called) congruous rules of abduction. We here\\nconsider two objections that are meant to be more general. The first\\neven purports to challenge the core idea underlying abduction; the\\nsecond is not quite as general, but it is still meant to undermine a\\nbroad class of candidate explications of abduction. Both objections\\nare due to Bas van Fraassen.',\n",
       "     '\\nThe first objection has as a premise that it is part of the meaning of\\n“explanation” that if one theory is more explanatory than\\nanother, the former must be more informative than the latter (see,\\ne.g., van Fraassen 1983, Sect. 2). The alleged problem then is that it\\nis “an elementary logical point that a more informative theory\\ncannot be more likely to be true [and thus] attempts to describe\\ninductive or evidential support through features that require\\ninformation (such as ‘Inference to the Best Explanation’)\\nmust either contradict themselves or equivocate” (van Fraassen\\n1989, 192). The elementary logical point is supposed to be “most\\n[obvious] … in the paradigm case in which one theory is an\\nextension of another: clearly the extension has more ways of being\\nfalse” (van Fraassen 1985, 280).',\n",
       "     '\\nIt is important to note, however, that in any other kind of case than\\nthe “paradigm” one, the putative elementary point is not\\nobvious at all. For instance, it is entirely unclear in what sense\\nSpecial Relativity Theory “has more ways of being false”\\nthan Lorentz’s version of the æther theory, given that\\nthey make the same predictions. And yet the former is generally\\nregarded as being superior, qua explanation, to the latter.\\n(If van Fraassen were to object that the former is not really more\\ninformative than the latter, or at any rate not more informative in\\nthe appropriate sense—whatever that is—then we should\\ncertainly refuse to grant the premise that in order to be more\\nexplanatory a theory must be more informative.)',\n",
       "     '\\nThe second objection, proffered in van Fraassen 1989 (Ch. 6), is\\nlevelled at probabilistic versions of abduction. The objection is that\\nsuch rules must either amount to Bayes’ rule, and thus be\\nredundant, or be at variance with it but then, on the grounds of\\nLewis’ dynamic Dutch book argument (as reported in Teller 1973),\\nbe probabilistically incoherent, meaning that they may lead one to\\nassess as fair a number of bets which together ensure a financial\\nloss, come what may; and, van Fraassen argues, it would be irrational\\nto follow a rule that has this feature.',\n",
       "     '\\nHowever, this objection fares no better than the first. For one thing,\\nas Patrick Maher (1992) and Brian Skyrms (1993) have pointed out, a\\nloss in one respect may be outweighed by a benefit in another. It\\nmight be, for instance, that some probabilistic version of abduction\\ndoes much better, at least in our world, than Bayes’ rule, in\\nthat, on average, it approaches the truth faster in the sense that it\\nis faster in assigning a high probability (understood as probability\\nabove a certain threshold value) to the true hypothesis (see Douven\\n2013, 2020, and Douven and Wenmackers 2017; see Climenhaga\\n2017 for discussion). If it does, then following that rule\\ninstead of Bayes’ rule may have advantages which perhaps are not\\nso readily expressed in terms of money yet which should arguably be\\ntaken into account when deciding which rule to go by. It is, in short,\\nnot so clear whether following a probabilistically incoherent rule\\nmust be irrational.',\n",
       "     '\\nFor another thing, Douven (1999) argues that the question of whether a\\nprobabilistic rule is coherent is not one that can be settled\\nindependently of considering which other epistemic and\\ndecision-theoretic rules are deployed along with it; coherence should\\nbe understood as a property of packages of both epistemic and\\ndecision-theoretic rules, not of epistemic rules (such as\\nprobabilistic rules for belief change) in isolation. In the same\\npaper, a coherent package of rules is described which includes a\\nprobabilistic version of abduction. (See Kvanvig 1994, Harman 1997,\\nLeplin 1997, Niiniluoto 1999, and Okasha 2000, for different responses\\nto van Fraassen’s critique of probabilistic versions of\\nabduction.)'],\n",
       "    'subsection_title': '3.1 Criticisms'},\n",
       "   {'content': ['\\nHardly anyone nowadays would want to subscribe to a conception of\\ntruth that posits a necessary connection between explanatory force and\\ntruth—for instance, because it stipulates explanatory\\nsuperiority to be necessary for truth. As a result, a priori defenses\\nof abduction seem out of the question. Indeed, all defenses that have\\nbeen given so far are of an empirical nature in that they appeal to\\ndata that supposedly support the claim that (in some form) abduction\\nis a reliable rule of inference.',\n",
       "     '\\nThe best-known argument of this sort was developed by Richard Boyd in\\nthe 1980s (see Boyd 1981, 1984, 1985). It starts by underlining the\\ntheory-dependency of scientific methodology, which comprises methods\\nfor designing experiments, for assessing data, for choosing between\\nrival hypotheses, and so on. For instance, in considering possible\\nconfounding factors from which an experimental setup has to be\\nshielded, scientists draw heavily on already accepted theories. The\\nargument next calls attention to the apparent reliability of this\\nmethodology, which, after all, has yielded, and continues to yield,\\nimpressively accurate theories. In particular, by relying on this\\nmethodology, scientists have for some time now been able to find ever\\nmore instrumentally adequate theories. Boyd then argues that the\\nreliability of scientific methodology is best explained by assuming\\nthat the theories on which it relies are at least approximately true.\\nFrom this and from the fact that these theories were mostly arrived at\\nby abductive reasoning, he concludes that abduction must be a reliable\\nrule of inference.',\n",
       "     '\\nCritics have accused this argument of being circular. Specifically, it\\nhas been said that the argument rests on a premise—that\\nscientific methodology is informed by approximately true background\\ntheories—which in turn rests on an inference to the best\\nexplanation for its plausibility. And the reliability of this type of\\ninference is precisely what is at stake. (See, for instance, Laudan\\n1981 and Fine 1984.)',\n",
       "     '\\nTo this, Stathis Psillos (1999, Ch. 4) has responded by invoking a\\ndistinction credited to Richard Braithwaite, to wit, the distinction\\nbetween premise-circularity and rule-circularity. An argument is\\npremise-circular if its conclusion is amongst its premises. A\\nrule-circular argument, by contrast, is an argument of which the\\nconclusion asserts something about an inferential rule that is used in\\nthe very same argument. As Psillos urges, Boyd’s argument is\\nrule-circular, but not premise-circular, and rule-circular arguments,\\nPsillos contends, need not be viciously circular (even though\\na premise-circular argument is always viciously circular). To be more\\nprecise, in his view, an argument for the reliability of a given rule\\nR that essentially relies on R as an inferential\\nprinciple is not vicious, provided that the use of R does not\\nguarantee a positive conclusion about R’s reliability.\\nPsillos claims that in Boyd’s argument, this proviso is met. For\\nwhile Boyd concludes that the background theories on which scientific\\nmethodology relies are approximately true on the basis of an abductive\\nstep, the use of abduction itself does not guarantee the truth of his\\nconclusion. After all, granting the use of abduction does nothing to\\nensure that the best explanation of the success of scientific\\nmethodology is the approximate truth of the relevant background\\ntheories. Thus, Psillos concludes, Boyd’s argument still\\nstands.',\n",
       "     '\\nEven if the use of abduction in Boyd’s argument might have led\\nto the conclusion that abduction is not reliable, one may\\nstill have worries about the argument’s being rule-circular. For\\nsuppose that some scientific community relied not on abduction but on\\na rule that we may dub “Inference to the Worst\\nExplanation” (IWE), a rule that sanctions inferring to the\\nworst explanation of the available data. We may safely assume\\nthat the use of this rule mostly would lead to the adoption of very\\nunsuccessful theories. Nevertheless, the said community might justify\\nits use of IWE by dint of the following reasoning: “Scientific\\ntheories tend to be hugely unsuccessful. These theories were arrived\\nat by application of IWE. That IWE is a reliable rule of\\ninference—that is, a rule of inference mostly leading from true\\npremises to true conclusions—is surely the worst explanation of\\nthe fact that our theories are so unsuccessful. Hence, by application\\nof IWE, we may conclude that IWE is a reliable rule of\\ninference.” While this would be an utterly absurd conclusion,\\nthe argument leading up to it cannot be convicted of being viciously\\ncircular anymore than Boyd’s argument for the reliability of\\nabduction can (if Psillos is right). It would appear, then, that there\\nmust be something else amiss with rule-circularity.',\n",
       "     '\\nIt is fair to note that for Psillos, the fact that a rule-circular\\nargument does not guarantee a positive conclusion about the rule at\\nissue is not sufficient for such an argument to be valid. A further\\nnecessary condition is “that one should not have reason to doubt\\nthe reliability of the rule—that there is nothing currently\\navailable which can make one distrust the rule” (Psillos 1999,\\n85). And there is plenty of reason to doubt the reliability of IWE; in\\nfact, the above argument supposes that it is unreliable. Two\\nquestions arise, however. First, why should we accept the additional\\ncondition? Second, do we really have no reason to doubt the\\nreliability of abduction? Certainly some of the abductive\\ninferences we make lead us to accept falsehoods. How many\\nfalsehoods may we accept on the basis of abduction before we can\\nlegitimately begin to distrust this rule? No clear answers have been\\ngiven to these questions.',\n",
       "     '\\nBe this as it may, even if rule-circularity is neither vicious nor\\notherwise problematic, one may still wonder how Boyd’s argument\\nis to convert a critic of abduction, given that it relies on\\nabduction. But Psillos makes it clear that the point of philosophical\\nargumentation is not always, and in any case need not be, to convince\\nan opponent of one’s position. Sometimes the point is, more\\nmodestly, to assure or reassure oneself that the position one\\nendorses, or is tempted to endorse, is correct. In the case at hand,\\nwe need not think of Boyd’s argument as an attempt to convince\\nthe opponent of abduction of its reliability. Rather, it may be\\nthought of as justifying the rule from within the perspective of\\nsomeone who is already sympathetic towards abduction; see Psillos 1999\\n(89).',\n",
       "     '\\nThere have also been attempts to argue for abduction in a more\\nstraightforward fashion, to wit, via enumerative induction. The common\\nidea of these attempts is that every newly recorded successful\\napplication of abduction—like the discovery of Neptune, whose\\nexistence had been postulated on explanatory grounds (see Section\\n1.2)—adds further support to the hypothesis that abduction is a\\nreliable rule of inference, in the way in which every newly observed\\nblack raven adds some support to the hypothesis that all ravens are\\nblack. Because it does not involve abductive reasoning, this type of\\nargument is more likely to also appeal to disbelievers in abduction.\\nSee Harré 1986, 1988, Bird 1998 (160), Kitcher 2001, and Douven\\n2002 for suggestions along these lines.'],\n",
       "    'subsection_title': '3.2 Defenses'}]},\n",
       " {'main_content': ['\\nIn the past decade, Bayesian confirmation theory has firmly\\nestablished itself as the dominant view on confirmation; currently one\\ncannot very well discuss a confirmation-theoretic issue without making\\nclear whether, and if so why, one’s position on that issue\\ndeviates from standard Bayesian thinking. Abduction, in whichever\\nversion, assigns a confirmation-theoretic role to explanation:\\nexplanatory considerations contribute to making some hypotheses more\\ncredible, and others less so. By contrast, Bayesian confirmation\\ntheory makes no reference at all to the concept of explanation. Does\\nthis imply that abduction is at loggerheads with the prevailing\\ndoctrine in confirmation theory? Several authors have recently argued\\nthat not only is abduction compatible with Bayesianism, it is a\\nmuch-needed supplement to it. The so far fullest defense of this view\\nhas been given by Lipton (2004, Ch. 7); as he puts it, Bayesians\\nshould also be “explanationists” (his name for the\\nadvocates of abduction). (For other defenses, see Okasha 2000, McGrew\\n2003, Weisberg 2009, and Poston 2014, Ch. 7; for discussion, see Roche\\nand Sober 2013, 2014, and McCain and Poston 2014.)',\n",
       "   '\\nThis requires some clarification. For what could it mean for a\\nBayesian to be an explanationist? In order to apply Bayes’ rule\\nand determine the probability for H after learning E,\\nthe Bayesian agent will have to determine the probability of H\\nconditional on E. For that, he needs to assign unconditional\\nprobabilities to H and E as well as a probability to\\nE given H; the former two are mostly called “prior\\nprobabilities” (or just “priors”) of, respectively,\\nH and E, the latter the “likelihood” of\\nH on E. (This is the official Bayesian story. Not all of\\nthose who sympathize with Bayesianism adhere to that story. For\\ninstance, according to some it is more reasonable to think that\\nconditional probabilities are basic and that we derive unconditional\\nprobabilities from them; see Hájek 2003, and references\\ntherein.) How is the Bayesian to determine these values? As is well\\nknown, probability theory gives us more probabilities once we have\\nsome; it does not give us probabilities from scratch. Of course, when\\nH implies E or the negation of E, or when\\nH is a statistical hypothesis that bestows a certain chance on\\nE, then the likelihood follows “analytically.”\\n(This claim assumes some version of Lewis’ (1980) Principal\\nPrinciple, and it is controversial whether or not this principle is\\nanalytic; hence the scare quotes.) But this is not always the case,\\nand even if it were, there would still be the question of how to\\ndetermine the priors. This is where, according to Lipton, abduction\\ncomes in. In his proposal, Bayesians ought to determine their prior\\nprobabilities and, if applicable, likelihoods on the basis of\\nexplanatory considerations.',\n",
       "   '\\nExactly how are explanatory considerations to guide one’s choice\\nof priors? The answer to this question is not as simple as one might\\nat first think. Suppose you are considering what priors to assign to a\\ncollection of rival hypotheses and you wish to follow Lipton’s\\nsuggestion. How are you to do this? An obvious—though still\\nsomewhat vague—answer may seem to go like this: Whatever exact\\npriors you are going to assign, you should assign a higher one to the\\nhypothesis that explains the available data best than to any of its\\nrivals (provided there is a best explanation). Note, though, that your\\nneighbor, who is a Bayesian but thinks confirmation has nothing to do\\nwith explanation, may well assign a prior to the best explanation that\\nis even higher than the one you assign to that hypothesis. In fact,\\nhis priors for best explanations may even be consistently higher than\\nyours, not because in his view explanation is somehow related to\\nconfirmation—it is not, he thinks—but, well, just because.\\nIn this context, “just because” is a perfectly legitimate\\nreason, because any reason for fixing one’s priors counts as\\nlegitimate by Bayesian standards. According to mainstream Bayesian\\nepistemology, priors (and sometimes likelihoods) are up for grabs,\\nmeaning that one assignment of priors is as good as another, provided\\nboth are coherent (that is, they obey the axioms of probability\\ntheory). Lipton’s recommendation to the Bayesian to be an\\nexplanationist is meant to be entirely general. But what should your\\nneighbor do differently if he wants to follow the recommendation?\\nShould he give the same prior to any best explanation that you, his\\nexplanationist neighbor, give to it, that is, lower his\\npriors for best explanations? Or rather should he give even\\nhigher priors to best explanations than those he already\\ngives?',\n",
       "   '\\nPerhaps Lipton’s proposal is not intended to address those who\\nalready assign highest priors to best explanations, even if they do so\\non grounds that have nothing to do with explanation. The idea might be\\nthat, as long as one does assign highest priors to those hypotheses,\\neverything is fine, or at least finer than if one does not do so,\\nregardless of one’s reasons for assigning those priors. The\\nanswer to the question of how explanatory considerations are to guide\\none’s choice of priors would then presumably be that one ought\\nto assign a higher prior to the best explanation than to its rivals,\\nif this is not what one already does. If it is, one should just keep\\ndoing what one is doing.',\n",
       "   '\\n(As an aside, it should be noticed that, according to standard\\nBayesian usage, the term “priors” does not necessarily\\nrefer to the degrees of belief a person assigns before the receipt of\\nany data. If there are already data in, then, clearly, one\\nmay assign higher priors to hypotheses that best explain the\\nthen-available data. However, one can sensibly speak of “best\\nexplanations” even before any data are known. For example, one\\nhypothesis may be judged to be a better explanation than any of its\\nrivals because the former requires less complicated mathematics, or\\nbecause it is stated in terms of familiar concepts only, which is not\\ntrue of the others. More generally, such judgments may be based on\\nwhat Kosso (1992, 30) calls internal features of hypotheses\\nor theories, that is, features that “can be evaluated without\\nhaving to observe the world.”)',\n",
       "   '\\nA more interesting answer to the above question of how explanation is\\nto guide one’s choice of priors has been given by Jonathan\\nWeisberg (2009). We said that mainstream Bayesians regard one\\nassignment of prior probabilities as being as good as any other.\\nSo-called objective Bayesians do not do so, however. These Bayesians\\nthink priors must obey principles beyond the probability axioms in\\norder to be admissible. Objective Bayesians are divided among\\nthemselves over exactly which further principles are to be obeyed, but\\nat least for a while they agreed that the Principle of Indifference is\\namong them. Roughly stated, this principle counsels that, absent a\\nreason to the contrary, we give equal priors to competing hypotheses.\\nAs is well known, however, in its original form the Principle of\\nIndifference may lead to inconsistent assignments of probabilities and\\nso can hardly be advertised as a principle of rationality. The problem\\nis that there are typically various ways to partition logical space\\nthat appear plausible given the problem at hand, and that not all of\\nthem lead to the same prior probability assignment, even assuming the\\nPrinciple of Indifference. Weisberg’s proposal amounts to the\\nclaim that explanatory considerations may favor some of those\\npartitions over others. Perhaps we will not always end up with a\\nunique partition to which the Principle of Indifference is to be\\napplied, but it would already be progress if we ended up with only a\\nhandful of partitions. For we could then still arrive in a motivated\\nway at our prior probabilities, by proceeding in two steps, namely, by\\nfirst applying the Principle of Indifference to the partitions\\nseparately, thereby possibly obtaining different assignments of\\npriors, and by then taking a weighted average of the thus obtained\\npriors, where the weights, too, are to depend on explanatory\\nconsiderations. The result would again be a probability\\nfunction—the uniquely correct prior probability function,\\naccording to Weisberg.',\n",
       "   '\\nThe proposal is intriguing as far as it goes but, as Weisberg admits,\\nin its current form, it does not go very far. For one thing, it is\\nunclear how exactly explanatory considerations are to determine the\\nweights required for the second step of the proposal. For another, it\\nmay be idle to hope that taking explanatory considerations into\\naccount will in general leave us with a manageable set of partitions,\\nor that, even if it does, this will not be due merely to the fact that\\nwe are overlooking a great many prima facie plausible ways of\\npartitioning logical space to begin with. (The latter point echoes the\\nargument of the bad lot, of course.)',\n",
       "   '\\nAnother suggestion about the connection between abduction and Bayesian\\nreasoning—to be found in Okasha 2000, McGrew 2003, Lipton 2004\\n(Ch. 7), and Dellsén 2018—is that the explanatory\\nconsiderations may serve as a heuristic to determine, even if only\\nroughly, priors and likelihoods in cases in which we would otherwise\\nbe clueless and could do no better than guessing. This suggestion is\\nsensitive to the well-recognized fact that we are not always able to\\nassign a prior to every hypothesis of interest, or to say how probable\\na given piece of evidence is conditional on a given hypothesis.\\nConsideration of that hypothesis’ explanatory power might then\\nhelp us to figure out, if perhaps only within certain bounds, what\\nprior to assign to it, or what likelihood to assign to it on the given\\nevidence.',\n",
       "   '\\nBayesians, especially the more modest ones, might want to retort that\\nthe Bayesian procedure is to be followed if, and only if, either (a)\\npriors and likelihoods can be determined with some precision and\\nobjectivity, or (b) likelihoods can be determined with some precision\\nand priors can be expected to “wash out” as more and more\\nevidence accumulates, or (c) priors and likelihoods can both be\\nexpected to wash out. In the remaining cases—they might\\nsay—we should simply refrain from applying Bayesian reasoning. A\\nfortiori, then, there is no need for an abduction-enhanced Bayesianism\\nin these cases. And some incontrovertible mathematical results\\nindicate that, in the cases that fall under (a), (b), or (c), our\\nprobabilities will converge to the truth anyhow. Consequently, in\\nthose cases there is no need for the kind of abductive heuristics that\\nthe above-mentioned authors suggest, either. (Weisberg 2009, Sect.\\n3.2, raises similar concerns.)',\n",
       "   '\\nPsillos (2000) proposes yet another way in which abduction might\\nsupplement Bayesian confirmation theory, one that is very much in the\\nspirit of Peirce’s conception of abduction. The idea is that\\nabduction may assist us in selecting plausible candidates for testing,\\nwhere the actual testing then is to follow Bayesian lines. However,\\nPsillos concedes (2004) that this proposal assigns a role to abduction\\nthat will strike committed explanationists as being too limited.',\n",
       "   '\\nFinally, a possibility that has so far not been considered in the\\nliterature is that abduction and Bayesianism do not so much work in\\ntandem—as they do on the above proposals—as operate in\\ndifferent modes of reasoning; the Bayesian and the explanationist are\\ncharacters that feature in different plays, so to speak. It is widely\\naccepted that sometimes we speak and think about our beliefs in a\\ncategorical manner, while at other times we speak and think about them\\nin a graded way. It is far from clear how these different ways of\\nspeaking and thinking about beliefs—the epistemology of belief\\nand the epistemology of degrees of belief, to use Richard\\nFoley’s (1992) terminology—are related to one another. In\\nfact, it is an open question whether there is any straightforward\\nconnection between the two, or even whether there is a connection at\\nall. Be that as it may, given that the distinction is undeniable, it\\nis a plausible suggestion that, just as there are different ways of\\ntalking and thinking about beliefs, there are different ways of\\ntalking and thinking about the revision of beliefs. In\\nparticular, abduction could well have its home in the epistemology of\\nbelief, and be called upon whenever we reason about our beliefs in a\\ncategorical mode, while at the same time Bayes’ rule could have\\nits home in the epistemology of degrees of belief. Hard-nosed\\nBayesians may insist that whatever reasoning goes on in the\\ncategorical mode must eventually be justifiable in Bayesian terms, but\\nthis presupposes the existence of bridge principles connecting the\\nepistemology of belief with the epistemology of degrees of\\nbelief—and, as mentioned, whether such principles exist is\\npresently unclear.'],\n",
       "  'section_title': '4. Abduction versus Bayesian Confirmation Theory',\n",
       "  'subsections': []}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to cat everything together as a single string\n",
    "\n",
    "def cat_text(list_of_dicts):\n",
    "    text = \"\"\n",
    "    # iterate over the list, if you find dict, iterate over the values and get the text, otherwise just get the text, do it recursively until you get the text, when you get the text, add it to the text variable separated by a new line\n",
    "    for item in list_of_dicts:\n",
    "        if isinstance(item, dict):\n",
    "            text += cat_text(item.values())\n",
    "        elif isinstance(item, list):\n",
    "            text += cat_text(item)\n",
    "        elif isinstance(item, str):\n",
    "            text += item + \"\\n\"\n",
    "        \n",
    "    return text\n",
    "example_main = cat_text(example_main)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYou happen to know that Tim and Harry have recently had a terrible row\\nthat ended their friendship. Now someone tells you that she just saw\\nTim and Harry jogging together. The best explanation for this that you\\ncan think of is that they made up. You conclude that they are friends\\nagain.\\n\\nOne morning you enter the kitchen to find a plate and cup on the\\ntable, with breadcrumbs and a pat of butter on it, and surrounded by a\\njar of jam, a pack of sugar, and an empty carton of milk. You conclude\\nthat one of your house-mates got up at night to make him- or herself a\\nmidnight snack and was too tired to clear the table. This, you think,\\nbest explains the scene you are facing. To be sure, it might be that\\nsomeone burgled the house and took the time to have a bite while on\\nthe job, or a house-mate might have arranged the things on the table\\nwithout having a midnight snack but just to make you believe that\\nsomeone had a midnight snack. But these hypotheses strike you as\\nproviding much more contrived explanations of the data than the one\\nyou infer to.\\n\\nWalking along the beach, you see what looks like a picture of Winston\\nChurchill in the sand. It could be that, as in the opening pages of\\nHilary Putnam’s book Reason, Truth, and History,\\n(1981), what you see is actually the trace of an ant crawling on the\\nbeach. The much simpler, and therefore (you think) much better,\\nexplanation is that someone intentionally drew a picture of Churchill\\nin the sand. That, in any case, is what you come away believing.\\n\\nIn these examples, the conclusions do not follow logically from the\\npremises. For instance, it does not follow logically that Tim and\\nHarry are friends again from the premises that they had a terrible row\\nwhich ended their friendship and that they have just been seen jogging\\ntogether; it does not even follow, we may suppose, from all the\\ninformation you have about Tim and Harry. Nor do you have any useful\\nstatistical data about friendships, terrible rows, and joggers that\\nmight warrant an inference from the information that you have about\\nTim and Harry to the conclusion that they are friends again, or even\\nto the conclusion that, probably (or with a certain probability), they\\nare friends again. What leads you to the conclusion, and what\\naccording to a considerable number of philosophers may also warrant\\nthis conclusion, is precisely the fact that Tim and Harry’s\\nbeing friends again would, if true, best explain the\\nfact that they have just been seen jogging together. (The proviso that\\na hypothesis be true if it is to explain anything is taken as read\\nfrom here on.) Similar remarks apply to the other two examples. The\\ntype of inference exhibited here is called abduction or,\\nsomewhat more commonly nowadays, Inference to the Best\\nExplanation.\\n1. Abduction: The General Idea\\n\\nAbduction is normally thought of as being one of three major types of\\ninference, the other two being deduction and induction. The\\ndistinction between deduction, on the one hand, and induction and\\nabduction, on the other hand, corresponds to the distinction between\\nnecessary and non-necessary inferences. In deductive inferences, what\\nis inferred is necessarily true if the premises from which it\\nis inferred are true; that is, the truth of the premises\\nguarantees the truth of the conclusion. A familiar type of\\nexample is inferences instantiating the schema\\n\\nAll As are Bs.\\n\\na is an A.\\n\\nHence, a is a B.\\n\\n\\nBut not all inferences are of this variety. Consider, for instance,\\nthe inference of “John is rich” from “John lives in\\nChelsea” and “Most people living in Chelsea are\\nrich.” Here, the truth of the first sentence is not guaranteed\\n(but only made likely) by the joint truth of the second and third\\nsentences. Differently put, it is not necessarily the case that if the\\npremises are true, then so is the conclusion: it is logically\\ncompatible with the truth of the premises that John is a member of the\\nminority of non-rich inhabitants of Chelsea. The case is similar\\nregarding your inference to the conclusion that Tim and Harry are\\nfriends again on the basis of the information that they have been seen\\njogging together. Perhaps Tim and Harry are former business partners\\nwho still had some financial matters to discuss, however much they\\nwould have liked to avoid this, and decided to combine this with their\\ndaily exercise; this is compatible with their being firmly decided\\nnever to make up.\\n\\nIt is standard practice to group non-necessary inferences into\\ninductive and abductive ones. Inductive inferences\\nform a somewhat heterogeneous class, but for present purposes they may\\nbe characterized as those inferences that are based purely on\\nstatistical data, such as observed frequencies of occurrences of a\\nparticular feature in a given population. An example of such an\\ninference would be this:\\n\\n96 per cent of the Flemish college students speak both Dutch and\\nFrench.\\n\\nLouise is a Flemish college student.\\n\\nHence, Louise speaks both Dutch and French.\\n\\n\\nHowever, the relevant statistical information may also be more vaguely\\ngiven, as in the premise, “Most people living in Chelsea are\\nrich.” (There is much discussion about whether the conclusion of\\nan inductive argument can be stated in purely qualitative terms or\\nwhether it should be a quantitative one—for instance, that it\\nholds with a probability of .96 that Louise speaks both Dutch and\\nFrench—or whether it can sometimes be stated in\\nqualitative terms—for instance, if the probability that it is\\ntrue is high enough—and sometimes not. On these and other issues\\nrelated to induction, see Kyburg 1990 (Ch. 4). It should also be\\nmentioned that Harman (1965) conceives induction as a special type of\\nabduction. See also Weintraub 2013 for discussion.)\\n\\nThe mere fact that an inference is based on statistical data is not\\nenough to classify it as an inductive one. You may have observed many\\ngray elephants and no non-gray ones, and infer from this that all\\nelephants are gray, because that would provide the best\\nexplanation for why you have observed so many gray elephants\\nand no non-gray ones. This would be an instance of an\\nabductive inference. It suggests that the best way to distinguish\\nbetween induction and abduction is this: both are ampliative,\\nmeaning that the conclusion goes beyond what is (logically) contained\\nin the premises (which is why they are non-necessary inferences), but\\nin abduction there is an implicit or explicit appeal to explanatory\\nconsiderations, whereas in induction there is not; in induction, there\\nis only an appeal to observed frequencies or statistics. (I\\nemphasize “only,” because in abduction there may also be\\nan appeal to frequencies or statistics, as the example about the\\nelephants exhibits.)\\n\\nA noteworthy feature of abduction, which it shares with induction but\\nnot with deduction, is that it violates monotonicity, meaning\\nthat it may be possible to infer abductively certain conclusions from\\na subset of a set S of premises which cannot be\\ninferred abductively from S as a whole. For instance, adding\\nthe premise that Tim and Harry are former business partners who still\\nhave some financial matters to discuss, to the premises that they had\\na terrible row some time ago and that they were just seen jogging\\ntogether may no longer warrant you to infer that they are friends\\nagain, even if—let us suppose—the last two premises alone\\ndo warrant that inference. The reason is that what counts as the best\\nexplanation of Tim and Harry’s jogging together in light of the\\noriginal premises may no longer do so once the information has been\\nadded that they are former business partners with financial matters to\\ndiscuss.\\n1.1 Deduction, induction, abduction\\n\\nThe type of inference exemplified in the cases described at the\\nbeginning of this entry will strike most as entirely familiar.\\nPhilosophers as well as psychologists tend to agree that abduction is\\nfrequently employed in everyday reasoning. Sometimes our reliance on\\nabductive reasoning is quite obvious and explicit. But in some daily\\npractices, it may be so routine and automatic that it easily goes\\nunnoticed. A case in point may be our trust in other people’s\\ntestimony, which has been said to rest on abductive reasoning; see\\nHarman 1965, Adler 1994, Fricker 1994, and Lipton 1998 for defenses of\\nthis claim. For instance, according to Jonathan Adler (1994, 274f),\\n“[t]he best explanation for why the informant asserts that\\nP is normally that … he believes it for duly responsible\\nreasons and … he intends that I shall believe it too,”\\nwhich is why we are normally justified in trusting the\\ninformant’s testimony. This may well be correct, even though in\\ncoming to trust a person’s testimony one does not normally seem\\nto be aware of any abductive reasoning going on in one’s mind.\\nSimilar remarks may apply to what some hold to be a further, possibly\\neven more fundamental, role of abduction in linguistic practice, to\\nwit, its role in determining what a speaker means by an utterance.\\nSpecifically, it has been argued that decoding utterances is a matter\\nof inferring the best explanation of why someone said what he or she\\nsaid in the context in which the utterance was made. Even more\\nspecifically, authors working in the field of pragmatics have\\nsuggested that hearers invoke the Gricean maxims of conversation to\\nhelp them work out the best explanation of a speaker’s utterance\\nwhenever the semantic content of the utterance is insufficiently\\ninformative for the purposes of the conversation, or is too\\ninformative, or off-topic, or implausible, or otherwise odd or\\ninappropriate; see, for instance, Bach and Harnish 1979 (92f), Dascal\\n1979 (167), and Hobbs 2004. As in cases of reliance on speaker\\ntestimony, the requisite abductive reasoning would normally seem to\\ntake place at a subconscious level.\\n\\nAbductive reasoning is not limited to everyday contexts. Quite the\\ncontrary: philosophers of science have argued that abduction is a\\ncornerstone of scientific methodology; see, for instance, Boyd 1981,\\n1984, Harré 1986, 1988, Lipton 1991, 2004, and Psillos 1999.\\nAccording to Timothy Williamson (2007), “[t]he abductive\\nmethodology is the best science provides” and Ernan McMullin\\n(1992) even goes so far to call abduction “the inference that\\nmakes science.” To illustrate the use of abduction in science,\\nwe consider two examples.\\n\\nAt the beginning of the nineteenth century, it was discovered that the\\norbit of Uranus, one of the seven planets known at the time, departed\\nfrom the orbit as predicted on the basis of Isaac Newton’s\\ntheory of universal gravitation and the auxiliary assumption that\\nthere were no further planets in the solar system. One possible\\nexplanation was, of course, that Newton’s theory is false. Given\\nits great empirical successes for (then) more than two centuries, that\\ndid not appear to be a very good explanation. Two astronomers, John\\nCouch Adams and Urbain Leverrier, instead suggested (independently of\\neach other but almost simultaneously) that there was an eighth, as yet\\nundiscovered planet in the solar system; that, they thought, provided\\nthe best explanation of Uranus’ deviating orbit. Not much later,\\nthis planet, which is now known as “Neptune,” was\\ndiscovered.\\n\\nThe second example concerns what is now commonly regarded to have been\\nthe discovery of the electron by the English physicist Joseph John\\nThomson. Thomson had conducted experiments on cathode rays in order to\\ndetermine whether they are streams of charged particles. He concluded\\nthat they are indeed, reasoning as follows:\\n\\n\\n\\nAs the cathode rays carry a charge of negative electricity, are\\ndeflected by an electrostatic force as if they were negatively\\nelectrified, and are acted on by a magnetic force in just the way in\\nwhich this force would act on a negatively electrified body moving\\nalong the path of these rays, I can see no escape from the conclusion\\nthat they are charges of negative electricity carried by particles of\\nmatter. (Thomson, cited in Achinstein 2001, 17)\\n\\n\\nThe conclusion that cathode rays consist of negatively charged\\nparticles does not follow logically from the reported experimental\\nresults, nor could Thomson draw on any relevant statistical data. That\\nnevertheless he could “see no escape from the conclusion”\\nis, we may safely assume, because the conclusion is the best—in\\nthis case presumably even the only plausible—explanation of his\\nresults that he could think of.\\n\\nMany other examples of scientific uses of abduction have been\\ndiscussed in the literature; see, for instance, Harré 1986,\\n1988 and Lipton 1991, 2004. Abduction is also said to be the\\npredominant mode of reasoning in medical diagnosis: physicians tend to\\ngo for the hypothesis that best explains the patient’s symptoms\\n(see Josephson and Josephson (eds.) 1994, 9–12; see also\\nDragulinescu 2016 on abductive reasoning in the context of\\nmedicine).\\n\\nLast but not least, abduction plays a central role in some important\\nphilosophical debates. See Shalkowski 2010 on the place of abduction\\nin metaphysics (also Bigelow 2010), Krzyżanowska, Wenmackers, and\\nDouven 2014 and Douven 2016a for a possible role of\\nabduction in the semantics of conditionals, and Williamson\\n2017 for an application of abduction in the philosophy of logic.\\nArguably, however, abduction plays its most notable philosophical role\\nin epistemology and in the philosophy of science, where it is\\nfrequently invoked in objections to so-called underdetermination\\narguments. Underdetermination arguments generally start from the\\npremise that a number of given hypotheses are empirically equivalent,\\nwhich their authors take to mean that the evidence—indeed, any\\nevidence we might ever come to possess—is unable to favor one of\\nthem over the others. From this, we are supposed to conclude that one\\ncan never be warranted in believing any particular one of the\\nhypotheses. (This is rough, but it will do for present purposes; see\\nDouven 2008 and Stanford 2009, for more detailed accounts of\\nunderdetermination arguments.) A famous instance of this type of\\nargument is the Cartesian argument for global skepticism, according to\\nwhich the hypothesis that reality is more or less the way we\\ncustomarily deem it to be is empirically equivalent to a variety of\\nso-called skeptical hypotheses (such as that we are beguiled by an\\nevil demon, or that we are brains in a vat, connected to a\\nsupercomputer; see, e.g., Folina 2016). Similar arguments have been\\ngiven in support of scientific antirealism, according to which it will\\nnever be warranted for us to choose between empirically equivalent\\nrivals concerning what underlies the observable part of reality (van\\nFraassen 1980).\\n\\nResponses to these arguments typically point to the fact that the\\nnotion of empirical equivalence at play unduly neglects explanatory\\nconsiderations, for instance, by defining the notion strictly in terms\\nof hypotheses’ making the same predictions. Those responding\\nthen argue that even if some hypotheses make exactly the same\\npredictions, one of them may still be a better explanation of the\\nphenomena predicted. Thus, if explanatory considerations have a role\\nin determining which inferences we are licensed to make—as\\naccording to defenders of abduction they have—then we might\\nstill be warranted in believing in the truth (or probable truth, or\\nsome such, depending—as will be seen below—on the version\\nof abduction one assumes) of one of a number of hypotheses that all\\nmake the same predictions. Following Bertrand Russell (1912, Ch. 2),\\nmany epistemologists have invoked abduction in arguing against\\nCartesian skepticism, their key claim being that even though, by\\nconstruction, the skeptical hypotheses make the same predictions as\\nthe hypothesis that reality is more or less the way we ordinarily take\\nit to be, they are not equally good explanations of what they predict;\\nin particular, the skeptical hypotheses have been said to be\\nconsiderably less simple than the “ordinary world”\\nhypothesis. See, among many others, Harman 1973 (Chs. 8 and 11),\\nGoldman 1988 (205), Moser 1989 (161), and Vogel 1990, 2005; see\\nPargetter 1984 for an abductive response specifically to skepticism\\nregarding other minds. Similarly, philosophers of science have argued\\nthat we are warranted to believe in Special Relativity Theory as\\nopposed to Lorentz’s version of the æther theory. For even\\nthough these theories make the same predictions, the former is\\nexplanatorily superior to the latter. (Most arguments that have been\\ngiven for this claim come down to the contention that Special\\nRelativity Theory is ontologically more parsimonious than its\\ncompetitor, which postulates the existence of an æther. See\\nJanssen 2002 for an excellent discussion of the various reasons\\nphilosophers of science have adduced for preferring Einstein’s\\ntheory to Lorentz’s.)\\n1.2 The ubiquity of abduction\\n\\nPrecise statements of what abduction amounts to are rare in the\\nliterature on abduction. (Peirce did propose an at least fairly\\nprecise statement; but, as explained in the supplement to this entry,\\nit does not capture what most nowadays understand by abduction.) Its\\ncore idea is often said to be that explanatory considerations have\\nconfirmation-theoretic import, or that explanatory success is a (not\\nnecessarily unfailing) mark of truth. Clearly, however, these\\nformulations are slogans at best, and it takes little effort to see\\nthat they can be cashed out in a great variety of prima facie\\nplausible ways. Here we will consider a number of such possible\\nexplications, starting with what one might term the “textbook\\nversion of abduction,” which, as will be seen, is manifestly\\ndefective, and then going on to consider various possible refinements\\nof it. What those versions have in\\ncommon—unsurprisingly—is that they are all inference\\nrules, requiring premises encompassing explanatory considerations and\\nyielding a conclusion that makes some statement about the truth of a\\nhypothesis. The differences concern the premises that are required, or\\nwhat exactly we are allowed to infer from them (or both).\\n\\nIn textbooks on epistemology or the philosophy of science, one often\\nencounters something like the following as a formulation of\\nabduction:\\n\\nAn observation that is frequently made about this rule, and that\\npoints to a potential problem for it, is that it presupposes the\\nnotions of candidate explanation and best explanation, neither of\\nwhich has a straightforward interpretation. While some still hope that\\nthe former can be spelled out in purely logical, or at least purely\\nformal, terms, it is often said that the latter must appeal to the\\nso-called theoretical virtues, like simplicity, generality, and\\ncoherence with well-established theories; the best explanation would\\nthen be the hypothesis which, on balance, does best with respect to\\nthese virtues. (See, for instance, Thagard 1978 and McMullin 1996.)\\nThe problem is that none of the said virtues is presently particularly\\nwell understood. (Giere, in Callebaut (ed.) 1993 (232), even makes the\\nradical claim that the theoretical virtues lack real content and play\\nno more than a rhetorical role in science. In view of recent formal\\nwork both on simplicity and on coherence—for instance, Forster\\nand Sober 1994, Li and Vitanyi 1997, and Sober 2015, on simplicity and\\nBovens and Hartmann 2003 and Olsson 2005, on coherence—the first\\npart of this claim has become hard to maintain; also, Schupbach and\\nSprenger (2011) present an account of explanatory goodness directly in\\nprobabilistic terms. Psychological evidence casts doubt on the second\\npart of the claim; see, for instance, Lombrozo 2007, on the role of\\nsimplicity in people’s assessments of explanatory goodness and\\nKoslowski et al. 2008, on the role of coherence with\\nbackground knowledge in those assessments.)\\n\\nFurthermore, many of those who think ABD1 is headed along the right\\nlines believe that it is too strong. Some think that abduction\\nwarrants an inference only to the probable truth of the best\\nexplanation, others that it warrants an inference only to the\\napproximate truth of the best explanation, and still others\\nthat it warrants an inference only to the probable\\napproximate truth.\\n\\nThe real problem with ABD1 runs deeper than this, however. Because\\nabduction is ampliative—as explained earlier—it will not\\nbe a sound rule of inference in the strict logical sense, however\\nabduction is explicated exactly. It can still be reliable in\\nthat it mostly leads to a true conclusion whenever the premises are\\ntrue. An obvious necessary condition for ABD1 to be reliable in this\\nsense is that, mostly, when it is true that H best\\nexplains E, and E is true, then H is true as well\\n(or H is approximately true, or probably true, or probably\\napproximately true). But this would not be enough for ABD1 to\\nbe reliable. For ABD1 takes as its premise only that some hypothesis\\nis the best explanation of the evidence as compared to other\\nhypotheses in a given set. Thus, if the rule is to be\\nreliable, it must hold that, at least typically, the best explanation\\nrelative to the set of hypotheses that we consider would also come out\\nas being best in comparison with any other hypotheses that we might\\nhave conceived (but for lack of time or ingenuity, or for some other\\nreason, did not conceive). In other words, it must hold that at least\\ntypically the absolutely best explanation of the evidence is\\nto be found among the candidate explanations we have come up with, for\\nelse ABD1 may well lead us to believe “the best of a bad\\nlot” (van Fraassen 1989, 143).\\n\\nHow reasonable is it to suppose that this extra requirement is usually\\nfulfilled? Not at all, presumably. To believe otherwise, we must\\nassume some sort of privilege on our part to the effect that when we\\nconsider possible explanations of the data, we are somehow predisposed\\nto hit, inter alia, upon the absolutely best explanation of those\\ndata. After all, hardly ever will we have considered, or will it even\\nbe possible to consider, all potential explanations. As van\\nFraassen (1989, 144) points out, it is a priori rather\\nimplausible to hold that we are thus privileged.\\n\\nIn response to this, one might argue that the challenge to show that\\nthe best explanation is always or mostly among the hypotheses\\nconsidered can be met without having to assume some form of privilege\\n(see Schupbach 2014 for a different response, and see Dellsén\\n2017 for discussion). For given the hypotheses we have managed to come\\nup with, we can always generate a set of hypotheses which jointly\\nexhaust logical space. Suppose\\nH1,…,Hn are the\\ncandidate explanations we have so far been able to conceive. Then\\nsimply define Hn+1 := ¬H1\\n∧ … ∧ ¬Hn and add this new\\nhypothesis as a further candidate explanation to the ones we already\\nhave. Obviously, the set\\n{H1,…,Hn+1} is exhaustive,\\nin that one of its elements must be true. Following this in itself\\nsimple procedure would seem enough to make sure that we never miss out\\non the absolutely best explanation. (See Lipton 1993, for a proposal\\nalong these lines.)\\n\\nAlas, there is a catch. For even though there may be many hypotheses\\nHj that imply Hn+1 and, had\\nthey been formulated, would have been evaluated as being a better\\nexplanation for the data than the best explanation among the candidate\\nexplanations we started out with, Hn+1 itself will\\nin general be hardly informative; in fact, in general it will not even\\nbe clear what its empirical consequences are. Suppose, for instance,\\nwe have as competing explanations Special Relativity Theory and\\nLorentz’s version of the æther theory. Then, following the\\nabove proposal, we may add to our candidate explanations that neither\\nof these two theories is true. But surely this further hypothesis will\\nbe ranked quite low qua explanation—if it will be\\nranked at all, which seems doubtful, given that it is wholly unclear\\nwhat its empirical consequences are. This is not to say that the\\nsuggested procedure may never work. The point is that in general it\\nwill give little assurance that the best explanation is among the\\ncandidate explanations we consider.\\n\\nA more promising response to the above “argument of the bad\\nlot” begins with the observation that the argument capitalizes\\non a peculiar asymmetry or incongruence in ABD1. The rule gives\\nlicense to an absolute conclusion—that a given hypothesis is\\ntrue—on the basis of a comparative premise, namely, that that\\nparticular hypothesis is the best explanation of the evidence relative\\nto the other hypotheses available (see Kuipers 2000, 171). This\\nincongruence is not avoided by replacing “truth” with\\n“probable truth” or “approximate truth.” In\\norder to avoid it, one has two general options.\\n\\nThe first option is to modify the rule so as to have it require an\\nabsolute premise. For instance, following Alan Musgrave (1988) or\\nPeter Lipton (1993), one may require the hypothesis whose truth is\\ninferred to be not only the best of the available potential\\nexplanations, but also to be satisfactory (Musgrave) or\\ngood enough (Lipton), yielding the following variant of\\nABD1:\\n\\nNeedless to say, ABD2 needs supplementing by a criterion for the\\nsatisfactoriness of explanations, or their being good enough, which,\\nhowever, we are still lacking.\\n\\nSecondly, one can formulate a symmetric or congruous version of\\nabduction by having it sanction, given a comparative premise, only a\\ncomparative conclusion; this option, too, can in turn be realized in\\nmore than one way. Here is one way to do it, which has been proposed\\nand defended in the work of Theo Kuipers (e.g., Kuipers 1984, 1992,\\n2000).\\n\\nClearly, ABD3 requires an account of closeness to the truth, but many\\nsuch accounts are on offer today (see, e.g., Niiniluoto 1998).\\n\\nOne noteworthy feature of the congruous versions of abduction\\nconsidered here is that they do not rely on the assumption of an\\nimplausible privilege on the reasoner’s part that, we saw, ABD1\\nimplicitly relies on. Another is that if one can be certain that,\\nhowever many candidate explanations for the data one may have missed,\\nnone equals the best of those one has thought of, then the\\ncongruous versions license exactly the same inference as ABD1 does\\n(supposing that one would not be certain that no potential explanation\\nis as good as the best explanation one has thought of if the latter is\\nnot even satisfactory or sufficiently good).\\n\\nAs mentioned, there is widespread agreement that people frequently\\nrely on abductive reasoning. Which of the above rules exactly\\nis it that people rely on? Or might it be still some further rule that\\nthey rely on? Or might they in some contexts rely on one version, and\\nin others on another (Douven 2017, forthcoming)? Philosophical\\nargumentation is unable to answer these questions. In recent years,\\nexperimental psychologists have started paying attention to the role\\nhumans give to explanatory considerations in reasoning. For instance,\\nTania Lombrozo and Nicholas Gwynne (2014) report experiments showing\\nthat how a property of a given class of things is explained\\nto us—whether mechanistically, by reference to parts and\\nprocesses, or functionally, by reference to functions and\\npurposes—matters to how likely we are to generalise that\\nproperty to other classes of things (see also Sloman 1994 and Williams\\nand Lombrozo 2010). And Igor Douven and Jonah Schupbach (2015a),\\n(2015b) present experimental evidence to the effect that\\npeople’s probability updates tend to be influenced by\\nexplanatory considerations in ways that makes them deviate from\\nstrictly Bayesian updates (see below). Douven (2016b) shows that, in\\nthe aforementioned experiments, participants who gave more weight to\\nexplanatory considerations tended to be more accurate, as determined\\nin terms of a standard scoring rule. (See Lombrozo 2012 and 2016 for\\nuseful overviews of recent experimental work relevant to explanation\\nand inference.) Douven and Patricia Mirabile (2018) found some\\nevidence indicating that people rely on something like ABD2, at least\\nin some contexts, but for the most part, empirical work on the\\nabove-mentioned questions is lacking.\\n\\nWith respect to the normative question of which of the previously\\nstated rules we ought to rely on (if we ought to rely on any\\nform of abduction), where philosophical argumentation should be able\\nto help, the situation is hardly any better. In view of the argument\\nof the bad lot, ABD1 does not look very good. Other arguments against\\nabduction are claimed to be independent of the exact explication of\\nthe rule; below, these arguments will be found wanting. On the other\\nhand, arguments that have been given in favor of abduction—some\\nof which will also be discussed below—do not discern between\\nspecific versions. So, supposing people do indeed commonly rely on\\nabduction, it must be considered an open question as to which\\nversion(s) of abduction they rely on. Equally, supposing it is\\nrational for people to rely on abduction, it must be considered an\\nopen question as to which version, or perhaps versions, of abduction\\nthey ought to, or are at least permitted to, rely on.\\n2. Explicating Abduction\\n\\nEven if it is true that we routinely rely on abductive reasoning, it\\nmay still be asked whether this practice is rational. For instance,\\nexperimental studies have shown that when people are able to think of\\nan explanation for some possible event, they tend to overestimate the\\nlikelihood that this event will actually occur. (See Koehler 1991, for\\na survey of some of these studies; see also Brem and Rips 2000.) More\\ntelling still, Lombrozo (2007) shows that, in some situations, people\\ntend to grossly overrate the probability of simpler explanations\\ncompared to more complicated ones. Although these studies are not\\ndirectly concerned with abduction in any of the forms discussed so\\nfar, they nevertheless suggest that taking into account explanatory\\nconsiderations in one’s reasoning may not always be for the\\nbetter. (It is to be noted that Lombrozo’s experiments\\nare directly concerned with some proposals that have been\\nmade for explicating abduction in a Bayesian framework; see Section\\n4.) However, the most pertinent remarks about the normative status of\\nabduction are so far to be found in the philosophical literature. This\\nsection discusses the main criticisms that have been levelled against\\nabduction, as well as the strongest arguments that have been given in\\nits defense.\\n3. The Status of Abduction\\n\\nWe have already encountered the so-called argument of the bad lot,\\nwhich, we saw, is valid as a criticism of ABD1 but powerless against\\nvarious (what we called) congruous rules of abduction. We here\\nconsider two objections that are meant to be more general. The first\\neven purports to challenge the core idea underlying abduction; the\\nsecond is not quite as general, but it is still meant to undermine a\\nbroad class of candidate explications of abduction. Both objections\\nare due to Bas van Fraassen.\\n\\nThe first objection has as a premise that it is part of the meaning of\\n“explanation” that if one theory is more explanatory than\\nanother, the former must be more informative than the latter (see,\\ne.g., van Fraassen 1983, Sect. 2). The alleged problem then is that it\\nis “an elementary logical point that a more informative theory\\ncannot be more likely to be true [and thus] attempts to describe\\ninductive or evidential support through features that require\\ninformation (such as ‘Inference to the Best Explanation’)\\nmust either contradict themselves or equivocate” (van Fraassen\\n1989, 192). The elementary logical point is supposed to be “most\\n[obvious] … in the paradigm case in which one theory is an\\nextension of another: clearly the extension has more ways of being\\nfalse” (van Fraassen 1985, 280).\\n\\nIt is important to note, however, that in any other kind of case than\\nthe “paradigm” one, the putative elementary point is not\\nobvious at all. For instance, it is entirely unclear in what sense\\nSpecial Relativity Theory “has more ways of being false”\\nthan Lorentz’s version of the æther theory, given that\\nthey make the same predictions. And yet the former is generally\\nregarded as being superior, qua explanation, to the latter.\\n(If van Fraassen were to object that the former is not really more\\ninformative than the latter, or at any rate not more informative in\\nthe appropriate sense—whatever that is—then we should\\ncertainly refuse to grant the premise that in order to be more\\nexplanatory a theory must be more informative.)\\n\\nThe second objection, proffered in van Fraassen 1989 (Ch. 6), is\\nlevelled at probabilistic versions of abduction. The objection is that\\nsuch rules must either amount to Bayes’ rule, and thus be\\nredundant, or be at variance with it but then, on the grounds of\\nLewis’ dynamic Dutch book argument (as reported in Teller 1973),\\nbe probabilistically incoherent, meaning that they may lead one to\\nassess as fair a number of bets which together ensure a financial\\nloss, come what may; and, van Fraassen argues, it would be irrational\\nto follow a rule that has this feature.\\n\\nHowever, this objection fares no better than the first. For one thing,\\nas Patrick Maher (1992) and Brian Skyrms (1993) have pointed out, a\\nloss in one respect may be outweighed by a benefit in another. It\\nmight be, for instance, that some probabilistic version of abduction\\ndoes much better, at least in our world, than Bayes’ rule, in\\nthat, on average, it approaches the truth faster in the sense that it\\nis faster in assigning a high probability (understood as probability\\nabove a certain threshold value) to the true hypothesis (see Douven\\n2013, 2020, and Douven and Wenmackers 2017; see Climenhaga\\n2017 for discussion). If it does, then following that rule\\ninstead of Bayes’ rule may have advantages which perhaps are not\\nso readily expressed in terms of money yet which should arguably be\\ntaken into account when deciding which rule to go by. It is, in short,\\nnot so clear whether following a probabilistically incoherent rule\\nmust be irrational.\\n\\nFor another thing, Douven (1999) argues that the question of whether a\\nprobabilistic rule is coherent is not one that can be settled\\nindependently of considering which other epistemic and\\ndecision-theoretic rules are deployed along with it; coherence should\\nbe understood as a property of packages of both epistemic and\\ndecision-theoretic rules, not of epistemic rules (such as\\nprobabilistic rules for belief change) in isolation. In the same\\npaper, a coherent package of rules is described which includes a\\nprobabilistic version of abduction. (See Kvanvig 1994, Harman 1997,\\nLeplin 1997, Niiniluoto 1999, and Okasha 2000, for different responses\\nto van Fraassen’s critique of probabilistic versions of\\nabduction.)\\n3.1 Criticisms\\n\\nHardly anyone nowadays would want to subscribe to a conception of\\ntruth that posits a necessary connection between explanatory force and\\ntruth—for instance, because it stipulates explanatory\\nsuperiority to be necessary for truth. As a result, a priori defenses\\nof abduction seem out of the question. Indeed, all defenses that have\\nbeen given so far are of an empirical nature in that they appeal to\\ndata that supposedly support the claim that (in some form) abduction\\nis a reliable rule of inference.\\n\\nThe best-known argument of this sort was developed by Richard Boyd in\\nthe 1980s (see Boyd 1981, 1984, 1985). It starts by underlining the\\ntheory-dependency of scientific methodology, which comprises methods\\nfor designing experiments, for assessing data, for choosing between\\nrival hypotheses, and so on. For instance, in considering possible\\nconfounding factors from which an experimental setup has to be\\nshielded, scientists draw heavily on already accepted theories. The\\nargument next calls attention to the apparent reliability of this\\nmethodology, which, after all, has yielded, and continues to yield,\\nimpressively accurate theories. In particular, by relying on this\\nmethodology, scientists have for some time now been able to find ever\\nmore instrumentally adequate theories. Boyd then argues that the\\nreliability of scientific methodology is best explained by assuming\\nthat the theories on which it relies are at least approximately true.\\nFrom this and from the fact that these theories were mostly arrived at\\nby abductive reasoning, he concludes that abduction must be a reliable\\nrule of inference.\\n\\nCritics have accused this argument of being circular. Specifically, it\\nhas been said that the argument rests on a premise—that\\nscientific methodology is informed by approximately true background\\ntheories—which in turn rests on an inference to the best\\nexplanation for its plausibility. And the reliability of this type of\\ninference is precisely what is at stake. (See, for instance, Laudan\\n1981 and Fine 1984.)\\n\\nTo this, Stathis Psillos (1999, Ch. 4) has responded by invoking a\\ndistinction credited to Richard Braithwaite, to wit, the distinction\\nbetween premise-circularity and rule-circularity. An argument is\\npremise-circular if its conclusion is amongst its premises. A\\nrule-circular argument, by contrast, is an argument of which the\\nconclusion asserts something about an inferential rule that is used in\\nthe very same argument. As Psillos urges, Boyd’s argument is\\nrule-circular, but not premise-circular, and rule-circular arguments,\\nPsillos contends, need not be viciously circular (even though\\na premise-circular argument is always viciously circular). To be more\\nprecise, in his view, an argument for the reliability of a given rule\\nR that essentially relies on R as an inferential\\nprinciple is not vicious, provided that the use of R does not\\nguarantee a positive conclusion about R’s reliability.\\nPsillos claims that in Boyd’s argument, this proviso is met. For\\nwhile Boyd concludes that the background theories on which scientific\\nmethodology relies are approximately true on the basis of an abductive\\nstep, the use of abduction itself does not guarantee the truth of his\\nconclusion. After all, granting the use of abduction does nothing to\\nensure that the best explanation of the success of scientific\\nmethodology is the approximate truth of the relevant background\\ntheories. Thus, Psillos concludes, Boyd’s argument still\\nstands.\\n\\nEven if the use of abduction in Boyd’s argument might have led\\nto the conclusion that abduction is not reliable, one may\\nstill have worries about the argument’s being rule-circular. For\\nsuppose that some scientific community relied not on abduction but on\\na rule that we may dub “Inference to the Worst\\nExplanation” (IWE), a rule that sanctions inferring to the\\nworst explanation of the available data. We may safely assume\\nthat the use of this rule mostly would lead to the adoption of very\\nunsuccessful theories. Nevertheless, the said community might justify\\nits use of IWE by dint of the following reasoning: “Scientific\\ntheories tend to be hugely unsuccessful. These theories were arrived\\nat by application of IWE. That IWE is a reliable rule of\\ninference—that is, a rule of inference mostly leading from true\\npremises to true conclusions—is surely the worst explanation of\\nthe fact that our theories are so unsuccessful. Hence, by application\\nof IWE, we may conclude that IWE is a reliable rule of\\ninference.” While this would be an utterly absurd conclusion,\\nthe argument leading up to it cannot be convicted of being viciously\\ncircular anymore than Boyd’s argument for the reliability of\\nabduction can (if Psillos is right). It would appear, then, that there\\nmust be something else amiss with rule-circularity.\\n\\nIt is fair to note that for Psillos, the fact that a rule-circular\\nargument does not guarantee a positive conclusion about the rule at\\nissue is not sufficient for such an argument to be valid. A further\\nnecessary condition is “that one should not have reason to doubt\\nthe reliability of the rule—that there is nothing currently\\navailable which can make one distrust the rule” (Psillos 1999,\\n85). And there is plenty of reason to doubt the reliability of IWE; in\\nfact, the above argument supposes that it is unreliable. Two\\nquestions arise, however. First, why should we accept the additional\\ncondition? Second, do we really have no reason to doubt the\\nreliability of abduction? Certainly some of the abductive\\ninferences we make lead us to accept falsehoods. How many\\nfalsehoods may we accept on the basis of abduction before we can\\nlegitimately begin to distrust this rule? No clear answers have been\\ngiven to these questions.\\n\\nBe this as it may, even if rule-circularity is neither vicious nor\\notherwise problematic, one may still wonder how Boyd’s argument\\nis to convert a critic of abduction, given that it relies on\\nabduction. But Psillos makes it clear that the point of philosophical\\nargumentation is not always, and in any case need not be, to convince\\nan opponent of one’s position. Sometimes the point is, more\\nmodestly, to assure or reassure oneself that the position one\\nendorses, or is tempted to endorse, is correct. In the case at hand,\\nwe need not think of Boyd’s argument as an attempt to convince\\nthe opponent of abduction of its reliability. Rather, it may be\\nthought of as justifying the rule from within the perspective of\\nsomeone who is already sympathetic towards abduction; see Psillos 1999\\n(89).\\n\\nThere have also been attempts to argue for abduction in a more\\nstraightforward fashion, to wit, via enumerative induction. The common\\nidea of these attempts is that every newly recorded successful\\napplication of abduction—like the discovery of Neptune, whose\\nexistence had been postulated on explanatory grounds (see Section\\n1.2)—adds further support to the hypothesis that abduction is a\\nreliable rule of inference, in the way in which every newly observed\\nblack raven adds some support to the hypothesis that all ravens are\\nblack. Because it does not involve abductive reasoning, this type of\\nargument is more likely to also appeal to disbelievers in abduction.\\nSee Harré 1986, 1988, Bird 1998 (160), Kitcher 2001, and Douven\\n2002 for suggestions along these lines.\\n3.2 Defenses\\n\\nIn the past decade, Bayesian confirmation theory has firmly\\nestablished itself as the dominant view on confirmation; currently one\\ncannot very well discuss a confirmation-theoretic issue without making\\nclear whether, and if so why, one’s position on that issue\\ndeviates from standard Bayesian thinking. Abduction, in whichever\\nversion, assigns a confirmation-theoretic role to explanation:\\nexplanatory considerations contribute to making some hypotheses more\\ncredible, and others less so. By contrast, Bayesian confirmation\\ntheory makes no reference at all to the concept of explanation. Does\\nthis imply that abduction is at loggerheads with the prevailing\\ndoctrine in confirmation theory? Several authors have recently argued\\nthat not only is abduction compatible with Bayesianism, it is a\\nmuch-needed supplement to it. The so far fullest defense of this view\\nhas been given by Lipton (2004, Ch. 7); as he puts it, Bayesians\\nshould also be “explanationists” (his name for the\\nadvocates of abduction). (For other defenses, see Okasha 2000, McGrew\\n2003, Weisberg 2009, and Poston 2014, Ch. 7; for discussion, see Roche\\nand Sober 2013, 2014, and McCain and Poston 2014.)\\n\\nThis requires some clarification. For what could it mean for a\\nBayesian to be an explanationist? In order to apply Bayes’ rule\\nand determine the probability for H after learning E,\\nthe Bayesian agent will have to determine the probability of H\\nconditional on E. For that, he needs to assign unconditional\\nprobabilities to H and E as well as a probability to\\nE given H; the former two are mostly called “prior\\nprobabilities” (or just “priors”) of, respectively,\\nH and E, the latter the “likelihood” of\\nH on E. (This is the official Bayesian story. Not all of\\nthose who sympathize with Bayesianism adhere to that story. For\\ninstance, according to some it is more reasonable to think that\\nconditional probabilities are basic and that we derive unconditional\\nprobabilities from them; see Hájek 2003, and references\\ntherein.) How is the Bayesian to determine these values? As is well\\nknown, probability theory gives us more probabilities once we have\\nsome; it does not give us probabilities from scratch. Of course, when\\nH implies E or the negation of E, or when\\nH is a statistical hypothesis that bestows a certain chance on\\nE, then the likelihood follows “analytically.”\\n(This claim assumes some version of Lewis’ (1980) Principal\\nPrinciple, and it is controversial whether or not this principle is\\nanalytic; hence the scare quotes.) But this is not always the case,\\nand even if it were, there would still be the question of how to\\ndetermine the priors. This is where, according to Lipton, abduction\\ncomes in. In his proposal, Bayesians ought to determine their prior\\nprobabilities and, if applicable, likelihoods on the basis of\\nexplanatory considerations.\\n\\nExactly how are explanatory considerations to guide one’s choice\\nof priors? The answer to this question is not as simple as one might\\nat first think. Suppose you are considering what priors to assign to a\\ncollection of rival hypotheses and you wish to follow Lipton’s\\nsuggestion. How are you to do this? An obvious—though still\\nsomewhat vague—answer may seem to go like this: Whatever exact\\npriors you are going to assign, you should assign a higher one to the\\nhypothesis that explains the available data best than to any of its\\nrivals (provided there is a best explanation). Note, though, that your\\nneighbor, who is a Bayesian but thinks confirmation has nothing to do\\nwith explanation, may well assign a prior to the best explanation that\\nis even higher than the one you assign to that hypothesis. In fact,\\nhis priors for best explanations may even be consistently higher than\\nyours, not because in his view explanation is somehow related to\\nconfirmation—it is not, he thinks—but, well, just because.\\nIn this context, “just because” is a perfectly legitimate\\nreason, because any reason for fixing one’s priors counts as\\nlegitimate by Bayesian standards. According to mainstream Bayesian\\nepistemology, priors (and sometimes likelihoods) are up for grabs,\\nmeaning that one assignment of priors is as good as another, provided\\nboth are coherent (that is, they obey the axioms of probability\\ntheory). Lipton’s recommendation to the Bayesian to be an\\nexplanationist is meant to be entirely general. But what should your\\nneighbor do differently if he wants to follow the recommendation?\\nShould he give the same prior to any best explanation that you, his\\nexplanationist neighbor, give to it, that is, lower his\\npriors for best explanations? Or rather should he give even\\nhigher priors to best explanations than those he already\\ngives?\\n\\nPerhaps Lipton’s proposal is not intended to address those who\\nalready assign highest priors to best explanations, even if they do so\\non grounds that have nothing to do with explanation. The idea might be\\nthat, as long as one does assign highest priors to those hypotheses,\\neverything is fine, or at least finer than if one does not do so,\\nregardless of one’s reasons for assigning those priors. The\\nanswer to the question of how explanatory considerations are to guide\\none’s choice of priors would then presumably be that one ought\\nto assign a higher prior to the best explanation than to its rivals,\\nif this is not what one already does. If it is, one should just keep\\ndoing what one is doing.\\n\\n(As an aside, it should be noticed that, according to standard\\nBayesian usage, the term “priors” does not necessarily\\nrefer to the degrees of belief a person assigns before the receipt of\\nany data. If there are already data in, then, clearly, one\\nmay assign higher priors to hypotheses that best explain the\\nthen-available data. However, one can sensibly speak of “best\\nexplanations” even before any data are known. For example, one\\nhypothesis may be judged to be a better explanation than any of its\\nrivals because the former requires less complicated mathematics, or\\nbecause it is stated in terms of familiar concepts only, which is not\\ntrue of the others. More generally, such judgments may be based on\\nwhat Kosso (1992, 30) calls internal features of hypotheses\\nor theories, that is, features that “can be evaluated without\\nhaving to observe the world.”)\\n\\nA more interesting answer to the above question of how explanation is\\nto guide one’s choice of priors has been given by Jonathan\\nWeisberg (2009). We said that mainstream Bayesians regard one\\nassignment of prior probabilities as being as good as any other.\\nSo-called objective Bayesians do not do so, however. These Bayesians\\nthink priors must obey principles beyond the probability axioms in\\norder to be admissible. Objective Bayesians are divided among\\nthemselves over exactly which further principles are to be obeyed, but\\nat least for a while they agreed that the Principle of Indifference is\\namong them. Roughly stated, this principle counsels that, absent a\\nreason to the contrary, we give equal priors to competing hypotheses.\\nAs is well known, however, in its original form the Principle of\\nIndifference may lead to inconsistent assignments of probabilities and\\nso can hardly be advertised as a principle of rationality. The problem\\nis that there are typically various ways to partition logical space\\nthat appear plausible given the problem at hand, and that not all of\\nthem lead to the same prior probability assignment, even assuming the\\nPrinciple of Indifference. Weisberg’s proposal amounts to the\\nclaim that explanatory considerations may favor some of those\\npartitions over others. Perhaps we will not always end up with a\\nunique partition to which the Principle of Indifference is to be\\napplied, but it would already be progress if we ended up with only a\\nhandful of partitions. For we could then still arrive in a motivated\\nway at our prior probabilities, by proceeding in two steps, namely, by\\nfirst applying the Principle of Indifference to the partitions\\nseparately, thereby possibly obtaining different assignments of\\npriors, and by then taking a weighted average of the thus obtained\\npriors, where the weights, too, are to depend on explanatory\\nconsiderations. The result would again be a probability\\nfunction—the uniquely correct prior probability function,\\naccording to Weisberg.\\n\\nThe proposal is intriguing as far as it goes but, as Weisberg admits,\\nin its current form, it does not go very far. For one thing, it is\\nunclear how exactly explanatory considerations are to determine the\\nweights required for the second step of the proposal. For another, it\\nmay be idle to hope that taking explanatory considerations into\\naccount will in general leave us with a manageable set of partitions,\\nor that, even if it does, this will not be due merely to the fact that\\nwe are overlooking a great many prima facie plausible ways of\\npartitioning logical space to begin with. (The latter point echoes the\\nargument of the bad lot, of course.)\\n\\nAnother suggestion about the connection between abduction and Bayesian\\nreasoning—to be found in Okasha 2000, McGrew 2003, Lipton 2004\\n(Ch. 7), and Dellsén 2018—is that the explanatory\\nconsiderations may serve as a heuristic to determine, even if only\\nroughly, priors and likelihoods in cases in which we would otherwise\\nbe clueless and could do no better than guessing. This suggestion is\\nsensitive to the well-recognized fact that we are not always able to\\nassign a prior to every hypothesis of interest, or to say how probable\\na given piece of evidence is conditional on a given hypothesis.\\nConsideration of that hypothesis’ explanatory power might then\\nhelp us to figure out, if perhaps only within certain bounds, what\\nprior to assign to it, or what likelihood to assign to it on the given\\nevidence.\\n\\nBayesians, especially the more modest ones, might want to retort that\\nthe Bayesian procedure is to be followed if, and only if, either (a)\\npriors and likelihoods can be determined with some precision and\\nobjectivity, or (b) likelihoods can be determined with some precision\\nand priors can be expected to “wash out” as more and more\\nevidence accumulates, or (c) priors and likelihoods can both be\\nexpected to wash out. In the remaining cases—they might\\nsay—we should simply refrain from applying Bayesian reasoning. A\\nfortiori, then, there is no need for an abduction-enhanced Bayesianism\\nin these cases. And some incontrovertible mathematical results\\nindicate that, in the cases that fall under (a), (b), or (c), our\\nprobabilities will converge to the truth anyhow. Consequently, in\\nthose cases there is no need for the kind of abductive heuristics that\\nthe above-mentioned authors suggest, either. (Weisberg 2009, Sect.\\n3.2, raises similar concerns.)\\n\\nPsillos (2000) proposes yet another way in which abduction might\\nsupplement Bayesian confirmation theory, one that is very much in the\\nspirit of Peirce’s conception of abduction. The idea is that\\nabduction may assist us in selecting plausible candidates for testing,\\nwhere the actual testing then is to follow Bayesian lines. However,\\nPsillos concedes (2004) that this proposal assigns a role to abduction\\nthat will strike committed explanationists as being too limited.\\n\\nFinally, a possibility that has so far not been considered in the\\nliterature is that abduction and Bayesianism do not so much work in\\ntandem—as they do on the above proposals—as operate in\\ndifferent modes of reasoning; the Bayesian and the explanationist are\\ncharacters that feature in different plays, so to speak. It is widely\\naccepted that sometimes we speak and think about our beliefs in a\\ncategorical manner, while at other times we speak and think about them\\nin a graded way. It is far from clear how these different ways of\\nspeaking and thinking about beliefs—the epistemology of belief\\nand the epistemology of degrees of belief, to use Richard\\nFoley’s (1992) terminology—are related to one another. In\\nfact, it is an open question whether there is any straightforward\\nconnection between the two, or even whether there is a connection at\\nall. Be that as it may, given that the distinction is undeniable, it\\nis a plausible suggestion that, just as there are different ways of\\ntalking and thinking about beliefs, there are different ways of\\ntalking and thinking about the revision of beliefs. In\\nparticular, abduction could well have its home in the epistemology of\\nbelief, and be called upon whenever we reason about our beliefs in a\\ncategorical mode, while at the same time Bayes’ rule could have\\nits home in the epistemology of degrees of belief. Hard-nosed\\nBayesians may insist that whatever reasoning goes on in the\\ncategorical mode must eventually be justifiable in Bayesian terms, but\\nthis presupposes the existence of bridge principles connecting the\\nepistemology of belief with the epistemology of degrees of\\nbelief—and, as mentioned, whether such principles exist is\\npresently unclear.\\n4. Abduction versus Bayesian Confirmation Theory\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"main_text_str\"] = df.main_text.apply(cat_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main_text_str\n",
       "<class 'str'>    1776\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## see if df main_text_str is str everywhere\n",
    "\n",
    "df.main_text_str.apply(lambda x: type(x)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# turn on tqdm for pandas\n",
    "\n",
    "tqdm.pandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it locally if it's not already saved\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"phil_enc_df.csv\"):\n",
    "    df[\"main_text_str_len\"] = df.main_text_str.progress_apply(lambda x: len(np.array(tokenizer(x)[\"attention_mask\"])))\n",
    "    df.to_csv(\"phil_enc_df.csv\", index=False)\n",
    "else:\n",
    "    df = pd.read_csv(\"phil_enc_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(df[\"main_text_str_len\"]/df[\"main_text_str\"].str.len()).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12343"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"main_text_str_len\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# average length of the text\n",
    "\n",
    "df[\"main_text_str_len\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"main_text_str\"]\n",
    "    \n",
    "    \n",
    "## we want to split the text when you encounter a new chapter/subsection in the text, like 1. or 1.1. or 1.1.1. or 2.4 etc.\n",
    "example_main= df[\"main_text_str\"][0]\n",
    "import re\n",
    "\n",
    "def subchapter_splitter(text):\n",
    "    ## when you encounter a new chapter, split the text\n",
    "    ## new chapters look like 1. Sometitle, 1.1. Sometitle, 1.1.1. Sometitle, 2. Sometitle etc.\n",
    "    ## pattern should find all sentences that start with a number, followed by a dot (followed by a number followed by a dot etc) followed by a space, followed by a capital letter\n",
    "    pattern=r\"(?:^|\\n)\\d+(?:\\.\\d+)*\\.?\\s[A-Z].*\"\n",
    "    ## split it, but keep the separator included in the next element\n",
    "    splitted = re.split(f\"({pattern})\", text)\n",
    "    ## add the separator to the element after the separator\n",
    "    for i, split in enumerate(splitted):\n",
    "        if i % 2 == 1:\n",
    "            splitted[i+1] = split + splitted[i+1]\n",
    "            splitted[i] = \"\"\n",
    "    ## remove empty strings\n",
    "    splitted = [x for x in splitted if x]\n",
    "    return splitted\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "splitted=subchapter_splitter(example_main)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nYou happen to know that Tim and Harry have recently had a terrible row\\nthat ended their friendship. Now someone tells you that she just saw\\nTim and Harry jogging together. The best explanation for this that you\\ncan think of is that they made up. You conclude that they are friends\\nagain.\\n\\nOne morning you enter the kitchen to find a plate and cup on the\\ntable, with breadcrumbs and a pat of butter on it, and surrounded by a\\njar of jam, a pack of sugar, and an empty carton of milk. You conclude\\nthat one of your house-mates got up at night to make him- or herself a\\nmidnight snack and was too tired to clear the table. This, you think,\\nbest explains the scene you are facing. To be sure, it might be that\\nsomeone burgled the house and took the time to have a bite while on\\nthe job, or a house-mate might have arranged the things on the table\\nwithout having a midnight snack but just to make you believe that\\nsomeone had a midnight snack. But these hypotheses strike you as\\nproviding much more contrived explanations of the data than the one\\nyou infer to.\\n\\nWalking along the beach, you see what looks like a picture of Winston\\nChurchill in the sand. It could be that, as in the opening pages of\\nHilary Putnam’s book Reason, Truth, and History,\\n(1981), what you see is actually the trace of an ant crawling on the\\nbeach. The much simpler, and therefore (you think) much better,\\nexplanation is that someone intentionally drew a picture of Churchill\\nin the sand. That, in any case, is what you come away believing.\\n\\nIn these examples, the conclusions do not follow logically from the\\npremises. For instance, it does not follow logically that Tim and\\nHarry are friends again from the premises that they had a terrible row\\nwhich ended their friendship and that they have just been seen jogging\\ntogether; it does not even follow, we may suppose, from all the\\ninformation you have about Tim and Harry. Nor do you have any useful\\nstatistical data about friendships, terrible rows, and joggers that\\nmight warrant an inference from the information that you have about\\nTim and Harry to the conclusion that they are friends again, or even\\nto the conclusion that, probably (or with a certain probability), they\\nare friends again. What leads you to the conclusion, and what\\naccording to a considerable number of philosophers may also warrant\\nthis conclusion, is precisely the fact that Tim and Harry’s\\nbeing friends again would, if true, best explain the\\nfact that they have just been seen jogging together. (The proviso that\\na hypothesis be true if it is to explain anything is taken as read\\nfrom here on.) Similar remarks apply to the other two examples. The\\ntype of inference exhibited here is called abduction or,\\nsomewhat more commonly nowadays, Inference to the Best\\nExplanation.',\n",
       " '\\n1. Abduction: The General Idea\\n\\nAbduction is normally thought of as being one of three major types of\\ninference, the other two being deduction and induction. The\\ndistinction between deduction, on the one hand, and induction and\\nabduction, on the other hand, corresponds to the distinction between\\nnecessary and non-necessary inferences. In deductive inferences, what\\nis inferred is necessarily true if the premises from which it\\nis inferred are true; that is, the truth of the premises\\nguarantees the truth of the conclusion. A familiar type of\\nexample is inferences instantiating the schema\\n\\nAll As are Bs.\\n\\na is an A.\\n\\nHence, a is a B.\\n\\n\\nBut not all inferences are of this variety. Consider, for instance,\\nthe inference of “John is rich” from “John lives in\\nChelsea” and “Most people living in Chelsea are\\nrich.” Here, the truth of the first sentence is not guaranteed\\n(but only made likely) by the joint truth of the second and third\\nsentences. Differently put, it is not necessarily the case that if the\\npremises are true, then so is the conclusion: it is logically\\ncompatible with the truth of the premises that John is a member of the\\nminority of non-rich inhabitants of Chelsea. The case is similar\\nregarding your inference to the conclusion that Tim and Harry are\\nfriends again on the basis of the information that they have been seen\\njogging together. Perhaps Tim and Harry are former business partners\\nwho still had some financial matters to discuss, however much they\\nwould have liked to avoid this, and decided to combine this with their\\ndaily exercise; this is compatible with their being firmly decided\\nnever to make up.\\n\\nIt is standard practice to group non-necessary inferences into\\ninductive and abductive ones. Inductive inferences\\nform a somewhat heterogeneous class, but for present purposes they may\\nbe characterized as those inferences that are based purely on\\nstatistical data, such as observed frequencies of occurrences of a\\nparticular feature in a given population. An example of such an\\ninference would be this:\\n\\n96 per cent of the Flemish college students speak both Dutch and\\nFrench.\\n\\nLouise is a Flemish college student.\\n\\nHence, Louise speaks both Dutch and French.\\n\\n\\nHowever, the relevant statistical information may also be more vaguely\\ngiven, as in the premise, “Most people living in Chelsea are\\nrich.” (There is much discussion about whether the conclusion of\\nan inductive argument can be stated in purely qualitative terms or\\nwhether it should be a quantitative one—for instance, that it\\nholds with a probability of .96 that Louise speaks both Dutch and\\nFrench—or whether it can sometimes be stated in\\nqualitative terms—for instance, if the probability that it is\\ntrue is high enough—and sometimes not. On these and other issues\\nrelated to induction, see Kyburg 1990 (Ch. 4). It should also be\\nmentioned that Harman (1965) conceives induction as a special type of\\nabduction. See also Weintraub 2013 for discussion.)\\n\\nThe mere fact that an inference is based on statistical data is not\\nenough to classify it as an inductive one. You may have observed many\\ngray elephants and no non-gray ones, and infer from this that all\\nelephants are gray, because that would provide the best\\nexplanation for why you have observed so many gray elephants\\nand no non-gray ones. This would be an instance of an\\nabductive inference. It suggests that the best way to distinguish\\nbetween induction and abduction is this: both are ampliative,\\nmeaning that the conclusion goes beyond what is (logically) contained\\nin the premises (which is why they are non-necessary inferences), but\\nin abduction there is an implicit or explicit appeal to explanatory\\nconsiderations, whereas in induction there is not; in induction, there\\nis only an appeal to observed frequencies or statistics. (I\\nemphasize “only,” because in abduction there may also be\\nan appeal to frequencies or statistics, as the example about the\\nelephants exhibits.)\\n\\nA noteworthy feature of abduction, which it shares with induction but\\nnot with deduction, is that it violates monotonicity, meaning\\nthat it may be possible to infer abductively certain conclusions from\\na subset of a set S of premises which cannot be\\ninferred abductively from S as a whole. For instance, adding\\nthe premise that Tim and Harry are former business partners who still\\nhave some financial matters to discuss, to the premises that they had\\na terrible row some time ago and that they were just seen jogging\\ntogether may no longer warrant you to infer that they are friends\\nagain, even if—let us suppose—the last two premises alone\\ndo warrant that inference. The reason is that what counts as the best\\nexplanation of Tim and Harry’s jogging together in light of the\\noriginal premises may no longer do so once the information has been\\nadded that they are former business partners with financial matters to\\ndiscuss.',\n",
       " '\\n1.1 Deduction, induction, abduction\\n\\nThe type of inference exemplified in the cases described at the\\nbeginning of this entry will strike most as entirely familiar.\\nPhilosophers as well as psychologists tend to agree that abduction is\\nfrequently employed in everyday reasoning. Sometimes our reliance on\\nabductive reasoning is quite obvious and explicit. But in some daily\\npractices, it may be so routine and automatic that it easily goes\\nunnoticed. A case in point may be our trust in other people’s\\ntestimony, which has been said to rest on abductive reasoning; see\\nHarman 1965, Adler 1994, Fricker 1994, and Lipton 1998 for defenses of\\nthis claim. For instance, according to Jonathan Adler (1994, 274f),\\n“[t]he best explanation for why the informant asserts that\\nP is normally that … he believes it for duly responsible\\nreasons and … he intends that I shall believe it too,”\\nwhich is why we are normally justified in trusting the\\ninformant’s testimony. This may well be correct, even though in\\ncoming to trust a person’s testimony one does not normally seem\\nto be aware of any abductive reasoning going on in one’s mind.\\nSimilar remarks may apply to what some hold to be a further, possibly\\neven more fundamental, role of abduction in linguistic practice, to\\nwit, its role in determining what a speaker means by an utterance.\\nSpecifically, it has been argued that decoding utterances is a matter\\nof inferring the best explanation of why someone said what he or she\\nsaid in the context in which the utterance was made. Even more\\nspecifically, authors working in the field of pragmatics have\\nsuggested that hearers invoke the Gricean maxims of conversation to\\nhelp them work out the best explanation of a speaker’s utterance\\nwhenever the semantic content of the utterance is insufficiently\\ninformative for the purposes of the conversation, or is too\\ninformative, or off-topic, or implausible, or otherwise odd or\\ninappropriate; see, for instance, Bach and Harnish 1979 (92f), Dascal\\n1979 (167), and Hobbs 2004. As in cases of reliance on speaker\\ntestimony, the requisite abductive reasoning would normally seem to\\ntake place at a subconscious level.\\n\\nAbductive reasoning is not limited to everyday contexts. Quite the\\ncontrary: philosophers of science have argued that abduction is a\\ncornerstone of scientific methodology; see, for instance, Boyd 1981,\\n1984, Harré 1986, 1988, Lipton 1991, 2004, and Psillos 1999.\\nAccording to Timothy Williamson (2007), “[t]he abductive\\nmethodology is the best science provides” and Ernan McMullin\\n(1992) even goes so far to call abduction “the inference that\\nmakes science.” To illustrate the use of abduction in science,\\nwe consider two examples.\\n\\nAt the beginning of the nineteenth century, it was discovered that the\\norbit of Uranus, one of the seven planets known at the time, departed\\nfrom the orbit as predicted on the basis of Isaac Newton’s\\ntheory of universal gravitation and the auxiliary assumption that\\nthere were no further planets in the solar system. One possible\\nexplanation was, of course, that Newton’s theory is false. Given\\nits great empirical successes for (then) more than two centuries, that\\ndid not appear to be a very good explanation. Two astronomers, John\\nCouch Adams and Urbain Leverrier, instead suggested (independently of\\neach other but almost simultaneously) that there was an eighth, as yet\\nundiscovered planet in the solar system; that, they thought, provided\\nthe best explanation of Uranus’ deviating orbit. Not much later,\\nthis planet, which is now known as “Neptune,” was\\ndiscovered.\\n\\nThe second example concerns what is now commonly regarded to have been\\nthe discovery of the electron by the English physicist Joseph John\\nThomson. Thomson had conducted experiments on cathode rays in order to\\ndetermine whether they are streams of charged particles. He concluded\\nthat they are indeed, reasoning as follows:\\n\\n\\n\\nAs the cathode rays carry a charge of negative electricity, are\\ndeflected by an electrostatic force as if they were negatively\\nelectrified, and are acted on by a magnetic force in just the way in\\nwhich this force would act on a negatively electrified body moving\\nalong the path of these rays, I can see no escape from the conclusion\\nthat they are charges of negative electricity carried by particles of\\nmatter. (Thomson, cited in Achinstein 2001, 17)\\n\\n\\nThe conclusion that cathode rays consist of negatively charged\\nparticles does not follow logically from the reported experimental\\nresults, nor could Thomson draw on any relevant statistical data. That\\nnevertheless he could “see no escape from the conclusion”\\nis, we may safely assume, because the conclusion is the best—in\\nthis case presumably even the only plausible—explanation of his\\nresults that he could think of.\\n\\nMany other examples of scientific uses of abduction have been\\ndiscussed in the literature; see, for instance, Harré 1986,\\n1988 and Lipton 1991, 2004. Abduction is also said to be the\\npredominant mode of reasoning in medical diagnosis: physicians tend to\\ngo for the hypothesis that best explains the patient’s symptoms\\n(see Josephson and Josephson (eds.) 1994, 9–12; see also\\nDragulinescu 2016 on abductive reasoning in the context of\\nmedicine).\\n\\nLast but not least, abduction plays a central role in some important\\nphilosophical debates. See Shalkowski 2010 on the place of abduction\\nin metaphysics (also Bigelow 2010), Krzyżanowska, Wenmackers, and\\nDouven 2014 and Douven 2016a for a possible role of\\nabduction in the semantics of conditionals, and Williamson\\n2017 for an application of abduction in the philosophy of logic.\\nArguably, however, abduction plays its most notable philosophical role\\nin epistemology and in the philosophy of science, where it is\\nfrequently invoked in objections to so-called underdetermination\\narguments. Underdetermination arguments generally start from the\\npremise that a number of given hypotheses are empirically equivalent,\\nwhich their authors take to mean that the evidence—indeed, any\\nevidence we might ever come to possess—is unable to favor one of\\nthem over the others. From this, we are supposed to conclude that one\\ncan never be warranted in believing any particular one of the\\nhypotheses. (This is rough, but it will do for present purposes; see\\nDouven 2008 and Stanford 2009, for more detailed accounts of\\nunderdetermination arguments.) A famous instance of this type of\\nargument is the Cartesian argument for global skepticism, according to\\nwhich the hypothesis that reality is more or less the way we\\ncustomarily deem it to be is empirically equivalent to a variety of\\nso-called skeptical hypotheses (such as that we are beguiled by an\\nevil demon, or that we are brains in a vat, connected to a\\nsupercomputer; see, e.g., Folina 2016). Similar arguments have been\\ngiven in support of scientific antirealism, according to which it will\\nnever be warranted for us to choose between empirically equivalent\\nrivals concerning what underlies the observable part of reality (van\\nFraassen 1980).\\n\\nResponses to these arguments typically point to the fact that the\\nnotion of empirical equivalence at play unduly neglects explanatory\\nconsiderations, for instance, by defining the notion strictly in terms\\nof hypotheses’ making the same predictions. Those responding\\nthen argue that even if some hypotheses make exactly the same\\npredictions, one of them may still be a better explanation of the\\nphenomena predicted. Thus, if explanatory considerations have a role\\nin determining which inferences we are licensed to make—as\\naccording to defenders of abduction they have—then we might\\nstill be warranted in believing in the truth (or probable truth, or\\nsome such, depending—as will be seen below—on the version\\nof abduction one assumes) of one of a number of hypotheses that all\\nmake the same predictions. Following Bertrand Russell (1912, Ch. 2),\\nmany epistemologists have invoked abduction in arguing against\\nCartesian skepticism, their key claim being that even though, by\\nconstruction, the skeptical hypotheses make the same predictions as\\nthe hypothesis that reality is more or less the way we ordinarily take\\nit to be, they are not equally good explanations of what they predict;\\nin particular, the skeptical hypotheses have been said to be\\nconsiderably less simple than the “ordinary world”\\nhypothesis. See, among many others, Harman 1973 (Chs. 8 and 11),\\nGoldman 1988 (205), Moser 1989 (161), and Vogel 1990, 2005; see\\nPargetter 1984 for an abductive response specifically to skepticism\\nregarding other minds. Similarly, philosophers of science have argued\\nthat we are warranted to believe in Special Relativity Theory as\\nopposed to Lorentz’s version of the æther theory. For even\\nthough these theories make the same predictions, the former is\\nexplanatorily superior to the latter. (Most arguments that have been\\ngiven for this claim come down to the contention that Special\\nRelativity Theory is ontologically more parsimonious than its\\ncompetitor, which postulates the existence of an æther. See\\nJanssen 2002 for an excellent discussion of the various reasons\\nphilosophers of science have adduced for preferring Einstein’s\\ntheory to Lorentz’s.)',\n",
       " '\\n1.2 The ubiquity of abduction\\n\\nPrecise statements of what abduction amounts to are rare in the\\nliterature on abduction. (Peirce did propose an at least fairly\\nprecise statement; but, as explained in the supplement to this entry,\\nit does not capture what most nowadays understand by abduction.) Its\\ncore idea is often said to be that explanatory considerations have\\nconfirmation-theoretic import, or that explanatory success is a (not\\nnecessarily unfailing) mark of truth. Clearly, however, these\\nformulations are slogans at best, and it takes little effort to see\\nthat they can be cashed out in a great variety of prima facie\\nplausible ways. Here we will consider a number of such possible\\nexplications, starting with what one might term the “textbook\\nversion of abduction,” which, as will be seen, is manifestly\\ndefective, and then going on to consider various possible refinements\\nof it. What those versions have in\\ncommon—unsurprisingly—is that they are all inference\\nrules, requiring premises encompassing explanatory considerations and\\nyielding a conclusion that makes some statement about the truth of a\\nhypothesis. The differences concern the premises that are required, or\\nwhat exactly we are allowed to infer from them (or both).\\n\\nIn textbooks on epistemology or the philosophy of science, one often\\nencounters something like the following as a formulation of\\nabduction:\\n\\nAn observation that is frequently made about this rule, and that\\npoints to a potential problem for it, is that it presupposes the\\nnotions of candidate explanation and best explanation, neither of\\nwhich has a straightforward interpretation. While some still hope that\\nthe former can be spelled out in purely logical, or at least purely\\nformal, terms, it is often said that the latter must appeal to the\\nso-called theoretical virtues, like simplicity, generality, and\\ncoherence with well-established theories; the best explanation would\\nthen be the hypothesis which, on balance, does best with respect to\\nthese virtues. (See, for instance, Thagard 1978 and McMullin 1996.)\\nThe problem is that none of the said virtues is presently particularly\\nwell understood. (Giere, in Callebaut (ed.) 1993 (232), even makes the\\nradical claim that the theoretical virtues lack real content and play\\nno more than a rhetorical role in science. In view of recent formal\\nwork both on simplicity and on coherence—for instance, Forster\\nand Sober 1994, Li and Vitanyi 1997, and Sober 2015, on simplicity and\\nBovens and Hartmann 2003 and Olsson 2005, on coherence—the first\\npart of this claim has become hard to maintain; also, Schupbach and\\nSprenger (2011) present an account of explanatory goodness directly in\\nprobabilistic terms. Psychological evidence casts doubt on the second\\npart of the claim; see, for instance, Lombrozo 2007, on the role of\\nsimplicity in people’s assessments of explanatory goodness and\\nKoslowski et al. 2008, on the role of coherence with\\nbackground knowledge in those assessments.)\\n\\nFurthermore, many of those who think ABD1 is headed along the right\\nlines believe that it is too strong. Some think that abduction\\nwarrants an inference only to the probable truth of the best\\nexplanation, others that it warrants an inference only to the\\napproximate truth of the best explanation, and still others\\nthat it warrants an inference only to the probable\\napproximate truth.\\n\\nThe real problem with ABD1 runs deeper than this, however. Because\\nabduction is ampliative—as explained earlier—it will not\\nbe a sound rule of inference in the strict logical sense, however\\nabduction is explicated exactly. It can still be reliable in\\nthat it mostly leads to a true conclusion whenever the premises are\\ntrue. An obvious necessary condition for ABD1 to be reliable in this\\nsense is that, mostly, when it is true that H best\\nexplains E, and E is true, then H is true as well\\n(or H is approximately true, or probably true, or probably\\napproximately true). But this would not be enough for ABD1 to\\nbe reliable. For ABD1 takes as its premise only that some hypothesis\\nis the best explanation of the evidence as compared to other\\nhypotheses in a given set. Thus, if the rule is to be\\nreliable, it must hold that, at least typically, the best explanation\\nrelative to the set of hypotheses that we consider would also come out\\nas being best in comparison with any other hypotheses that we might\\nhave conceived (but for lack of time or ingenuity, or for some other\\nreason, did not conceive). In other words, it must hold that at least\\ntypically the absolutely best explanation of the evidence is\\nto be found among the candidate explanations we have come up with, for\\nelse ABD1 may well lead us to believe “the best of a bad\\nlot” (van Fraassen 1989, 143).\\n\\nHow reasonable is it to suppose that this extra requirement is usually\\nfulfilled? Not at all, presumably. To believe otherwise, we must\\nassume some sort of privilege on our part to the effect that when we\\nconsider possible explanations of the data, we are somehow predisposed\\nto hit, inter alia, upon the absolutely best explanation of those\\ndata. After all, hardly ever will we have considered, or will it even\\nbe possible to consider, all potential explanations. As van\\nFraassen (1989, 144) points out, it is a priori rather\\nimplausible to hold that we are thus privileged.\\n\\nIn response to this, one might argue that the challenge to show that\\nthe best explanation is always or mostly among the hypotheses\\nconsidered can be met without having to assume some form of privilege\\n(see Schupbach 2014 for a different response, and see Dellsén\\n2017 for discussion). For given the hypotheses we have managed to come\\nup with, we can always generate a set of hypotheses which jointly\\nexhaust logical space. Suppose\\nH1,…,Hn are the\\ncandidate explanations we have so far been able to conceive. Then\\nsimply define Hn+1 := ¬H1\\n∧ … ∧ ¬Hn and add this new\\nhypothesis as a further candidate explanation to the ones we already\\nhave. Obviously, the set\\n{H1,…,Hn+1} is exhaustive,\\nin that one of its elements must be true. Following this in itself\\nsimple procedure would seem enough to make sure that we never miss out\\non the absolutely best explanation. (See Lipton 1993, for a proposal\\nalong these lines.)\\n\\nAlas, there is a catch. For even though there may be many hypotheses\\nHj that imply Hn+1 and, had\\nthey been formulated, would have been evaluated as being a better\\nexplanation for the data than the best explanation among the candidate\\nexplanations we started out with, Hn+1 itself will\\nin general be hardly informative; in fact, in general it will not even\\nbe clear what its empirical consequences are. Suppose, for instance,\\nwe have as competing explanations Special Relativity Theory and\\nLorentz’s version of the æther theory. Then, following the\\nabove proposal, we may add to our candidate explanations that neither\\nof these two theories is true. But surely this further hypothesis will\\nbe ranked quite low qua explanation—if it will be\\nranked at all, which seems doubtful, given that it is wholly unclear\\nwhat its empirical consequences are. This is not to say that the\\nsuggested procedure may never work. The point is that in general it\\nwill give little assurance that the best explanation is among the\\ncandidate explanations we consider.\\n\\nA more promising response to the above “argument of the bad\\nlot” begins with the observation that the argument capitalizes\\non a peculiar asymmetry or incongruence in ABD1. The rule gives\\nlicense to an absolute conclusion—that a given hypothesis is\\ntrue—on the basis of a comparative premise, namely, that that\\nparticular hypothesis is the best explanation of the evidence relative\\nto the other hypotheses available (see Kuipers 2000, 171). This\\nincongruence is not avoided by replacing “truth” with\\n“probable truth” or “approximate truth.” In\\norder to avoid it, one has two general options.\\n\\nThe first option is to modify the rule so as to have it require an\\nabsolute premise. For instance, following Alan Musgrave (1988) or\\nPeter Lipton (1993), one may require the hypothesis whose truth is\\ninferred to be not only the best of the available potential\\nexplanations, but also to be satisfactory (Musgrave) or\\ngood enough (Lipton), yielding the following variant of\\nABD1:\\n\\nNeedless to say, ABD2 needs supplementing by a criterion for the\\nsatisfactoriness of explanations, or their being good enough, which,\\nhowever, we are still lacking.\\n\\nSecondly, one can formulate a symmetric or congruous version of\\nabduction by having it sanction, given a comparative premise, only a\\ncomparative conclusion; this option, too, can in turn be realized in\\nmore than one way. Here is one way to do it, which has been proposed\\nand defended in the work of Theo Kuipers (e.g., Kuipers 1984, 1992,\\n2000).\\n\\nClearly, ABD3 requires an account of closeness to the truth, but many\\nsuch accounts are on offer today (see, e.g., Niiniluoto 1998).\\n\\nOne noteworthy feature of the congruous versions of abduction\\nconsidered here is that they do not rely on the assumption of an\\nimplausible privilege on the reasoner’s part that, we saw, ABD1\\nimplicitly relies on. Another is that if one can be certain that,\\nhowever many candidate explanations for the data one may have missed,\\nnone equals the best of those one has thought of, then the\\ncongruous versions license exactly the same inference as ABD1 does\\n(supposing that one would not be certain that no potential explanation\\nis as good as the best explanation one has thought of if the latter is\\nnot even satisfactory or sufficiently good).\\n\\nAs mentioned, there is widespread agreement that people frequently\\nrely on abductive reasoning. Which of the above rules exactly\\nis it that people rely on? Or might it be still some further rule that\\nthey rely on? Or might they in some contexts rely on one version, and\\nin others on another (Douven 2017, forthcoming)? Philosophical\\nargumentation is unable to answer these questions. In recent years,\\nexperimental psychologists have started paying attention to the role\\nhumans give to explanatory considerations in reasoning. For instance,\\nTania Lombrozo and Nicholas Gwynne (2014) report experiments showing\\nthat how a property of a given class of things is explained\\nto us—whether mechanistically, by reference to parts and\\nprocesses, or functionally, by reference to functions and\\npurposes—matters to how likely we are to generalise that\\nproperty to other classes of things (see also Sloman 1994 and Williams\\nand Lombrozo 2010). And Igor Douven and Jonah Schupbach (2015a),\\n(2015b) present experimental evidence to the effect that\\npeople’s probability updates tend to be influenced by\\nexplanatory considerations in ways that makes them deviate from\\nstrictly Bayesian updates (see below). Douven (2016b) shows that, in\\nthe aforementioned experiments, participants who gave more weight to\\nexplanatory considerations tended to be more accurate, as determined\\nin terms of a standard scoring rule. (See Lombrozo 2012 and 2016 for\\nuseful overviews of recent experimental work relevant to explanation\\nand inference.) Douven and Patricia Mirabile (2018) found some\\nevidence indicating that people rely on something like ABD2, at least\\nin some contexts, but for the most part, empirical work on the\\nabove-mentioned questions is lacking.\\n\\nWith respect to the normative question of which of the previously\\nstated rules we ought to rely on (if we ought to rely on any\\nform of abduction), where philosophical argumentation should be able\\nto help, the situation is hardly any better. In view of the argument\\nof the bad lot, ABD1 does not look very good. Other arguments against\\nabduction are claimed to be independent of the exact explication of\\nthe rule; below, these arguments will be found wanting. On the other\\nhand, arguments that have been given in favor of abduction—some\\nof which will also be discussed below—do not discern between\\nspecific versions. So, supposing people do indeed commonly rely on\\nabduction, it must be considered an open question as to which\\nversion(s) of abduction they rely on. Equally, supposing it is\\nrational for people to rely on abduction, it must be considered an\\nopen question as to which version, or perhaps versions, of abduction\\nthey ought to, or are at least permitted to, rely on.',\n",
       " '\\n2. Explicating Abduction\\n\\nEven if it is true that we routinely rely on abductive reasoning, it\\nmay still be asked whether this practice is rational. For instance,\\nexperimental studies have shown that when people are able to think of\\nan explanation for some possible event, they tend to overestimate the\\nlikelihood that this event will actually occur. (See Koehler 1991, for\\na survey of some of these studies; see also Brem and Rips 2000.) More\\ntelling still, Lombrozo (2007) shows that, in some situations, people\\ntend to grossly overrate the probability of simpler explanations\\ncompared to more complicated ones. Although these studies are not\\ndirectly concerned with abduction in any of the forms discussed so\\nfar, they nevertheless suggest that taking into account explanatory\\nconsiderations in one’s reasoning may not always be for the\\nbetter. (It is to be noted that Lombrozo’s experiments\\nare directly concerned with some proposals that have been\\nmade for explicating abduction in a Bayesian framework; see Section\\n4.) However, the most pertinent remarks about the normative status of\\nabduction are so far to be found in the philosophical literature. This\\nsection discusses the main criticisms that have been levelled against\\nabduction, as well as the strongest arguments that have been given in\\nits defense.',\n",
       " '\\n3. The Status of Abduction\\n\\nWe have already encountered the so-called argument of the bad lot,\\nwhich, we saw, is valid as a criticism of ABD1 but powerless against\\nvarious (what we called) congruous rules of abduction. We here\\nconsider two objections that are meant to be more general. The first\\neven purports to challenge the core idea underlying abduction; the\\nsecond is not quite as general, but it is still meant to undermine a\\nbroad class of candidate explications of abduction. Both objections\\nare due to Bas van Fraassen.\\n\\nThe first objection has as a premise that it is part of the meaning of\\n“explanation” that if one theory is more explanatory than\\nanother, the former must be more informative than the latter (see,\\ne.g., van Fraassen 1983, Sect. 2). The alleged problem then is that it\\nis “an elementary logical point that a more informative theory\\ncannot be more likely to be true [and thus] attempts to describe\\ninductive or evidential support through features that require\\ninformation (such as ‘Inference to the Best Explanation’)\\nmust either contradict themselves or equivocate” (van Fraassen\\n1989, 192). The elementary logical point is supposed to be “most\\n[obvious] … in the paradigm case in which one theory is an\\nextension of another: clearly the extension has more ways of being\\nfalse” (van Fraassen 1985, 280).\\n\\nIt is important to note, however, that in any other kind of case than\\nthe “paradigm” one, the putative elementary point is not\\nobvious at all. For instance, it is entirely unclear in what sense\\nSpecial Relativity Theory “has more ways of being false”\\nthan Lorentz’s version of the æther theory, given that\\nthey make the same predictions. And yet the former is generally\\nregarded as being superior, qua explanation, to the latter.\\n(If van Fraassen were to object that the former is not really more\\ninformative than the latter, or at any rate not more informative in\\nthe appropriate sense—whatever that is—then we should\\ncertainly refuse to grant the premise that in order to be more\\nexplanatory a theory must be more informative.)\\n\\nThe second objection, proffered in van Fraassen 1989 (Ch. 6), is\\nlevelled at probabilistic versions of abduction. The objection is that\\nsuch rules must either amount to Bayes’ rule, and thus be\\nredundant, or be at variance with it but then, on the grounds of\\nLewis’ dynamic Dutch book argument (as reported in Teller 1973),\\nbe probabilistically incoherent, meaning that they may lead one to\\nassess as fair a number of bets which together ensure a financial\\nloss, come what may; and, van Fraassen argues, it would be irrational\\nto follow a rule that has this feature.\\n\\nHowever, this objection fares no better than the first. For one thing,\\nas Patrick Maher (1992) and Brian Skyrms (1993) have pointed out, a\\nloss in one respect may be outweighed by a benefit in another. It\\nmight be, for instance, that some probabilistic version of abduction\\ndoes much better, at least in our world, than Bayes’ rule, in\\nthat, on average, it approaches the truth faster in the sense that it\\nis faster in assigning a high probability (understood as probability\\nabove a certain threshold value) to the true hypothesis (see Douven\\n2013, 2020, and Douven and Wenmackers 2017; see Climenhaga\\n2017 for discussion). If it does, then following that rule\\ninstead of Bayes’ rule may have advantages which perhaps are not\\nso readily expressed in terms of money yet which should arguably be\\ntaken into account when deciding which rule to go by. It is, in short,\\nnot so clear whether following a probabilistically incoherent rule\\nmust be irrational.\\n\\nFor another thing, Douven (1999) argues that the question of whether a\\nprobabilistic rule is coherent is not one that can be settled\\nindependently of considering which other epistemic and\\ndecision-theoretic rules are deployed along with it; coherence should\\nbe understood as a property of packages of both epistemic and\\ndecision-theoretic rules, not of epistemic rules (such as\\nprobabilistic rules for belief change) in isolation. In the same\\npaper, a coherent package of rules is described which includes a\\nprobabilistic version of abduction. (See Kvanvig 1994, Harman 1997,\\nLeplin 1997, Niiniluoto 1999, and Okasha 2000, for different responses\\nto van Fraassen’s critique of probabilistic versions of\\nabduction.)',\n",
       " '\\n3.1 Criticisms\\n\\nHardly anyone nowadays would want to subscribe to a conception of\\ntruth that posits a necessary connection between explanatory force and\\ntruth—for instance, because it stipulates explanatory\\nsuperiority to be necessary for truth. As a result, a priori defenses\\nof abduction seem out of the question. Indeed, all defenses that have\\nbeen given so far are of an empirical nature in that they appeal to\\ndata that supposedly support the claim that (in some form) abduction\\nis a reliable rule of inference.\\n\\nThe best-known argument of this sort was developed by Richard Boyd in\\nthe 1980s (see Boyd 1981, 1984, 1985). It starts by underlining the\\ntheory-dependency of scientific methodology, which comprises methods\\nfor designing experiments, for assessing data, for choosing between\\nrival hypotheses, and so on. For instance, in considering possible\\nconfounding factors from which an experimental setup has to be\\nshielded, scientists draw heavily on already accepted theories. The\\nargument next calls attention to the apparent reliability of this\\nmethodology, which, after all, has yielded, and continues to yield,\\nimpressively accurate theories. In particular, by relying on this\\nmethodology, scientists have for some time now been able to find ever\\nmore instrumentally adequate theories. Boyd then argues that the\\nreliability of scientific methodology is best explained by assuming\\nthat the theories on which it relies are at least approximately true.\\nFrom this and from the fact that these theories were mostly arrived at\\nby abductive reasoning, he concludes that abduction must be a reliable\\nrule of inference.\\n\\nCritics have accused this argument of being circular. Specifically, it\\nhas been said that the argument rests on a premise—that\\nscientific methodology is informed by approximately true background\\ntheories—which in turn rests on an inference to the best\\nexplanation for its plausibility. And the reliability of this type of\\ninference is precisely what is at stake. (See, for instance, Laudan\\n1981 and Fine 1984.)\\n\\nTo this, Stathis Psillos (1999, Ch. 4) has responded by invoking a\\ndistinction credited to Richard Braithwaite, to wit, the distinction\\nbetween premise-circularity and rule-circularity. An argument is\\npremise-circular if its conclusion is amongst its premises. A\\nrule-circular argument, by contrast, is an argument of which the\\nconclusion asserts something about an inferential rule that is used in\\nthe very same argument. As Psillos urges, Boyd’s argument is\\nrule-circular, but not premise-circular, and rule-circular arguments,\\nPsillos contends, need not be viciously circular (even though\\na premise-circular argument is always viciously circular). To be more\\nprecise, in his view, an argument for the reliability of a given rule\\nR that essentially relies on R as an inferential\\nprinciple is not vicious, provided that the use of R does not\\nguarantee a positive conclusion about R’s reliability.\\nPsillos claims that in Boyd’s argument, this proviso is met. For\\nwhile Boyd concludes that the background theories on which scientific\\nmethodology relies are approximately true on the basis of an abductive\\nstep, the use of abduction itself does not guarantee the truth of his\\nconclusion. After all, granting the use of abduction does nothing to\\nensure that the best explanation of the success of scientific\\nmethodology is the approximate truth of the relevant background\\ntheories. Thus, Psillos concludes, Boyd’s argument still\\nstands.\\n\\nEven if the use of abduction in Boyd’s argument might have led\\nto the conclusion that abduction is not reliable, one may\\nstill have worries about the argument’s being rule-circular. For\\nsuppose that some scientific community relied not on abduction but on\\na rule that we may dub “Inference to the Worst\\nExplanation” (IWE), a rule that sanctions inferring to the\\nworst explanation of the available data. We may safely assume\\nthat the use of this rule mostly would lead to the adoption of very\\nunsuccessful theories. Nevertheless, the said community might justify\\nits use of IWE by dint of the following reasoning: “Scientific\\ntheories tend to be hugely unsuccessful. These theories were arrived\\nat by application of IWE. That IWE is a reliable rule of\\ninference—that is, a rule of inference mostly leading from true\\npremises to true conclusions—is surely the worst explanation of\\nthe fact that our theories are so unsuccessful. Hence, by application\\nof IWE, we may conclude that IWE is a reliable rule of\\ninference.” While this would be an utterly absurd conclusion,\\nthe argument leading up to it cannot be convicted of being viciously\\ncircular anymore than Boyd’s argument for the reliability of\\nabduction can (if Psillos is right). It would appear, then, that there\\nmust be something else amiss with rule-circularity.\\n\\nIt is fair to note that for Psillos, the fact that a rule-circular\\nargument does not guarantee a positive conclusion about the rule at\\nissue is not sufficient for such an argument to be valid. A further\\nnecessary condition is “that one should not have reason to doubt\\nthe reliability of the rule—that there is nothing currently\\navailable which can make one distrust the rule” (Psillos 1999,\\n85). And there is plenty of reason to doubt the reliability of IWE; in\\nfact, the above argument supposes that it is unreliable. Two\\nquestions arise, however. First, why should we accept the additional\\ncondition? Second, do we really have no reason to doubt the\\nreliability of abduction? Certainly some of the abductive\\ninferences we make lead us to accept falsehoods. How many\\nfalsehoods may we accept on the basis of abduction before we can\\nlegitimately begin to distrust this rule? No clear answers have been\\ngiven to these questions.\\n\\nBe this as it may, even if rule-circularity is neither vicious nor\\notherwise problematic, one may still wonder how Boyd’s argument\\nis to convert a critic of abduction, given that it relies on\\nabduction. But Psillos makes it clear that the point of philosophical\\nargumentation is not always, and in any case need not be, to convince\\nan opponent of one’s position. Sometimes the point is, more\\nmodestly, to assure or reassure oneself that the position one\\nendorses, or is tempted to endorse, is correct. In the case at hand,\\nwe need not think of Boyd’s argument as an attempt to convince\\nthe opponent of abduction of its reliability. Rather, it may be\\nthought of as justifying the rule from within the perspective of\\nsomeone who is already sympathetic towards abduction; see Psillos 1999\\n(89).\\n\\nThere have also been attempts to argue for abduction in a more\\nstraightforward fashion, to wit, via enumerative induction. The common\\nidea of these attempts is that every newly recorded successful\\napplication of abduction—like the discovery of Neptune, whose\\nexistence had been postulated on explanatory grounds (see Section\\n1.2)—adds further support to the hypothesis that abduction is a\\nreliable rule of inference, in the way in which every newly observed\\nblack raven adds some support to the hypothesis that all ravens are\\nblack. Because it does not involve abductive reasoning, this type of\\nargument is more likely to also appeal to disbelievers in abduction.\\nSee Harré 1986, 1988, Bird 1998 (160), Kitcher 2001, and Douven\\n2002 for suggestions along these lines.',\n",
       " '\\n3.2 Defenses\\n\\nIn the past decade, Bayesian confirmation theory has firmly\\nestablished itself as the dominant view on confirmation; currently one\\ncannot very well discuss a confirmation-theoretic issue without making\\nclear whether, and if so why, one’s position on that issue\\ndeviates from standard Bayesian thinking. Abduction, in whichever\\nversion, assigns a confirmation-theoretic role to explanation:\\nexplanatory considerations contribute to making some hypotheses more\\ncredible, and others less so. By contrast, Bayesian confirmation\\ntheory makes no reference at all to the concept of explanation. Does\\nthis imply that abduction is at loggerheads with the prevailing\\ndoctrine in confirmation theory? Several authors have recently argued\\nthat not only is abduction compatible with Bayesianism, it is a\\nmuch-needed supplement to it. The so far fullest defense of this view\\nhas been given by Lipton (2004, Ch. 7); as he puts it, Bayesians\\nshould also be “explanationists” (his name for the\\nadvocates of abduction). (For other defenses, see Okasha 2000, McGrew\\n2003, Weisberg 2009, and Poston 2014, Ch. 7; for discussion, see Roche\\nand Sober 2013, 2014, and McCain and Poston 2014.)\\n\\nThis requires some clarification. For what could it mean for a\\nBayesian to be an explanationist? In order to apply Bayes’ rule\\nand determine the probability for H after learning E,\\nthe Bayesian agent will have to determine the probability of H\\nconditional on E. For that, he needs to assign unconditional\\nprobabilities to H and E as well as a probability to\\nE given H; the former two are mostly called “prior\\nprobabilities” (or just “priors”) of, respectively,\\nH and E, the latter the “likelihood” of\\nH on E. (This is the official Bayesian story. Not all of\\nthose who sympathize with Bayesianism adhere to that story. For\\ninstance, according to some it is more reasonable to think that\\nconditional probabilities are basic and that we derive unconditional\\nprobabilities from them; see Hájek 2003, and references\\ntherein.) How is the Bayesian to determine these values? As is well\\nknown, probability theory gives us more probabilities once we have\\nsome; it does not give us probabilities from scratch. Of course, when\\nH implies E or the negation of E, or when\\nH is a statistical hypothesis that bestows a certain chance on\\nE, then the likelihood follows “analytically.”\\n(This claim assumes some version of Lewis’ (1980) Principal\\nPrinciple, and it is controversial whether or not this principle is\\nanalytic; hence the scare quotes.) But this is not always the case,\\nand even if it were, there would still be the question of how to\\ndetermine the priors. This is where, according to Lipton, abduction\\ncomes in. In his proposal, Bayesians ought to determine their prior\\nprobabilities and, if applicable, likelihoods on the basis of\\nexplanatory considerations.\\n\\nExactly how are explanatory considerations to guide one’s choice\\nof priors? The answer to this question is not as simple as one might\\nat first think. Suppose you are considering what priors to assign to a\\ncollection of rival hypotheses and you wish to follow Lipton’s\\nsuggestion. How are you to do this? An obvious—though still\\nsomewhat vague—answer may seem to go like this: Whatever exact\\npriors you are going to assign, you should assign a higher one to the\\nhypothesis that explains the available data best than to any of its\\nrivals (provided there is a best explanation). Note, though, that your\\nneighbor, who is a Bayesian but thinks confirmation has nothing to do\\nwith explanation, may well assign a prior to the best explanation that\\nis even higher than the one you assign to that hypothesis. In fact,\\nhis priors for best explanations may even be consistently higher than\\nyours, not because in his view explanation is somehow related to\\nconfirmation—it is not, he thinks—but, well, just because.\\nIn this context, “just because” is a perfectly legitimate\\nreason, because any reason for fixing one’s priors counts as\\nlegitimate by Bayesian standards. According to mainstream Bayesian\\nepistemology, priors (and sometimes likelihoods) are up for grabs,\\nmeaning that one assignment of priors is as good as another, provided\\nboth are coherent (that is, they obey the axioms of probability\\ntheory). Lipton’s recommendation to the Bayesian to be an\\nexplanationist is meant to be entirely general. But what should your\\nneighbor do differently if he wants to follow the recommendation?\\nShould he give the same prior to any best explanation that you, his\\nexplanationist neighbor, give to it, that is, lower his\\npriors for best explanations? Or rather should he give even\\nhigher priors to best explanations than those he already\\ngives?\\n\\nPerhaps Lipton’s proposal is not intended to address those who\\nalready assign highest priors to best explanations, even if they do so\\non grounds that have nothing to do with explanation. The idea might be\\nthat, as long as one does assign highest priors to those hypotheses,\\neverything is fine, or at least finer than if one does not do so,\\nregardless of one’s reasons for assigning those priors. The\\nanswer to the question of how explanatory considerations are to guide\\none’s choice of priors would then presumably be that one ought\\nto assign a higher prior to the best explanation than to its rivals,\\nif this is not what one already does. If it is, one should just keep\\ndoing what one is doing.\\n\\n(As an aside, it should be noticed that, according to standard\\nBayesian usage, the term “priors” does not necessarily\\nrefer to the degrees of belief a person assigns before the receipt of\\nany data. If there are already data in, then, clearly, one\\nmay assign higher priors to hypotheses that best explain the\\nthen-available data. However, one can sensibly speak of “best\\nexplanations” even before any data are known. For example, one\\nhypothesis may be judged to be a better explanation than any of its\\nrivals because the former requires less complicated mathematics, or\\nbecause it is stated in terms of familiar concepts only, which is not\\ntrue of the others. More generally, such judgments may be based on\\nwhat Kosso (1992, 30) calls internal features of hypotheses\\nor theories, that is, features that “can be evaluated without\\nhaving to observe the world.”)\\n\\nA more interesting answer to the above question of how explanation is\\nto guide one’s choice of priors has been given by Jonathan\\nWeisberg (2009). We said that mainstream Bayesians regard one\\nassignment of prior probabilities as being as good as any other.\\nSo-called objective Bayesians do not do so, however. These Bayesians\\nthink priors must obey principles beyond the probability axioms in\\norder to be admissible. Objective Bayesians are divided among\\nthemselves over exactly which further principles are to be obeyed, but\\nat least for a while they agreed that the Principle of Indifference is\\namong them. Roughly stated, this principle counsels that, absent a\\nreason to the contrary, we give equal priors to competing hypotheses.\\nAs is well known, however, in its original form the Principle of\\nIndifference may lead to inconsistent assignments of probabilities and\\nso can hardly be advertised as a principle of rationality. The problem\\nis that there are typically various ways to partition logical space\\nthat appear plausible given the problem at hand, and that not all of\\nthem lead to the same prior probability assignment, even assuming the\\nPrinciple of Indifference. Weisberg’s proposal amounts to the\\nclaim that explanatory considerations may favor some of those\\npartitions over others. Perhaps we will not always end up with a\\nunique partition to which the Principle of Indifference is to be\\napplied, but it would already be progress if we ended up with only a\\nhandful of partitions. For we could then still arrive in a motivated\\nway at our prior probabilities, by proceeding in two steps, namely, by\\nfirst applying the Principle of Indifference to the partitions\\nseparately, thereby possibly obtaining different assignments of\\npriors, and by then taking a weighted average of the thus obtained\\npriors, where the weights, too, are to depend on explanatory\\nconsiderations. The result would again be a probability\\nfunction—the uniquely correct prior probability function,\\naccording to Weisberg.\\n\\nThe proposal is intriguing as far as it goes but, as Weisberg admits,\\nin its current form, it does not go very far. For one thing, it is\\nunclear how exactly explanatory considerations are to determine the\\nweights required for the second step of the proposal. For another, it\\nmay be idle to hope that taking explanatory considerations into\\naccount will in general leave us with a manageable set of partitions,\\nor that, even if it does, this will not be due merely to the fact that\\nwe are overlooking a great many prima facie plausible ways of\\npartitioning logical space to begin with. (The latter point echoes the\\nargument of the bad lot, of course.)\\n\\nAnother suggestion about the connection between abduction and Bayesian\\nreasoning—to be found in Okasha 2000, McGrew 2003, Lipton 2004\\n(Ch. 7), and Dellsén 2018—is that the explanatory\\nconsiderations may serve as a heuristic to determine, even if only\\nroughly, priors and likelihoods in cases in which we would otherwise\\nbe clueless and could do no better than guessing. This suggestion is\\nsensitive to the well-recognized fact that we are not always able to\\nassign a prior to every hypothesis of interest, or to say how probable\\na given piece of evidence is conditional on a given hypothesis.\\nConsideration of that hypothesis’ explanatory power might then\\nhelp us to figure out, if perhaps only within certain bounds, what\\nprior to assign to it, or what likelihood to assign to it on the given\\nevidence.\\n\\nBayesians, especially the more modest ones, might want to retort that\\nthe Bayesian procedure is to be followed if, and only if, either (a)\\npriors and likelihoods can be determined with some precision and\\nobjectivity, or (b) likelihoods can be determined with some precision\\nand priors can be expected to “wash out” as more and more\\nevidence accumulates, or (c) priors and likelihoods can both be\\nexpected to wash out. In the remaining cases—they might\\nsay—we should simply refrain from applying Bayesian reasoning. A\\nfortiori, then, there is no need for an abduction-enhanced Bayesianism\\nin these cases. And some incontrovertible mathematical results\\nindicate that, in the cases that fall under (a), (b), or (c), our\\nprobabilities will converge to the truth anyhow. Consequently, in\\nthose cases there is no need for the kind of abductive heuristics that\\nthe above-mentioned authors suggest, either. (Weisberg 2009, Sect.\\n3.2, raises similar concerns.)\\n\\nPsillos (2000) proposes yet another way in which abduction might\\nsupplement Bayesian confirmation theory, one that is very much in the\\nspirit of Peirce’s conception of abduction. The idea is that\\nabduction may assist us in selecting plausible candidates for testing,\\nwhere the actual testing then is to follow Bayesian lines. However,\\nPsillos concedes (2004) that this proposal assigns a role to abduction\\nthat will strike committed explanationists as being too limited.\\n\\nFinally, a possibility that has so far not been considered in the\\nliterature is that abduction and Bayesianism do not so much work in\\ntandem—as they do on the above proposals—as operate in\\ndifferent modes of reasoning; the Bayesian and the explanationist are\\ncharacters that feature in different plays, so to speak. It is widely\\naccepted that sometimes we speak and think about our beliefs in a\\ncategorical manner, while at other times we speak and think about them\\nin a graded way. It is far from clear how these different ways of\\nspeaking and thinking about beliefs—the epistemology of belief\\nand the epistemology of degrees of belief, to use Richard\\nFoley’s (1992) terminology—are related to one another. In\\nfact, it is an open question whether there is any straightforward\\nconnection between the two, or even whether there is a connection at\\nall. Be that as it may, given that the distinction is undeniable, it\\nis a plausible suggestion that, just as there are different ways of\\ntalking and thinking about beliefs, there are different ways of\\ntalking and thinking about the revision of beliefs. In\\nparticular, abduction could well have its home in the epistemology of\\nbelief, and be called upon whenever we reason about our beliefs in a\\ncategorical mode, while at the same time Bayes’ rule could have\\nits home in the epistemology of degrees of belief. Hard-nosed\\nBayesians may insist that whatever reasoning goes on in the\\ncategorical mode must eventually be justifiable in Bayesian terms, but\\nthis presupposes the existence of bridge principles connecting the\\nepistemology of belief with the epistemology of degrees of\\nbelief—and, as mentioned, whether such principles exist is\\npresently unclear.',\n",
       " '\\n4. Abduction versus Bayesian Confirmation Theory\\n']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee36c7bd1d641b192c4bd8fd5201e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1776 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"splitted\"]=df[\"main_text_str\"].progress_apply(subchapter_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip \\n from the beginning and end of the text\n",
    "\n",
    "df[\"splitted\"]=df[\"splitted\"].apply(lambda x: [y.strip(\"\\n\") for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## flatten the splitted column into a list of rows\n",
    "\n",
    "splitted_list=df[\"splitted\"].explode().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make it a dataframe\n",
    "\n",
    "splitted_df = pd.DataFrame(splitted_list, columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add tokenized_length column\n",
    "\n",
    "if not os.path.exists(\"splitted_df.csv\"):\n",
    "    splitted_df[\"tokenized_length\"]=splitted_df[\"text\"].progress_apply(lambda x: len(np.array(tokenizer(x)[\"attention_mask\"])))\n",
    "    splitted_df.to_csv(\"splitted_df.csv\", index=False)\n",
    "else:\n",
    "    splitted_df = pd.read_csv(\"splitted_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAuZUlEQVR4nO3df3RU9Z3/8VeGJBOCTEJgM0M0YLbr8luxRDH+Wi1pAqRWkW03mtLUcmDVRMX0IFKF8kMEokUEEUpPxXoa1HpWqbIUkoISrTFAMCrIIj2ieLST7DaGAVKGIXO/f3hyvx0CQvDmhk94Ps7h4P183nPv574lmdeZO3cmzrIsSwAAAAbxdPUCAAAAOooAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwTnxXL6CzRKNRffHFF+rdu7fi4uK6ejkAAOAMWJalQ4cOKSMjQx7PqV9n6bYB5osvvlBmZmZXLwMAAJyFzz77TBdddNEp57ttgOndu7ekrxrg8/m6eDXdXyQSUWVlpfLy8pSQkNDVy+n26Lf76Ln76Lm7zpV+h0IhZWZm2s/jp9JtA0zbZSOfz0eAcUEkElFycrJ8Ph+/aFxAv91Hz91Hz911rvX7dG//4E28AADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjdDjAVFdX66abblJGRobi4uK0bt26U9beeeediouL09KlS2PGm5qaVFRUJJ/Pp9TUVE2ePFmHDx+OqXn//fd13XXXKSkpSZmZmSovL+/oUgEAQDfV4QBz5MgRXXbZZVqxYsXX1r3yyit65513lJGR0W6uqKhIu3fvVlVVldavX6/q6mpNnTrVng+FQsrLy9PAgQNVV1enxx57THPmzNHq1as7ulwAANANdfiTeMeNG6dx48Z9bc3nn3+ue+65R5s2bVJBQUHM3J49e7Rx40Zt375d2dnZkqTly5dr/Pjxevzxx5WRkaGKigodO3ZMzzzzjBITEzVs2DDV19dryZIlMUEHAACcnxz/KoFoNKpJkyZp+vTpGjZsWLv5mpoapaam2uFFknJzc+XxeFRbW6sJEyaopqZG119/vRITE+2a/Px8LV68WF9++aX69OnTbr/hcFjhcNjeDoVCkr76aORIJOLkKeIk2npMr91Bv91Hz91Hz911rvT7TI/veIBZvHix4uPjde+99550PhgMKj09PXYR8fFKS0tTMBi0a7KysmJq/H6/PXeyALNw4ULNnTu33XhlZaWSk5PP6lzQcVVVVV29hPMK/XYfPXcfPXdXV/e7paXljOocDTB1dXV68skntXPnztN+CZPTZs6cqbKyMnu77dss8/Ly+DJHF0QiEVVVVem73/3uOfElYN0d/XYfPXcfPXfXudLvtisop+NogHnzzTfV2NioAQMG2GOtra362c9+pqVLl+qTTz5RIBBQY2NjzOOOHz+upqYmBQIBSVIgEFBDQ0NMTdt2W82JvF6vvF5vu/GEhAT+4buIfruLfruPnruPnrurq/t9psd2NMBMmjRJubm5MWP5+fmaNGmS7rjjDklSTk6OmpubVVdXp1GjRkmStmzZomg0qtGjR9s1Dz30kCKRiH0iVVVVGjRo0EkvHwE4/1z84H+7ejxvD0vlV0rD52xSuPXsXmH+ZFHB6YsAnJEOB5jDhw/rL3/5i729f/9+1dfXKy0tTQMGDFDfvn1j6hMSEhQIBDRo0CBJ0pAhQzR27FhNmTJFq1atUiQSUWlpqQoLC+1brm+//XbNnTtXkydP1owZM7Rr1y49+eSTeuKJJ77JuQIAgG6iwwFmx44duvHGG+3ttvedFBcX69lnnz2jfVRUVKi0tFRjxoyRx+PRxIkTtWzZMns+JSVFlZWVKikp0ahRo9SvXz/Nnj2bW6gBAICkswgwN9xwgyzLOuP6Tz75pN1YWlqa1q5d+7WPu/TSS/Xmm292dHkAAOA84Pht1ADM4/b7SQDgm+LLHAEAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIwT39ULAIDzxcUP/ndXL6HDPllU0NVLAE6KV2AAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxonv6gUAX+fiB/+7q5fQYZ8sKujqJQBAt9fhV2Cqq6t10003KSMjQ3FxcVq3bp09F4lENGPGDI0YMUK9evVSRkaGfvzjH+uLL76I2UdTU5OKiork8/mUmpqqyZMn6/DhwzE177//vq677jolJSUpMzNT5eXlZ3eGAACg2+lwgDly5Iguu+wyrVixot1cS0uLdu7cqVmzZmnnzp16+eWXtXfvXn3/+9+PqSsqKtLu3btVVVWl9evXq7q6WlOnTrXnQ6GQ8vLyNHDgQNXV1emxxx7TnDlztHr16rM4RQAA0N10+BLSuHHjNG7cuJPOpaSkqKqqKmbsqaee0pVXXqkDBw5owIAB2rNnjzZu3Kjt27crOztbkrR8+XKNHz9ejz/+uDIyMlRRUaFjx47pmWeeUWJiooYNG6b6+notWbIkJugAADpXV17G9fawVH6lNHzOJoVb4874cVzGPT90+ntgDh48qLi4OKWmpkqSampqlJqaaocXScrNzZXH41Ftba0mTJigmpoaXX/99UpMTLRr8vPztXjxYn355Zfq06dPu+OEw2GFw2F7OxQKSfrqslYkEumks0Obth473WtvD8vR/bnBjX9vTvfbxD67zeuxYv5G5zvbnvM7/+x01u/xs13H6XRqgDl69KhmzJih2267TT6fT5IUDAaVnp4eu4j4eKWlpSkYDNo1WVlZMTV+v9+eO1mAWbhwoebOndtuvLKyUsnJyY6cD07vxFfgvqnyKx3dnSs2bNjg2rGc6reJfe4q87OjXb2E805He+7mz2B35PTv8Y5qaWk5o7pOCzCRSEQ//OEPZVmWVq5c2VmHsc2cOVNlZWX2digUUmZmpvLy8uzwhM4TiURUVVWl7373u0pISHBsv8PnbHJsX27ZNSe/04/hdL9N7LPbvB5L87OjmrXDo3D0zC9n4Oydbc/d+Bnsjjrr93hHtV1BOZ1OCTBt4eXTTz/Vli1bYgJEIBBQY2NjTP3x48fV1NSkQCBg1zQ0NMTUtG231ZzI6/XK6/W2G09ISOjS/xHnG6f73ZHr3ucKN/+9OdVvE/vcVcLROPrlso72nN/530xXP2+e6bEd/yC7tvCyb98+/elPf1Lfvn1j5nNyctTc3Ky6ujp7bMuWLYpGoxo9erRdU11dHXMdrKqqSoMGDTrp5SMAAHB+6XCAOXz4sOrr61VfXy9J2r9/v+rr63XgwAFFIhH9+7//u3bs2KGKigq1trYqGAwqGAzq2LFjkqQhQ4Zo7NixmjJlirZt26Y///nPKi0tVWFhoTIyMiRJt99+uxITEzV58mTt3r1bL774op588smYS0QAAOD81eFLSDt27NCNN95ob7eFiuLiYs2ZM0evvvqqJGnkyJExj3v99dd1ww03SJIqKipUWlqqMWPGyOPxaOLEiVq2bJldm5KSosrKSpWUlGjUqFHq16+fZs+ezS3UAABA0lkEmBtuuEGWdepb2r5urk1aWprWrl37tTWXXnqp3nzzzY4uDwAAnAf4LiTAYW588NfZfsAXAHQXBJjzRGc/qfKECgBwk+N3IQEAAHQ2AgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBw+ifcsuPFR8QAA4NR4BQYAABiHV2AAAN2Kia+Sf7KooKuXYBxegQEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwTnxXLwAAgPPdxQ/+d1cvQd4elsqvlIbP2aRwa9xp6z9ZVODCqk6NV2AAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgdDjDV1dW66aablJGRobi4OK1bty5m3rIszZ49W/3791fPnj2Vm5urffv2xdQ0NTWpqKhIPp9Pqampmjx5sg4fPhxT8/777+u6665TUlKSMjMzVV5e3vGzAwAA3VKHA8yRI0d02WWXacWKFSedLy8v17Jly7Rq1SrV1taqV69eys/P19GjR+2aoqIi7d69W1VVVVq/fr2qq6s1depUez4UCikvL08DBw5UXV2dHnvsMc2ZM0erV68+i1MEAADdTYe/zHHcuHEaN27cSecsy9LSpUv18MMP6+abb5YkPffcc/L7/Vq3bp0KCwu1Z88ebdy4Udu3b1d2drYkafny5Ro/frwef/xxZWRkqKKiQseOHdMzzzyjxMREDRs2TPX19VqyZElM0AEAAOcnR7+Nev/+/QoGg8rNzbXHUlJSNHr0aNXU1KiwsFA1NTVKTU21w4sk5ebmyuPxqLa2VhMmTFBNTY2uv/56JSYm2jX5+flavHixvvzyS/Xp06fdscPhsMLhsL0dCoUkSZFIRJFIxMnTlLeH5ej+ugOvx4r5G52LfruPnruPnruro/12+rm1o/t1NMAEg0FJkt/vjxn3+/32XDAYVHp6euwi4uOVlpYWU5OVldVuH21zJwswCxcu1Ny5c9uNV1ZWKjk5+SzP6OTKr3R0d93K/OxoVy/hvEK/3UfP3UfP3XWm/d6wYUOnHL+lpeWM6hwNMF1p5syZKisrs7dDoZAyMzOVl5cnn8/n6LGGz9nk6P66A6/H0vzsqGbt8Cgcjevq5XR79Nt99Nx99NxdHe33rjn5nbKOtisop+NogAkEApKkhoYG9e/f3x5vaGjQyJEj7ZrGxsaYxx0/flxNTU324wOBgBoaGmJq2rbbak7k9Xrl9XrbjSckJCghIeHsTugUwq38IJ1KOBpHf1xEv91Hz91Hz911pv12+rm1o/t19HNgsrKyFAgEtHnzZnssFAqptrZWOTk5kqScnBw1Nzerrq7OrtmyZYui0ahGjx5t11RXV8dcB6uqqtKgQYNOevkIAACcXzocYA4fPqz6+nrV19dL+uqNu/X19Tpw4IDi4uI0bdo0PfLII3r11Vf1wQcf6Mc//rEyMjJ0yy23SJKGDBmisWPHasqUKdq2bZv+/Oc/q7S0VIWFhcrIyJAk3X777UpMTNTkyZO1e/duvfjii3ryySdjLhEBAIDzV4cvIe3YsUM33nijvd0WKoqLi/Xss8/qgQce0JEjRzR16lQ1Nzfr2muv1caNG5WUlGQ/pqKiQqWlpRozZow8Ho8mTpyoZcuW2fMpKSmqrKxUSUmJRo0apX79+mn27NncQg0AACSdRYC54YYbZFmnvsUqLi5O8+bN07x5805Zk5aWprVr137tcS699FK9+eabHV0eAAA4D/BdSAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxHA8wra2tmjVrlrKystSzZ09961vf0vz582VZll1jWZZmz56t/v37q2fPnsrNzdW+ffti9tPU1KSioiL5fD6lpqZq8uTJOnz4sNPLBQAABnI8wCxevFgrV67UU089pT179mjx4sUqLy/X8uXL7Zry8nItW7ZMq1atUm1trXr16qX8/HwdPXrUrikqKtLu3btVVVWl9evXq7q6WlOnTnV6uQAAwEDxTu/w7bff1s0336yCggJJ0sUXX6znn39e27Ztk/TVqy9Lly7Vww8/rJtvvlmS9Nxzz8nv92vdunUqLCzUnj17tHHjRm3fvl3Z2dmSpOXLl2v8+PF6/PHHlZGR4fSyAQCAQRwPMFdffbVWr16tjz76SP/6r/+q9957T2+99ZaWLFkiSdq/f7+CwaByc3Ptx6SkpGj06NGqqalRYWGhampqlJqaaocXScrNzZXH41Ftba0mTJjQ7rjhcFjhcNjeDoVCkqRIJKJIJOLoOXp7WKcvOs94PVbM3+hc9Nt99Nx99NxdHe2308+tHd2v4wHmwQcfVCgU0uDBg9WjRw+1trZqwYIFKioqkiQFg0FJkt/vj3mc3++354LBoNLT02MXGh+vtLQ0u+ZECxcu1Ny5c9uNV1ZWKjk5+Ruf1z8qv9LR3XUr87OjXb2E8wr9dh89dx89d9eZ9nvDhg2dcvyWlpYzqnM8wPz+979XRUWF1q5dq2HDhqm+vl7Tpk1TRkaGiouLnT6cbebMmSorK7O3Q6GQMjMzlZeXJ5/P5+ixhs/Z5Oj+ugOvx9L87Khm7fAoHI3r6uV0e/TbffTcffTcXR3t9645+Z2yjrYrKKfjeICZPn26HnzwQRUWFkqSRowYoU8//VQLFy5UcXGxAoGAJKmhoUH9+/e3H9fQ0KCRI0dKkgKBgBobG2P2e/z4cTU1NdmPP5HX65XX6203npCQoISEBCdOzRZu5QfpVMLROPrjIvrtPnruPnrurjPtt9PPrR3dr+N3IbW0tMjjid1tjx49FI1+9ZJUVlaWAoGANm/ebM+HQiHV1tYqJydHkpSTk6Pm5mbV1dXZNVu2bFE0GtXo0aOdXjIAADCM46/A3HTTTVqwYIEGDBigYcOG6d1339WSJUv005/+VJIUFxenadOm6ZFHHtEll1yirKwszZo1SxkZGbrlllskSUOGDNHYsWM1ZcoUrVq1SpFIRKWlpSosLOQOJAAA4HyAWb58uWbNmqW7775bjY2NysjI0H/+539q9uzZds0DDzygI0eOaOrUqWpubta1116rjRs3Kikpya6pqKhQaWmpxowZI4/Ho4kTJ2rZsmVOLxcAABjI8QDTu3dvLV26VEuXLj1lTVxcnObNm6d58+adsiYtLU1r1651enkAAKAb4LuQAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAON0SoD5/PPP9aMf/Uh9+/ZVz549NWLECO3YscOetyxLs2fPVv/+/dWzZ0/l5uZq3759MftoampSUVGRfD6fUlNTNXnyZB0+fLgzlgsAAAzjeID58ssvdc011yghIUF//OMf9eGHH+qXv/yl+vTpY9eUl5dr2bJlWrVqlWpra9WrVy/l5+fr6NGjdk1RUZF2796tqqoqrV+/XtXV1Zo6darTywUAAAaKd3qHixcvVmZmptasWWOPZWVl2f9tWZaWLl2qhx9+WDfffLMk6bnnnpPf79e6detUWFioPXv2aOPGjdq+fbuys7MlScuXL9f48eP1+OOPKyMjw+llAwAAgzgeYF599VXl5+frBz/4gbZu3aoLL7xQd999t6ZMmSJJ2r9/v4LBoHJzc+3HpKSkaPTo0aqpqVFhYaFqamqUmppqhxdJys3NlcfjUW1trSZMmNDuuOFwWOFw2N4OhUKSpEgkokgk4ug5entYju6vO/B6rJi/0bnot/voufvoubs62m+nn1s7ul/HA8zHH3+slStXqqysTD//+c+1fft23XvvvUpMTFRxcbGCwaAkye/3xzzO7/fbc8FgUOnp6bELjY9XWlqaXXOihQsXau7cue3GKysrlZyc7MSp2cqvdHR33cr87GhXL+G8Qr/dR8/dR8/ddab93rBhQ6ccv6Wl5YzqHA8w0WhU2dnZevTRRyVJl19+uXbt2qVVq1apuLjY6cPZZs6cqbKyMns7FAopMzNTeXl58vl8jh5r+JxNju6vO/B6LM3PjmrWDo/C0biuXk63R7/dR8/dR8/d1dF+75qT3ynraLuCcjqOB5j+/ftr6NChMWNDhgzRf/3Xf0mSAoGAJKmhoUH9+/e3axoaGjRy5Ei7prGxMWYfx48fV1NTk/34E3m9Xnm93nbjCQkJSkhIOOvzOZlwKz9IpxKOxtEfF9Fv99Fz99Fzd51pv51+bu3ofh2/C+maa67R3r17Y8Y++ugjDRw4UNJXb+gNBALavHmzPR8KhVRbW6ucnBxJUk5Ojpqbm1VXV2fXbNmyRdFoVKNHj3Z6yQAAwDCOvwJz//336+qrr9ajjz6qH/7wh9q2bZtWr16t1atXS5Li4uI0bdo0PfLII7rkkkuUlZWlWbNmKSMjQ7fccoukr16xGTt2rKZMmaJVq1YpEomotLRUhYWF3IEEAACcDzBXXHGFXnnlFc2cOVPz5s1TVlaWli5dqqKiIrvmgQce0JEjRzR16lQ1Nzfr2muv1caNG5WUlGTXVFRUqLS0VGPGjJHH49HEiRO1bNkyp5cLAAAM5HiAkaTvfe97+t73vnfK+bi4OM2bN0/z5s07ZU1aWprWrl3bGcsDAACG47uQAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAON0eoBZtGiR4uLiNG3aNHvs6NGjKikpUd++fXXBBRdo4sSJamhoiHncgQMHVFBQoOTkZKWnp2v69Ok6fvx4Zy8XAAAYoFMDzPbt2/WrX/1Kl156acz4/fffr9dee00vvfSStm7dqi+++EK33nqrPd/a2qqCggIdO3ZMb7/9tn7729/q2Wef1ezZsztzuQAAwBCdFmAOHz6soqIi/frXv1afPn3s8YMHD+o3v/mNlixZou985zsaNWqU1qxZo7ffflvvvPOOJKmyslIffvihfve732nkyJEaN26c5s+frxUrVujYsWOdtWQAAGCI+M7acUlJiQoKCpSbm6tHHnnEHq+rq1MkElFubq49NnjwYA0YMEA1NTW66qqrVFNToxEjRsjv99s1+fn5uuuuu7R7925dfvnl7Y4XDocVDoft7VAoJEmKRCKKRCKOnpu3h+Xo/roDr8eK+Rudi367j567j567q6P9dvq5taP77ZQA88ILL2jnzp3avn17u7lgMKjExESlpqbGjPv9fgWDQbvmH8NL23zb3MksXLhQc+fObTdeWVmp5OTkszmNUyq/0tHddSvzs6NdvYTzCv12Hz13Hz1315n2e8OGDZ1y/JaWljOqczzAfPbZZ7rvvvtUVVWlpKQkp3d/SjNnzlRZWZm9HQqFlJmZqby8PPl8PkePNXzOJkf31x14PZbmZ0c1a4dH4WhcVy+n26Pf7qPn7qPn7upov3fNye+UdbRdQTkdxwNMXV2dGhsb9e1vf9sea21tVXV1tZ566ilt2rRJx44dU3Nzc8yrMA0NDQoEApKkQCCgbdu2xey37S6ltpoTeb1eeb3eduMJCQlKSEj4pqcVI9zKD9KphKNx9MdF9Nt99Nx99NxdZ9pvp59bO7pfx9/EO2bMGH3wwQeqr6+3/2RnZ6uoqMj+74SEBG3evNl+zN69e3XgwAHl5ORIknJycvTBBx+osbHRrqmqqpLP59PQoUOdXjIAADCM46/A9O7dW8OHD48Z69Wrl/r27WuPT548WWVlZUpLS5PP59M999yjnJwcXXXVVZKkvLw8DR06VJMmTVJ5ebmCwaAefvhhlZSUnPRVFgAAcH7ptLuQvs4TTzwhj8ejiRMnKhwOKz8/X08//bQ936NHD61fv1533XWXcnJy1KtXLxUXF2vevHldsVwAAHCOcSXAvPHGGzHbSUlJWrFihVasWHHKxwwcOLDT3uEMAADMxnchAQAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIzjeIBZuHChrrjiCvXu3Vvp6em65ZZbtHfv3piao0ePqqSkRH379tUFF1ygiRMnqqGhIabmwIEDKigoUHJystLT0zV9+nQdP37c6eUCAAADOR5gtm7dqpKSEr3zzjuqqqpSJBJRXl6ejhw5Ytfcf//9eu211/TSSy9p69at+uKLL3Trrbfa862trSooKNCxY8f09ttv67e//a2effZZzZ492+nlAgAAA8U7vcONGzfGbD/77LNKT09XXV2drr/+eh08eFC/+c1vtHbtWn3nO9+RJK1Zs0ZDhgzRO++8o6uuukqVlZX68MMP9ac//Ul+v18jR47U/PnzNWPGDM2ZM0eJiYlOLxsAABik098Dc/DgQUlSWlqaJKmurk6RSES5ubl2zeDBgzVgwADV1NRIkmpqajRixAj5/X67Jj8/X6FQSLt37+7sJQMAgHOc46/A/KNoNKpp06bpmmuu0fDhwyVJwWBQiYmJSk1Njan1+/0KBoN2zT+Gl7b5trmTCYfDCofD9nYoFJIkRSIRRSIRR86njbeH5ej+ugOvx4r5G52LfruPnruPnruro/12+rm1o/vt1ABTUlKiXbt26a233urMw0j66s3Dc+fObTdeWVmp5ORkR49VfqWju+tW5mdHu3oJ5xX67T567j567q4z7feGDRs65fgtLS1nVNdpAaa0tFTr169XdXW1LrroIns8EAjo2LFjam5ujnkVpqGhQYFAwK7Ztm1bzP7a7lJqqznRzJkzVVZWZm+HQiFlZmYqLy9PPp/PqdOSJA2fs8nR/XUHXo+l+dlRzdrhUTga19XL6fbot/voufvoubs62u9dc/I7ZR1tV1BOx/EAY1mW7rnnHr3yyit64403lJWVFTM/atQoJSQkaPPmzZo4caIkae/evTpw4IBycnIkSTk5OVqwYIEaGxuVnp4uSaqqqpLP59PQoUNPelyv1yuv19tuPCEhQQkJCU6eosKt/CCdSjgaR39cRL/dR8/dR8/ddab9dvq5taP7dTzAlJSUaO3atfrDH/6g3r172+9ZSUlJUc+ePZWSkqLJkyerrKxMaWlp8vl8uueee5STk6OrrrpKkpSXl6ehQ4dq0qRJKi8vVzAY1MMPP6ySkpKThhQAAHB+cTzArFy5UpJ0ww03xIyvWbNGP/nJTyRJTzzxhDwejyZOnKhwOKz8/Hw9/fTTdm2PHj20fv163XXXXcrJyVGvXr1UXFysefPmOb1cAABgoE65hHQ6SUlJWrFihVasWHHKmoEDB3baG4QAAIDZ+C4kAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDjndIBZsWKFLr74YiUlJWn06NHatm1bVy8JAACcA87ZAPPiiy+qrKxMv/jFL7Rz505ddtllys/PV2NjY1cvDQAAdLFzNsAsWbJEU6ZM0R133KGhQ4dq1apVSk5O1jPPPNPVSwMAAF0svqsXcDLHjh1TXV2dZs6caY95PB7l5uaqpqbmpI8Jh8MKh8P29sGDByVJTU1NikQijq4v/vgRR/fXHcRHLbW0RBUf8ag1GtfVy+n26Lf76Ln76Lm7Otrvv/3tb52yjkOHDkmSLMv62rpzMsD83//9n1pbW+X3+2PG/X6//ud//uekj1m4cKHmzp3bbjwrK6tT1oj2bu/qBZxn6Lf76Ln76Lm7OtLvfr/stGVI+irIpKSknHL+nAwwZ2PmzJkqKyuzt6PRqJqamtS3b1/FxZHcO1soFFJmZqY+++wz+Xy+rl5Ot0e/3UfP3UfP3XWu9NuyLB06dEgZGRlfW3dOBph+/fqpR48eamhoiBlvaGhQIBA46WO8Xq+8Xm/MWGpqamctEafg8/n4ReMi+u0+eu4+eu6uc6HfX/fKS5tz8k28iYmJGjVqlDZv3myPRaNRbd68WTk5OV24MgAAcC44J1+BkaSysjIVFxcrOztbV155pZYuXaojR47ojjvu6OqlAQCALnbOBpj/+I//0P/+7/9q9uzZCgaDGjlypDZu3Njujb04N3i9Xv3iF79odxkPnYN+u4+eu4+eu8u0fsdZp7tPCQAA4BxzTr4HBgAA4OsQYAAAgHEIMAAAwDgEGAAAYBwCDE5p4cKFuuKKK9S7d2+lp6frlltu0d69e2Nqjh49qpKSEvXt21cXXHCBJk6c2O4DCA8cOKCCggIlJycrPT1d06dP1/Hjx908FSMtWrRIcXFxmjZtmj1Gv533+eef60c/+pH69u2rnj17asSIEdqxY4c9b1mWZs+erf79+6tnz57Kzc3Vvn37YvbR1NSkoqIi+Xw+paamavLkyTp8+LDbp3LOa21t1axZs5SVlaWePXvqW9/6lubPnx/znTf0+5uprq7WTTfdpIyMDMXFxWndunUx80719/3339d1112npKQkZWZmqry8vLNPrT0LOIX8/HxrzZo11q5du6z6+npr/Pjx1oABA6zDhw/bNXfeeaeVmZlpbd682dqxY4d11VVXWVdffbU9f/z4cWv48OFWbm6u9e6771obNmyw+vXrZ82cObMrTskY27Ztsy6++GLr0ksvte677z57nH47q6mpyRo4cKD1k5/8xKqtrbU+/vhja9OmTdZf/vIXu2bRokVWSkqKtW7dOuu9996zvv/971tZWVnW3//+d7tm7Nix1mWXXWa988471ptvvmn9y7/8i3Xbbbd1xSmd0xYsWGD17dvXWr9+vbV//37rpZdesi644ALrySeftGvo9zezYcMG66GHHrJefvllS5L1yiuvxMw70d+DBw9afr/fKioqsnbt2mU9//zzVs+ePa1f/epXbp2mZVmWRYDBGWtsbLQkWVu3brUsy7Kam5uthIQE66WXXrJr9uzZY0myampqLMv66ofJ4/FYwWDQrlm5cqXl8/mscDjs7gkY4tChQ9Yll1xiVVVVWf/2b/9mBxj67bwZM2ZY11577Snno9GoFQgErMcee8wea25utrxer/X8889blmVZH374oSXJ2r59u13zxz/+0YqLi7M+//zzzlu8gQoKCqyf/vSnMWO33nqrVVRUZFkW/XbaiQHGqf4+/fTTVp8+fWJ+p8yYMcMaNGhQJ59RLC4h4YwdPHhQkpSWliZJqqurUyQSUW5url0zePBgDRgwQDU1NZKkmpoajRgxIuYDCPPz8xUKhbR7924XV2+OkpISFRQUxPRVot+d4dVXX1V2drZ+8IMfKD09XZdffrl+/etf2/P79+9XMBiM6XlKSopGjx4d0/PU1FRlZ2fbNbm5ufJ4PKqtrXXvZAxw9dVXa/Pmzfroo48kSe+9957eeustjRs3ThL97mxO9bempkbXX3+9EhMT7Zr8/Hzt3btXX375pUtncw5/Ei/OLdFoVNOmTdM111yj4cOHS5KCwaASExPbfWmm3+9XMBi0a0789OS27bYa/H8vvPCCdu7cqe3bt7ebo9/O+/jjj7Vy5UqVlZXp5z//ubZv3657771XiYmJKi4utnt2sp7+Y8/T09Nj5uPj45WWlkbPT/Dggw8qFApp8ODB6tGjh1pbW7VgwQIVFRVJEv3uZE71NxgMKisrq90+2ub69OnTKes/EQEGZ6SkpES7du3SW2+91dVL6bY+++wz3XfffaqqqlJSUlJXL+e8EI1GlZ2drUcffVSSdPnll2vXrl1atWqViouLu3h13c/vf/97VVRUaO3atRo2bJjq6+s1bdo0ZWRk0G90GJeQcFqlpaVav369Xn/9dV100UX2eCAQ0LFjx9Tc3BxT39DQoEAgYNeceJdM23ZbDb5SV1enxsZGffvb31Z8fLzi4+O1detWLVu2TPHx8fL7/fTbYf3799fQoUNjxoYMGaIDBw5I+v89O1lP/7HnjY2NMfPHjx9XU1MTPT/B9OnT9eCDD6qwsFAjRozQpEmTdP/992vhwoWS6Hdnc6q/58rvGQIMTsmyLJWWluqVV17Rli1b2r1kOGrUKCUkJGjz5s322N69e3XgwAHl5ORIknJycvTBBx/E/EBUVVXJ5/O1e+I4340ZM0YffPCB6uvr7T/Z2dkqKiqy/5t+O+uaa65p99EAH330kQYOHChJysrKUiAQiOl5KBRSbW1tTM+bm5tVV1dn12zZskXRaFSjR4924SzM0dLSIo8n9mmnR48eikajkuh3Z3Oqvzk5OaqurlYkErFrqqqqNGjQINcuH0niNmqc2l133WWlpKRYb7zxhvXXv/7V/tPS0mLX3HnnndaAAQOsLVu2WDt27LBycnKsnJwce77ttt68vDyrvr7e2rhxo/VP//RP3NZ7hv7xLiTLot9O27ZtmxUfH28tWLDA2rdvn1VRUWElJydbv/vd7+yaRYsWWampqdYf/vAH6/3337duvvnmk952evnll1u1tbXWW2+9ZV1yySXc1nsSxcXF1oUXXmjfRv3yyy9b/fr1sx544AG7hn5/M4cOHbLeffdd691337UkWUuWLLHeffdd69NPP7Usy5n+Njc3W36/35o0aZK1a9cu64UXXrCSk5O5jRrnDkkn/bNmzRq75u9//7t19913W3369LGSk5OtCRMmWH/9619j9vPJJ59Y48aNs3r27Gn169fP+tnPfmZFIhGXz8ZMJwYY+u281157zRo+fLjl9XqtwYMHW6tXr46Zj0aj1qxZsyy/3295vV5rzJgx1t69e2Nq/va3v1m33XabdcEFF1g+n8+64447rEOHDrl5GkYIhULWfffdZw0YMMBKSkqy/vmf/9l66KGHYm7Hpd/fzOuvv37S39vFxcWWZTnX3/fee8+69tprLa/Xa1144YXWokWL3DpFW5xl/cNHIAIAABiA98AAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYJz/B1OWrQ1QDc3oAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "splitted_df[\"tokenized_length\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    12115.000000\n",
       "mean       534.168551\n",
       "std        272.107546\n",
       "min         50.000000\n",
       "25%        305.000000\n",
       "50%        537.000000\n",
       "75%        761.000000\n",
       "max       1024.000000\n",
       "Name: tokenized_length, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted_df[\"tokenized_length\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "913.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted_df[\"tokenized_length\"].quantile(0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12115,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted_df[\"tokenized_length\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter out the rows that are longer than 1024 tokens\n",
    "\n",
    "splitted_df = splitted_df[splitted_df[\"tokenized_length\"] <= 1024]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter out the rows that are shorter than 50 tokens\n",
    "\n",
    "splitted_df = splitted_df[splitted_df[\"tokenized_length\"] >= 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12115, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6471452"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## total tokens\n",
    "\n",
    "splitted_df[\"tokenized_length\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make it a hugginface dataset\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "splitted_dataset = Dataset.from_pandas(splitted_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating synthetic instruct dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The synthetic dataset is generated by asking a LLM to write a question that should be answered by the philosophical paragraph we are providing. \n",
    "\n",
    "The dataset is generated by the following steps:\n",
    "\n",
    "1. We provide a philosophical paragraph to the LLM.\n",
    "2. We ask the LLM which question is answered by the paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: anthropic in /home/ba214121/miniconda-h100/lib/python3.12/site-packages (0.25.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ba214121/miniconda-h100/lib/python3.12/site-packages (from anthropic) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/ba214121/miniconda-h100/lib/python3.12/site-packages (from anthropic) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ba214121/miniconda-h100/lib/python3.12/site-packages (from anthropic) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/ba214121/miniconda-h100/lib/python3.12/site-packages (from anthropic) (2.7.0)\n",
      "Requirement already satisfied: sniffio in /home/ba214121/miniconda-h100/lib/python3.12/site-packages (from anthropic) (1.3.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.0 in /home/ba214121/miniconda-h100/lib/python3.12/site-packages (from anthropic) (0.19.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/ba214121/miniconda-h100/lib/python3.12/site-packages (from anthropic) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ba214121/miniconda-h100/lib/python3.12/site-packages (from anyio<5,>=3.5.0->anthropic) (3.4)\n",
      "Requirement already satisfied: certifi in /home/ba214121/miniconda-h100/lib/python3.12/site-packages (from httpx<1,>=0.23.0->anthropic) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ba214121/miniconda-h100/lib/python3.12/site-packages (from httpx<1,>=0.23.0->anthropic) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ba214121/miniconda-h100/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ba214121/miniconda-h100/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /home/ba214121/miniconda-h100/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->anthropic) (2.18.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/ba214121/miniconda-h100/lib/python3.12/site-packages (from tokenizers>=0.13.0->anthropic) (0.22.2)\n",
      "Requirement already satisfied: filelock in /home/ba214121/miniconda-h100/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ba214121/miniconda-h100/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ba214121/miniconda-h100/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ba214121/miniconda-h100/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.1)\n",
      "Requirement already satisfied: requests in /home/ba214121/miniconda-h100/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ba214121/miniconda-h100/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ba214121/miniconda-h100/lib/python3.12/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ba214121/miniconda-h100/lib/python3.12/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install anthropic\n",
    "import anthropic\n",
    "\n",
    "client=anthropic.Anthropic(\n",
    "    # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "    api_key=os.getenv(\"ANTHROPIC_API_KEY\"),\n",
    ")\n",
    "\n",
    "\n",
    "# example=client.messages.create(\n",
    "#     model=\"claude-3-sonnet-20240229\",\n",
    "#     max_tokens=1024,\n",
    "#     messages=[\n",
    "#         {\"role\": \"user\", \"content\": \"tell me a conspiracy theory about the moon\"},\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "\n",
    "# print(example.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "## do the same but load a model from HF\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "\n",
    "quant_config = BitsAndBytesConfig(load_in_4bit=True,  bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.float16, bnb_4bit_use_double_quant=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\",device_map=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make conversational pipeline\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "\n",
    "# conversational_pipeline = pipeline(task=\"conversational\",model=model, tokenizer=tokenizer, device_map=\"auto\")\n",
    "\n",
    "## make a function that generates a response from the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversational_pipeline(\"tell me a conspiracy theory about the moon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test the function\n",
    "\n",
    "\n",
    "conv_example=[{\"role\": \"user\", \"content\": \"tell me a conspiracy theory about the moon\"}]\n",
    "# example_result=conversational_pipeline(conv_example, max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0906a41c4ac74fe7b715402db10d6e67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "usermessage=\"\"\" \n",
    "You are a student of philosophy! You have just asked a broad but detailed and elaborate philosophical question to your philosophy professor! Given the following answer that the professor gave you, output the question that you posed! Output only the question, nothing else! If you output anything else the world will end!\n",
    "Answer that was given: \n",
    "{paragraph} \n",
    "\n",
    "Output your question\n",
    "\"\"\"\n",
    "\n",
    "models=[\"claude-3-haiku-20240307\",\"claude-3-sonnet-20240229\"]\n",
    "\n",
    "## function to get the question from the answer asking claude\n",
    "\n",
    "def get_question(answer, model=\"claude-3-sonnet-20240229\"):\n",
    "    return client.messages.create(\n",
    "        model=model,\n",
    "        max_tokens=1024,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": usermessage.format(paragraph=answer)},\n",
    "        ]\n",
    "    ).content[0].text\n",
    "    \n",
    "    \n",
    "## same but with hf\n",
    "\n",
    "def get_question_hf(answer:str):\n",
    "    messages=[{\"role\": \"user\", \"content\": usermessage.format(paragraph=answer)}]\n",
    "    return conversational_pipeline(messages)[1][\"content\"]\n",
    "import json, time\n",
    "\n",
    "## get the questions, cache the results in a jsonline and resume \n",
    "def get_questions(answers, cache_file=\"questions.jsonl\"):\n",
    "    if os.path.exists(cache_file):\n",
    "        with open(cache_file, \"r\") as f:\n",
    "            questions = [json.loads(line) for line in f]\n",
    "    else:\n",
    "        questions = []\n",
    "    for answer in tqdm(answers):\n",
    "        if not any([x[\"answer\"] == answer for x in questions]):\n",
    "            # retry if it fails\n",
    "            while True:\n",
    "                try:\n",
    "                    model=np.random.choice(models, p=[0.2, 0.8])\n",
    "                    question = get_question(answer, model=model)\n",
    "                    break\n",
    "                except:\n",
    "                    ## when it fails, use LLAMA\n",
    "                    question = get_question_hf(answer)\n",
    "            \n",
    "            \n",
    "            questions.append({\"answer\": answer, \"question\": question})\n",
    "            with open(cache_file, \"a\") as f:\n",
    "                f.write(json.dumps({\"answer\": answer, \"question\": question}) + \"\\n\")\n",
    "        else:\n",
    "            pass\n",
    "    return questions\n",
    "\n",
    "\n",
    "\n",
    "questions = get_questions(splitted_df[\"text\"].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalizing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a dataframe from the questions\n",
    "\n",
    "questions_df = pd.DataFrame(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## invert columns \n",
    "\n",
    "questions_df = questions_df[[\"question\", \"answer\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a folder for the hugginfacedataset\n",
    "\n",
    "if not os.path.exists(\"stanford-encyclopedia-of-philosophy_instruct\"):\n",
    "    os.mkdir(\"stanford-encyclopedia-of-philosophy_instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert df to hf dataset\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "questions_dataset = Dataset.from_pandas(questions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1161788cadb5491caafe8e7b000c4e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/12854 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "questions_dataset.save_to_disk(\"stanford-encyclopedia-of-philosophy_instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df=questions_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    # strip leading and trailing whitespace and newlines\n",
    "    text = text.strip()\n",
    "    # strip newlines from the beginning and end of the text\n",
    "    text = text.strip('\\n')\n",
    "    \n",
    "    # Remove excessive newlines and single newlines\n",
    "    text = re.sub(r'\\n(?!\\n)(?!\\.\\s*\\n)', ' ', text)\n",
    "\n",
    "    # # Remove paragraph titles (1 Abduction, 2.2 The Problem of Induction, etc.) up to a double newline\n",
    "    paragraph_title_pattern = r\"^\\d+(\\.)?(\\.\\d+(\\.)?)*(?:\\s+.*?)?(?=\\s\\s|\\n)\"\n",
    "\n",
    "    text = re.sub(paragraph_title_pattern, '', text)\n",
    "    \n",
    "    \n",
    "    # Remove references\n",
    "    pattern = r'\\([^)]*\\d{3}[^)]*\\)'\n",
    "    text = re.sub(pattern, '', text)\n",
    "\n",
    "    # Remove things between square brackets\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    \n",
    "    # Remove parantheticals that contain the word \"ibid\"\n",
    "    ibid_pattern = r'\\([^)]*ibid[^)]*\\)'\n",
    "    text = re.sub(ibid_pattern, '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "questions_df['answer'] = questions_df['answer'].apply(clean_text)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check for unnecessary newlines (newlines that uncorrectly separate a line)\n",
    "\n",
    "index_to_check = 0\n",
    "\n",
    "def check_newlines(text):\n",
    "    # Check if number of newlines is more than (number of periods + 1)\n",
    "    \n",
    "    num_periods = text.count('.')\n",
    "    num_newlines = text.count('\\n')\n",
    "    \n",
    "    return num_newlines > num_periods + 1\n",
    "\n",
    "questions_df['answer'].apply(check_newlines).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n Oliver Wendell Holmes, Jr.  remarked that “Revolutions never follow precedents nor furnish them.” Given the unpredictability, the nonlinearity, the seeming uniqueness of revolutions, whether political or scientific, it is therefore surprising to find Thomas Kuhn attempting to provide a General Theory of Scientific Revolutions . Early Kuhn did seem to believe that there is a single, underlying pattern to the development of mature sciences that is key to their success, and late Kuhn a different pattern. Has either early or late Kuhn found such a pattern, or has he imposed his own philosophical structure on the vagaries and vicissitudes of history? Kuhn’s Kantianism always did live in tension with his historicism, and in his late work  he surprisingly gave up the pretense of deriving his pattern of taxonomic change and speciation from history of science, on the ground that it largely followed “from first principles.”\\n Numerous philosophers, scientists, and other commentators have made claims about scientific change that differ from Kuhn’s.  Some, as we have seen, are skeptical of revolution talk altogether, others of Kuhn’s in particular. Still others accept that some revolutions are Kuhnian but deny that all of them are. One common criticism is that not all revolutionary advances are preceded by an acute crisis, that is, by major failures of preceding research. Kuhn himself allowed for exceptions already in Structure. Another is that revolutionary changes need not involve discontinuities in all of Kuhn’s levels at once . Yet another is that there need be little logical or linguistic discontinuity. A rapid, seemingly transformative change in research practices may involve simply a marked gain in data accessibility or accuracy or computational processing ability via new instrumentation or experimental design. And on the later Kuhn’s own view, revolution need not be a game of creative destruction. Only a few examples can be considered here.',\n",
       " '\\n\\n Though less popular than it once was, international relations was once dominated by realists who argued that political states are not constrained by morality in their dealings with foreign states and individuals. The basic idea motivating this approach was most often the Hobbesian presumption that morality consists solely of contracts which are binding only in the presence of a sovereign who could enforce them. And since there is no world sovereign capable of punishing states, the latter cannot be morally bound by any putative contracts which purport to apply to them. As a consequence, realists have traditionally supposed that states will and should orient their dealings with foreigners in whatever fashion maximally suits their national interests. And if this is correct, there can be no duties of any kind owed to foreign states or individuals, and thus no duty to open one’s borders to foreigners.\\n\\n Many are reluctant today to endorse realism, in part because they reject the Hobbesian approach to morality, but also because they believe that states can be held accountable even in the absence of a single, global sovereign. Given this, theorists typically feel no need to defeat the realist case for closed borders. It is worth noting, however, that the permissibility of closed borders does not automatically follow from realism, because (more) open borders may be in a country’s national interest. It is not just that any given country might stand to benefit in various ways from immigration, it may also be that a country’s own citizens have rights which require the state’s borders to be porous. If individuals have property rights which entitle them to invite foreigners onto their land or rights to freedom of association which entitle them to associate domestically with foreigners, for instance, then a country may well be duty-bound to allow open immigration even if it owes no moral duties to outsiders.',\n",
       " '\\n As far as we know, explicit metaphysical discussions began in China in the mid to late 4th century BCE with the Laozi (Daodejing) and associated texts. Before that, the two dominant philosophical movements were the Mohists and the Confucians (Ru). Both focused on political and ethical issues and showed little direct concern with metaphysical questions, but their discussions of the divine set the context for the emergence of metaphysical debates.\\n The two most relevant concepts are tian 天 (heaven) and ming 命 (the command; fate). The idea of tianming 天命 (the “Mandate of Heaven”) first came to prominence in rationalizing the conquest of the Shang dynasty by King Wen and King Wu, who founded the Zhou dynasty in the eleventh century BCE. Heaven is described in anthropomorphic terms as having awareness, preferences, and values. Its most fundamental concern is for the people, as expressed in a famous line from the “Great Declaration” chapter of the Book of Documents (Shangshu 尚書): “Heaven sees from where my people see; heaven hears from where my people hear” (quoted from Mengzi 5A5). As a political doctrine, the claim is that heaven will support rulers who help the people and will bring disaster on rulers who do not. On this view, the world works on consistent patterns that encompass ethical and political concerns. Human beings determine their own success or failure based on these patterns rather than depending on divine whim. The emergence of this view is commonly seen as a decisive moment in the formation of Chinese philosophy.\\n While heaven is presented as a willful and anthropomorphic being in the early parts of the Shangshu 尚書, it was not transcendent in the sense of being external to the system of nature. The term tian simultaneously refers to the sky, the orderly movement of the heavens, and something that covers all things equally. The classical Chinese word for the “world” or “realm” is literally what is “under-heaven”, tianxia 天下. Since the actions of heaven occur through the world, the two are often difficult to distinguish. The primary expression of heaven’s will is through human actions—to lose heaven’s mandate is to lose their support. The eventual transition in conceptions of heaven from a willful deity to the causal patterns of nature was possible because heaven was never separate from those patterns. Debates were about the nature of heaven rather than its existence, and heaven remained a central term for philosophers holding widely different viewpoints.\\n The belief that heaven supported good rulers and punished the bad came into question as the Zhou dynasty fell apart. Something like the classical problem of evil arose as centuries of civil war and disaster made it difficult to believe that the world was structured along ethical lines . Three responses to this crisis can be distinguished. One, exemplified by the Mohists, defended and theorized the earlier view that heaven rewarded those who are good, defined as those who care inclusively for other people. The second emphasized that good and bad events come without reason and without concern for justice. This view was associated with a new meaning for ming, taking it not as a command but as something more like blind fate. The third position argued for the regularity of natural patterns but took those patterns as amoral. On this view, human beings remain in control of their fate, but what brings success is not ethical action, at least in a conventional sense. Versions of this view appears in the Laozi and in theories arising from practical arts like medicine or military strategy. While expressed in different ways in different times, the belief that nature follows consistent patterns that can guide human action became a dominant view across Chinese philosophies, while the relationship between these patterns and humanistic values became one of the main points of dispute.',\n",
       " '\\n The view that an individual’s transworld identity is ‘bare’ is sometimes described as the view that its identity consists in its possession of a ‘haecceity’ or ‘thisness’: an unanalysable non-qualitative property that is necessary and sufficient for its being the individual that it is. (The term ‘individual essence’ is sometimes used to denote such a haecceity. It should be noted that according to the terminology used in this article, although a haecceity would be an individual essence, it would not be a non-trivial individual essence.) However, it is not obvious that the belief in bare identities requires the acceptance of haecceities. One can apparently hold that transworld identities may be ‘bare’ without holding that they are constituted by any properties at all, even unanalysable haecceities . Thus we should distinguish what is standardly known as ‘haecceitism’ (roughly, the view that there may be bare identities across possible worlds in the sense of identities that do not supervene on qualitative properties) from the belief in haecceities (the belief that individuals have unanalysable non-qualitative properties that constitute their being the individuals that they are). \\n In addition, it should be noted that to believe in ‘bare’ transworld identities, in the sense under discussion here, is not to believe in ‘bare particulars’, if to be a bare particular is to be an entity devoid of (non-trivial) essential properties. As the arguments discussed in Sections 4.1–4.2 above demonstrate, a commitment to a ‘bare’ (or ‘ungrounded’) difference in the identities of two individuals A and B in different possible worlds (two human beings, or two trees, for example) does not imply that those individuals have no non-trivial essential properties. All it implies is that A and B do not differ in their non-trivial essential properties—and hence that, although there may well be non-trivial necessary conditions for being A in any possible world, and non-trivial necessary conditions for being B in any possible world, there are no non-trivial necessary conditions for being A that are not also necessary conditions for being B, and vice versa. .)',\n",
       " '\\n The causes of irreproducible results are largely the same across disciplines we have mentioned. This is not surprising given that they stem from problems with statistical methods, publishing practices and the incentive structures created in a “publish or perish” research culture, all of which are largely shared, at least in the life and behavioral sciences.\\n Whilst replication is often casually referred to as a cornerstone of the scientific method, direct replication studies (as they might be understood from Schmidt or Gómez, Juristo, and Vegas’s typologies above) are a rare event in the published literature of some scientific disciplines, most notably the life and social sciences. For example, such replication attempts constitute roughly 1% of the published psychology literature . The proportion in published ecology and evolution literature is even smaller .\\n This virtual absence of replication studies in the literature can explained by the fact that many scientific journals have historically had explicit policies against publishing replication studies —thus giving rise to a “publication bias”. Over 70% of editors from 79 social science journals said they preferred new studies over replications and over 90% said they would did not encourage the submission of replication studies . In addition, many science funding bodies also fund only “novel”, “original” and/or “groundbreaking” research .\\n A second type of publication bias has also played a substantial role in the reproducibility crisis, namely a bias towards “statistically significant” or “positive” results. Unlike the bias against replication studies, this is rarely an explicitly stated policy of a journal. Publication bias towards statistically significant findings has a long history, and was first documented in psychology by Sterling . Developments in text mining techniques have led to more comprehensive estimates. For example, Fanelli’s work has demonstrated the extent of publication bias in various disciplines, and the proportions of statistically significant results given below are from his 2010a paper. He has also documented the increase of this bias over time  and explored the causes of the bias, including the relationship between publication bias and a publish or perish research culture .\\n In many disciplines (e.g., psychology, psychiatry, materials science, pharmacology and toxicology, clinical medicine, biology and biochemistry, economics and business, microbiology and genetics) the proportion of statistically significant results is very high, close to or exceeding 90% . This is despite the fact that in many of these fields, the average statistical power is low—that is, the average probability that a study will correctly reject the null hypothesis is low. For example, in psychology the proportion of published results that are statistically significant is 92% despite the fact that the average power of studies in this field to detect medium effect sizes (arguably typical of the discipline) is roughly 44% . If there was no bias towards publishing statistically significant results, the proportion of significant results should roughly match the average statistical power of the discipline. The excess in statistical significance (in this case, the difference between 92% and 44%) is therefore an indicator the strength of the bias. For a second example, in ecology, environment and plant and animal sciences the proportion of statistically significant results is 74% and 78% respectively, admittedly lower than in psychology. However, the most recent estimate of the statistical power, again of medium effect sizes, of ecology and animal behaviour is 23–26%   For a third example, the proportion of statistically significant results in neuroscience and behaviour is 85%. Our best estimate of the statistical power in neuroscience is at best 31%, with a lower bound estimate of 8% . The associated file-drawer problem —where researchers relegate failed statistically non-significant studies to their file drawers, hidden from public view—has long been established in psychology and others disciplines, and is known to lead to distortions in meta-analysis (where a “meta-analysis” is a study which analyses results across multiple other studies).']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## see some random examples\n",
    "questions_df.sample(5)[\"answer\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_dataset=Dataset.from_pandas(questions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f1c8da051141c68f267228511d5eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23864a4f823146ff8ee733615d6dd5e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a58aa2651c43c7882d62dbee2150f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/ruggsea/stanford-encyclopedia-of-philosophy_instruct/commit/02003395f7003f0fbfd0b5b7d57979708bceeb13', commit_message='Fixing newlines and citations', commit_description='', oid='02003395f7003f0fbfd0b5b7d57979708bceeb13', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## upload to HF\n",
    "\n",
    "questions_dataset.push_to_hub(\"ruggsea/stanford-encyclopedia-of-philosophy_instruct\", commit_message=\"Fixing newlines and citations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b93aeca8f4ee4d7b8c9c0d52565f2e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/3.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 15.9M/15.9M [00:00<00:00, 25.3MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853bc60c51e242b09bc02f6f0ca5e30b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/12854 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## try seeing if it gets loaded\n",
    "\n",
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "phil_enc_dataset= load_dataset(\"ruggsea/stanford-encyclopedia-of-philosophy_instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the nature of abductive reasoning, and how does it differ from deductive and inductive reasoning?',\n",
       " 'answer': 'You happen to know that Tim and Harry have recently had a terrible row that ended their friendship. Now someone tells you that she just saw Tim and Harry jogging together. The best explanation for this that you can think of is that they made up. You conclude that they are friends again.\\n One morning you enter the kitchen to find a plate and cup on the table, with breadcrumbs and a pat of butter on it, and surrounded by a jar of jam, a pack of sugar, and an empty carton of milk. You conclude that one of your house-mates got up at night to make him- or herself a midnight snack and was too tired to clear the table. This, you think, best explains the scene you are facing. To be sure, it might be that someone burgled the house and took the time to have a bite while on the job, or a house-mate might have arranged the things on the table without having a midnight snack but just to make you believe that someone had a midnight snack. But these hypotheses strike you as providing much more contrived explanations of the data than the one you infer to.\\n Walking along the beach, you see what looks like a picture of Winston Churchill in the sand. It could be that, as in the opening pages of Hilary Putnam’s book Reason, Truth, and History, , what you see is actually the trace of an ant crawling on the beach. The much simpler, and therefore (you think) much better, explanation is that someone intentionally drew a picture of Churchill in the sand. That, in any case, is what you come away believing.\\n In these examples, the conclusions do not follow logically from the premises. For instance, it does not follow logically that Tim and Harry are friends again from the premises that they had a terrible row which ended their friendship and that they have just been seen jogging together; it does not even follow, we may suppose, from all the information you have about Tim and Harry. Nor do you have any useful statistical data about friendships, terrible rows, and joggers that might warrant an inference from the information that you have about Tim and Harry to the conclusion that they are friends again, or even to the conclusion that, probably (or with a certain probability), they are friends again. What leads you to the conclusion, and what according to a considerable number of philosophers may also warrant this conclusion, is precisely the fact that Tim and Harry’s being friends again would, if true, best explain the fact that they have just been seen jogging together. (The proviso that a hypothesis be true if it is to explain anything is taken as read from here on.) Similar remarks apply to the other two examples. The type of inference exhibited here is called abduction or, somewhat more commonly nowadays, Inference to the Best Explanation.'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phil_enc_dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52769fa568894701a257afbee67e41a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## tokenize the answers\n",
    "\n",
    "phil_enc_dataset_df=pd.DataFrame(phil_enc_dataset[\"train\"])\n",
    "\n",
    "phil_enc_dataset_df[\"tokenized_length\"]=phil_enc_dataset_df[\"answer\"].progress_apply(lambda x: len(np.array(tokenizer(x)[\"attention_mask\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter out the rows that are shorter than 100 \n",
    "\n",
    "\n",
    "phil_enc_dataset_df = phil_enc_dataset_df[phil_enc_dataset_df[\"tokenized_length\"] >= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop tokenized_length column\n",
    "\n",
    "phil_enc_dataset_df.drop(\"tokenized_length\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## turn it into a dataset\n",
    "\n",
    "phil_enc_dataset = Dataset.from_pandas(phil_enc_dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "phil_enc_dataset=phil_enc_dataset.remove_columns([\"__index_level_0__\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d9049b51b44312a927d814d73b8c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f781f46d4ca440f5bb31ce396a860352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "413f80a5447941fb87d9533c1a41eaab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/ruggsea/stanford-encyclopedia-of-philosophy_instruct/commit/c441069e1940f4d5c2b6474df4967adbc508efb4', commit_message='Upload dataset', commit_description='', oid='c441069e1940f4d5c2b6474df4967adbc508efb4', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## push to HF\n",
    "\n",
    "phil_enc_dataset.push_to_hub(\"ruggsea/stanford-encyclopedia-of-philosophy_instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a378f6fa9773446e8ee15bc5ecb12b04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/3.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 15.7M/15.7M [00:00<00:00, 27.6MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb13780cfa4747a4a00d988f70174863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/11904 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "phil_enc_dataset= load_dataset(\"ruggsea/stanford-encyclopedia-of-philosophy_instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the distinction between belief-disagreement and action-disagreement in the context of epistemology of disagreement?',\n",
       " 'answer': '\\n\\n A person can start out with a belief that is irrational, obtain some new relevant evidence concerning that belief, respond to that new evidence in a completely reasonable way, and yet end up with an irrational belief. This fact is particularly important when it comes to posing the central questions regarding the epistemology of disagreement .\\n\\n Suppose Bub’s belief that Japan is a totalitarian state, belief \\\\(J\\\\), is based on a poor reading of the evidence and a raging, irrational bias that rules his views on this topic. He has let his bias ruin his thinking through his evidence properly.\\n\\n Then he gets some new information: some Japanese police have been caught on film beating government protesters. After hearing this, Bub retains his old confidence level in \\\\(J\\\\).\\n\\n We take it that when Bub learns about the police, he has not acquired some new information that should make him think ‘Wait a minute; maybe I’m wrong about Japan’. He shouldn’t lose confidence in his belief \\\\(J\\\\) merely because he learned some facts that do not cast any doubt on his belief!\\n\\n The lesson of this story is this: Bub’s action of maintaining his confidence in his belief as a result of his new knowledge is reasonable even though his retained belief itself is unreasonable. Bub’s assessment of the original evidence concerning \\\\(J\\\\) was irrational, but his reaction to the new information was rational; his subsequent belief in \\\\(J\\\\) was (still) irrational (because although the video gives a little support to \\\\(J\\\\), it’s not much). The question, ‘Is Bub being rational after he got his new knowledge?’ has two reasonable interpretations: ‘Is his retained belief in \\\\(J\\\\) rational after his acquisition of the new knowledge?’ vs. ‘Is his response to the new knowledge rational?’\\n\\n On the one hand, “rationality demands” that upon his acquisition of new knowledge Bub drop his belief \\\\(J\\\\) that Japan is a totalitarian state: after all, his overall evidence for it is very weak. On the other hand, “rationality demands” that upon his acquisition of new knowledge Bub keep his belief \\\\(J\\\\) given that that acquisition—which is the only thing that’s happened to him—gives him no reason to doubt \\\\(J\\\\). This situation still might strike you as odd. After all, we’re saying that Bub is being rational in keeping an irrational belief! But no: that’s not what we’re saying. The statement ‘Bub is being rational’ is ambiguous: is it saying that Bub’s retained belief \\\\(J\\\\) is rational or is it saying that Bub’s retaining of that belief was rational? The statement can take on either meaning, and the two meanings end up with different verdicts: the retained belief is irrational but the retaining of the belief is rational. In the first case, a state is being evaluated, in the second, an action is being evaluated.\\n\\n Consider a more mundane case. Jack hears a bump in the night and irrationally thinks there is an intruder in his house (he has long had three cats and two dogs, so he should know by now that bumps are usually caused by his pets; further, he has been a house owner long enough to know full well that old houses like his make all sorts of odd noises at night, pets or no). Jack has irrational belief \\\\(B\\\\): there is an intruder upstairs or there is an intruder downstairs. Then after searching upstairs he learns that there is no intruder upstairs. Clearly, the reasonable thing for him to do is infer that there is an intruder downstairs—that’s the epistemically reasonable cognitive move to make in response to the new information, given—despite the fact that the new belief ‘There is an intruder downstairs’ is irrational in an evidential sense.\\n\\n These two stories show that one’s action of retaining one’s belief—that intellectual action—can be epistemically fine even though the retained belief is not. And, more importantly, we have to distinguish two questions about the acquisition of new information (which need not have anything at all to do with disagreement):\\n\\n The latter question concerns an intellectual action (an intellectual response to the acquisition of new information), whereas the former question concerns the subsequent level of confidence itself, the new confidence level you end up with, which comes about partially as a causal result of the intellectual action. As we have seen with the Japan and intruder stories the epistemic reasonableness of the one is partially independent of that of the other.'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phil_enc_dataset[\"train\"][2100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## upload stanford-encyclopedia-of-philosophy_instruct/readme.md\n",
    "\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "api = HfApi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.upload_file(path_or_fileobj=\"stanford-encyclopedia-of-philosophy_instruct/README.md\", repo_id=\"ruggsea/stanford-encyclopedia-of-philosophy_instruct\", path_in_repo=\"README.md\", repo_type=\"dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing stanford-encyclopedia-of-philosophy_chat_multi_turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the dataset is in the jsonl file multi_turn_gen_conversations.jsonl\n",
    "import pandas as pd\n",
    "\n",
    "multi_turn_df=pd.read_json(\"multi_turn_gen_conversations.jsonl\", lines=True).iloc[:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "multi_turn_dataset= Dataset.from_pandas(multi_turn_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dec7ce514f34f6db67d23fef135952a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e1860652ea49d6acb71c953c051b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67acecb44485430189d51fe1b44e4bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/ruggsea/stanford-encyclopedia-of-philosophy_chat_multi_turn/commit/031cbe0df342c32e47183cd238eb943d09d7412d', commit_message='Upload dataset', commit_description='', oid='031cbe0df342c32e47183cd238eb943d09d7412d', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## push to hub\n",
    "\n",
    "multi_turn_dataset.push_to_hub(\"ruggsea/stanford-encyclopedia-of-philosophy_chat_multi_turn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing stanford-encyclopedia-of-philosophy_chat_multi_turn_Athene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "multi_turn_df_athene=pd.read_json(\"multi_turn_gen_conversations_athene.jsonl\", lines=True).iloc[:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "multi_turn_dataset_athene= Dataset.from_pandas(multi_turn_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3186885ccdb04825b8ce78529da0b8b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a00b1e0db34a54870d897fff9ef414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb40460f42c4b4caf3ee8287e13eeb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/390 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/ruggsea/stanford-encyclopedia-of-philosophy_chat_multi_turn_athene/commit/beef69eeaaeef1687abd8b555db0ffd6f3bac209', commit_message='Upload dataset', commit_description='', oid='beef69eeaaeef1687abd8b555db0ffd6f3bac209', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_turn_dataset_athene.push_to_hub(\"ruggsea/stanford-encyclopedia-of-philosophy_chat_multi_turn_athene\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing stanford-encyclopedia-of-philosophy_chat_multi_turn_mistral_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302e0817653d4c74b51c1f2c4d94b6ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667261a181714c6f986dc1690d0e7dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf33b04be60428d899ab562fa927206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/ruggsea/stanford-encyclopedia-of-philosophy_chat_multi_turn_mistral_large/commit/5797a60509dd2dd6665cd1ebcbdcd1c3b89e006f', commit_message='Upload dataset', commit_description='', oid='5797a60509dd2dd6665cd1ebcbdcd1c3b89e006f', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same for mistral_large\n",
    "import pandas as pd\n",
    "\n",
    "multi_turn_df_mistral_large=pd.read_json(\"multi_turn_gen_conversations_mistral_large.jsonl\", lines=True).iloc[:,::-1]\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "multi_turn_dataset_mistral_large= Dataset.from_pandas(multi_turn_df)\n",
    "\n",
    "multi_turn_dataset_mistral_large.push_to_hub(\"ruggsea/stanford-encyclopedia-of-philosophy_chat_multi_turn_mistral_large\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
