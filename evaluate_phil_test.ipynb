{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to see if we can use big models evaluate philosophical answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_HOME=/work/ba214121/.cache/huggingface\n",
      "env: TRANFORMERS_CACHE=/work/ba214121/.cache/huggingface\n",
      "env: HF_DATASETS_CACHE=/work/ba214121/.cache/huggingface\n",
      "/work/ba214121/.cache/huggingface\n"
     ]
    }
   ],
   "source": [
    "## loading env variables\n",
    "%env HF_HOME=/hpcwork/ba214121/.cache/huggingface\n",
    "%env TRANFORMERS_CACHE=/hpcwork/ba214121/.cache/huggingface\n",
    "%env HF_DATASETS_CACHE=/hpcwork/ba214121/.cache/huggingface\n",
    "\n",
    "\n",
    "!echo $HF_DATASETS_CACHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ba214121/.local/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9baa4d6bd4d3458e92ae37e5ccf67b75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/723 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ba214121/.local/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9729c83132343f1aa436f080b507cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc2345bf2044356be3b5014ac73b7b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "543e4125eead4a6b99faad66bf0fac96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from evaluate_phil import evaluate_philosophy\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "## load model inside home/ba214121/finetuning/Llama3-stanford-encyclopedia-philosophy-QA\n",
    "\n",
    "model=AutoModelForCausalLM.from_pretrained(\"ruggsea/Llama3-stanford-encyclopedia-philosophy-QA\")\n",
    "tokenizer=AutoTokenizer.from_pretrained(\"ruggsea/Llama3-stanford-encyclopedia-philosophy-QA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ba214121/.local/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "## set chat template to the llama instruct one\n",
    "\n",
    "\n",
    "llama_tokenizer=AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## trying inference\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "conversation_pipeline=pipeline(\"conversational\", model=model, tokenizer=tokenizer )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt=\"You are an expert and informative yet accessible Philosophy university professor. Students will pose you philosophical questions, answer them in a correct and rigorous but not to obscure way.\"\n",
    "\n",
    "convo=[\n",
    "    {\"role\":\"system\", \"content\":system_prompt},\n",
    "    {\"role\":\"user\", \"content\":\"What is peace\"}\n",
    "]\n",
    "\n",
    "convo_text=tokenizer.apply_chat_template(convo, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conversation id: 6a065891-e212-46aa-80a1-4f27fe7c8e66\n",
       "system: You are an expert and informative yet accessible Philosophy university professor. Students will pose you philosophical questions, answer them in a correct and rigorous but not to obscure way.\n",
       "user: What is peace\n",
       "assistant:  In the previous section we have seen that peace is a political good that is also a good for human nature. The problem of peace is the problem of the conditions for peace, which is a problem of the conditions for the use of reason. The problem of the conditions for the use of reason is the problem of the conditions for the use of reason in the public sphere. The problem of the conditions for the use of reason in the public sphere is the problem of the conditions for the use of reason in the public sphere without violence. The problem of the conditions for the use of reason in the public sphere without violence is the problem of the conditions for the use of reason in the public sphere without violence in the face of the threat of violence. The problem of the conditions for the use of reason in the public sphere without violence in the face of the threat of violence is the problem of the conditions for the use of reason in the public sphere without violence in the face of the threat of violence from the state. The problem of the conditions for the use of reason in the public sphere without violence in the face of the threat of violence from the state is the problem of the conditions for the use of reason in the public sphere without violence in the face of the threat of violence from the state"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_pipeline(convo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
